{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Table 5 Reproduction: Zero-Shot Perplexity\n",
        "\n",
        "**Ίδιες παράμετροι με Table 4**, διαφορετικό evaluation dataset.\n",
        "\n",
        "| | Table 4 | Table 5 |\n",
        "|---|---|---|\n",
        "| Training | OWT | OWT (ίδιο) |\n",
        "| Evaluation | OWT | Wikitext, PTB, LM1B, κλπ |"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "setup1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10437e04-727c-4fd5-8708-8237aa22011a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bd3lms'...\n",
            "remote: Enumerating objects: 841, done.\u001b[K\n",
            "remote: Counting objects: 100% (298/298), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 841 (delta 240), reused 224 (delta 198), pack-reused 543 (from 1)\u001b[K\n",
            "Receiving objects: 100% (841/841), 3.00 MiB | 38.83 MiB/s, done.\n",
            "Resolving deltas: 100% (534/534), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone repo\n",
        "!cd /content && rm -rf bd3lms\n",
        "!cd /content && git clone https://github.com/ntua-el21050/bd3lms.git\n",
        "\n",
        "# Create directories\n",
        "!mkdir -p /content/bd3lms/data\n",
        "!mkdir -p /content/repro_runs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics==1.6.2 datasets==3.3.2 einops==0.8.1 \\\n",
        "    hydra-core==1.3.2 lightning==2.5.0.post0 transformers==4.49.0"
      ],
      "metadata": {
        "id": "setup2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9996454f-7dbb-45e4-c824-ca96c055691c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m931.6/931.6 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import re\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "def run_main(overrides, timeout=None):\n",
        "    \"\"\"Run `python -u main.py ...` and return combined stdout/stderr text.\"\"\"\n",
        "    env = dict(os.environ)\n",
        "    env.setdefault(\"HYDRA_FULL_ERROR\", \"1\")\n",
        "    cmd = [sys.executable, \"-u\", \"bd3lms/main.py\", *overrides]\n",
        "    print(\"\\n$\", \" \".join(cmd))\n",
        "    proc = subprocess.run(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        timeout=timeout,\n",
        "        check=False,\n",
        "        env=env,\n",
        "    )\n",
        "    print(proc.stdout[-4000:])\n",
        "    if proc.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed with return code {proc.returncode}\")\n",
        "    return proc.stdout\n",
        "\n",
        "_METRIC_PATTERNS = [\n",
        "    re.compile(r\"val/ppl\\s*[:=]\\s*([0-9]+(?:\\.[0-9]+)?(?:e[+-]?\\d+)?)\", re.IGNORECASE),\n",
        "    re.compile(r\"'val/ppl'\\s*:\\s*([0-9]+(?:\\.[0-9]+)?(?:e[+-]?\\d+)?)\", re.IGNORECASE),\n",
        "    re.compile(r\"val/ppl\\s*[│|]\\s*([0-9]+(?:\\.[0-9]+)?(?:e[+-]?\\d+)?)\", re.IGNORECASE),\n",
        "]\n",
        "\n",
        "def extract_val_ppl(log_text: str):\n",
        "    for line in reversed(log_text.splitlines()):\n",
        "        if \"val/ppl\" in line.lower():\n",
        "            m = re.search(r\"val/ppl.*?([0-9]+(?:\\.[0-9]+)?(?:e[+-]?\\d+)?)\", line, re.IGNORECASE)\n",
        "            if m:\n",
        "                return float(m.group(1))\n",
        "    hits = []\n",
        "    for pat in _METRIC_PATTERNS:\n",
        "        hits.extend(pat.findall(log_text))\n",
        "    return float(hits[-1]) if hits else None\n",
        "\n",
        "def _small_loader_overrides(batch_size=4, num_workers=2):\n",
        "    \"\"\"Smaller batch size for OWT (1024 context length).\"\"\"\n",
        "    return [\n",
        "        f\"loader.global_batch_size={batch_size}\",\n",
        "        f\"loader.eval_global_batch_size={batch_size}\",\n",
        "        f\"loader.batch_size={batch_size}\",\n",
        "        f\"loader.eval_batch_size={batch_size}\",\n",
        "        f\"loader.num_workers={num_workers}\",\n",
        "        \"trainer.accumulate_grad_batches=1\",\n",
        "    ]"
      ],
      "metadata": {
        "id": "utils"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_run(run_name, algo, block_size=None, from_pretrained=None, max_steps=800, extra_overrides=None):\n",
        "    \"\"\"Train a model for Table 5 (identical to Table 4).\"\"\"\n",
        "    save_dir = Path(\"/content/repro_runs\") / run_name\n",
        "    if save_dir.exists():\n",
        "        shutil.rmtree(save_dir)\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    overrides = [\n",
        "        \"mode=train\",\n",
        "        # ══════════════════════════════════════════════════════════════════\n",
        "        # DATA CONFIG (ίδιο με Table 4)\n",
        "        # ══════════════════════════════════════════════════════════════════\n",
        "        \"data=openwebtext-split\",\n",
        "        \"data.cache_dir=/content/bd3lms/data\",\n",
        "        \"data.streaming=true\",\n",
        "        \"data.max_train_samples=1200\",      # ← Ίδιο με Table 4\n",
        "        \"data.max_valid_samples=100\",       # ← Ίδιο με Table 4\n",
        "        \"data.max_test_samples=100\",        # ← Ίδιο με Table 4\n",
        "        # ══════════════════════════════════════════════════════════════════\n",
        "        # MODEL CONFIG (ίδιο με Table 4)\n",
        "        # ══════════════════════════════════════════════════════════════════\n",
        "        \"model=tiny\",\n",
        "        \"model.length=1024\",\n",
        "        \"model.attn_backend=sdpa\",\n",
        "        f\"algo={algo}\",\n",
        "        # ══════════════════════════════════════════════════════════════════\n",
        "        # TRAINER CONFIG (ίδιο με Table 4)\n",
        "        # ══════════════════════════════════════════════════════════════════\n",
        "        \"trainer.accelerator=gpu\",\n",
        "        \"trainer.devices=1\",\n",
        "        \"trainer.num_nodes=1\",\n",
        "        \"trainer.precision=16-mixed\",\n",
        "        \"trainer.num_sanity_val_steps=0\",\n",
        "        \"trainer.log_every_n_steps=10\",\n",
        "        \"trainer.val_check_interval=10\",\n",
        "        f\"trainer.max_steps={max_steps}\",   # ← 800 by default\n",
        "        f\"checkpointing.save_dir=/content/repro_runs/{run_name}\",\n",
        "        \"checkpointing.resume_from_ckpt=false\",\n",
        "        \"wandb=null\",\n",
        "    ]\n",
        "    overrides.extend(_small_loader_overrides(batch_size=4, num_workers=2))\n",
        "\n",
        "    if block_size is not None:\n",
        "        overrides.append(f\"block_size={block_size}\")\n",
        "    if from_pretrained is not None:\n",
        "        overrides.append(f\"training.from_pretrained={from_pretrained}\")\n",
        "    if extra_overrides:\n",
        "        overrides.extend(extra_overrides)\n",
        "\n",
        "    _ = run_main(overrides)\n",
        "    ckpt = save_dir / \"checkpoints\" / \"last.ckpt\"\n",
        "    if not ckpt.exists():\n",
        "        raise FileNotFoundError(f\"Expected checkpoint not found: {ckpt}\")\n",
        "    return str(ckpt)"
      ],
      "metadata": {
        "id": "train_func"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_zeroshot(algo, checkpoint_path, dataset_name, block_size=None, extra_overrides=None):\n",
        "    \"\"\"\n",
        "    Zero-shot evaluation: trained on OWT, evaluated on DIFFERENT dataset.\n",
        "\n",
        "    Built-in datasets: 'wikitext', 'ptb', 'lm1b', 'lambada'\n",
        "    \"\"\"\n",
        "    overrides = [\n",
        "        \"mode=ppl_eval\",\n",
        "        # ══════════════════════════════════════════════════════════════════\n",
        "        # ZERO-SHOT: Different dataset!\n",
        "        # ══════════════════════════════════════════════════════════════════\n",
        "        f\"data={dataset_name}\",             # ← CHANGED for zero-shot\n",
        "        \"data.cache_dir=/content/bd3lms/data\",\n",
        "        \"data.streaming=true\",\n",
        "        \"data.max_test_samples=500\",        # ← Ίδιο με Table 4 eval\n",
        "        # ══════════════════════════════════════════════════════════════════\n",
        "        # MODEL CONFIG (must match training)\n",
        "        # ══════════════════════════════════════════════════════════════════\n",
        "        \"model=tiny\",\n",
        "        \"model.length=1024\",\n",
        "        \"model.attn_backend=sdpa\",\n",
        "        f\"algo={algo}\",\n",
        "        f\"eval.checkpoint_path={checkpoint_path}\",\n",
        "        \"trainer.accelerator=gpu\",\n",
        "        \"trainer.devices=1\",\n",
        "        \"trainer.num_nodes=1\",\n",
        "        \"trainer.precision=16-mixed\",\n",
        "        \"trainer.num_sanity_val_steps=0\",\n",
        "        \"wandb=null\",\n",
        "    ]\n",
        "    overrides.extend(_small_loader_overrides(batch_size=4, num_workers=2))\n",
        "\n",
        "    if block_size is not None:\n",
        "        overrides.append(f\"block_size={block_size}\")\n",
        "    if extra_overrides:\n",
        "        overrides.extend(extra_overrides)\n",
        "\n",
        "    log_text = run_main(overrides)\n",
        "    ppl = extract_val_ppl(log_text)\n",
        "    if ppl is None:\n",
        "        raise ValueError(\"Could not parse val/ppl from output.\")\n",
        "    return ppl"
      ],
      "metadata": {
        "id": "eval_func"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training (Ίδιο με Table 4)"
      ],
      "metadata": {
        "id": "training_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "CHECKPOINTS = {}\n",
        "\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# 1) AUTOREGRESSIVE BASELINE\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "print(\"=\" * 60)\n",
        "print(\"Training AR baseline...\")\n",
        "print(\"=\" * 60)\n",
        "ar_run = \"ar_tiny_owt_len1024\"\n",
        "CHECKPOINTS[\"AR\"] = train_run(ar_run, algo=\"ar\")\n",
        "print(f\"✓ AR checkpoint: {CHECKPOINTS['AR']}\")"
      ],
      "metadata": {
        "id": "train_ar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a0a06a-d19f-4e96-f94f-dd4df7d8aec6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Training AR baseline...\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_train_samples=1200 data.max_valid_samples=100 data.max_test_samples=100 model=tiny model.length=1024 model.attn_backend=sdpa algo=ar trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 trainer.log_every_n_steps=10 trainer.val_check_interval=10 trainer.max_steps=800 checkpointing.save_dir=/content/repro_runs/ar_tiny_owt_len1024 checkpointing.resume_from_ckpt=false wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1\n",
            "able this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 63.88it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 65.00it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:40<01:38,  2.45it/s, v_num=0]Epoch 2, global step 780: 'val/nll' reached 7.70358 (best 7.70358), saving model to '/content/repro_runs/ar_tiny_owt_len1024/checkpoints/best.ckpt' as top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 62.70it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 63.44it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:44<01:46,  2.25it/s, v_num=0]Epoch 2, global step 790: 'val/nll' reached 7.69995 (best 7.69995), saving model to '/content/repro_runs/ar_tiny_owt_len1024/checkpoints/best.ckpt' as top 1\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:49<01:30,  2.43it/s, v_num=0]\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:49<01:30,  2.43it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 60.69it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 61.52it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:49<01:31,  2.40it/s, v_num=0]Epoch 2, global step 800: 'val/nll' reached 7.69616 (best 7.69616), saving model to '/content/repro_runs/ar_tiny_owt_len1024/checkpoints/best.ckpt' as top 1\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:53<01:37,  2.26it/s, v_num=0]`Trainer.fit` stopped: `max_steps=800` reached.\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:53<01:37,  2.26it/s, v_num=0]\n",
            "\n",
            "✓ AR checkpoint: /content/repro_runs/ar_tiny_owt_len1024/checkpoints/last.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# 2) DIFFUSION BASELINES: SEDD + MDLM\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "for algo_name, display_name in [(\"sedd\", \"SEDD\"), (\"mdlm\", \"MDLM\")]:\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Training {display_name} baseline...\")\n",
        "    print(\"=\" * 60)\n",
        "    run_name = f\"{algo_name}_tiny_owt_len1024\"\n",
        "    CHECKPOINTS[display_name] = train_run(\n",
        "        run_name,\n",
        "        algo=algo_name,\n",
        "        extra_overrides=[\n",
        "            \"training.resample=false\",\n",
        "            \"algo.var_min=false\",\n",
        "            \"algo.clip_search_widths=[]\",\n",
        "        ],\n",
        "    )\n",
        "    print(f\"✓ {display_name} checkpoint: {CHECKPOINTS[display_name]}\")"
      ],
      "metadata": {
        "id": "train_diffusion",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e65371e-6374-454b-a884-a22998f9afbe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Training SEDD baseline...\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_train_samples=1200 data.max_valid_samples=100 data.max_test_samples=100 model=tiny model.length=1024 model.attn_backend=sdpa algo=sedd trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 trainer.log_every_n_steps=10 trainer.val_check_interval=10 trainer.max_steps=800 checkpointing.save_dir=/content/repro_runs/sedd_tiny_owt_len1024 checkpointing.resume_from_ckpt=false wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 training.resample=false algo.var_min=false algo.clip_search_widths=[]\n",
            "l/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:28<01:08,  3.48it/s, v_num=0]\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:28<01:08,  3.48it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 41.86it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 42.35it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:29<01:10,  3.39it/s, v_num=0]Epoch 2, global step 780: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 41.23it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 41.52it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:32<01:17,  3.09it/s, v_num=0]Epoch 2, global step 790: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:34<01:03,  3.44it/s, v_num=0]\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:34<01:03,  3.44it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 43.15it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 43.79it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:35<01:05,  3.37it/s, v_num=0]Epoch 2, global step 800: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:37<01:08,  3.23it/s, v_num=0]`Trainer.fit` stopped: `max_steps=800` reached.\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:37<01:08,  3.23it/s, v_num=0]\n",
            "\n",
            "✓ SEDD checkpoint: /content/repro_runs/sedd_tiny_owt_len1024/checkpoints/last.ckpt\n",
            "============================================================\n",
            "Training MDLM baseline...\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_train_samples=1200 data.max_valid_samples=100 data.max_test_samples=100 model=tiny model.length=1024 model.attn_backend=sdpa algo=mdlm trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 trainer.log_every_n_steps=10 trainer.val_check_interval=10 trainer.max_steps=800 checkpointing.save_dir=/content/repro_runs/mdlm_tiny_owt_len1024 checkpointing.resume_from_ckpt=false wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 training.resample=false algo.var_min=false algo.clip_search_widths=[]\n",
            "l/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:29<01:11,  3.38it/s, v_num=0]\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:29<01:11,  3.38it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 39.49it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 39.89it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:30<01:12,  3.29it/s, v_num=0]Epoch 2, global step 780: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 40.45it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 40.95it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:33<01:20,  2.98it/s, v_num=0]Epoch 2, global step 790: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:35<01:05,  3.36it/s, v_num=0]\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:35<01:05,  3.36it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 39.66it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 40.08it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:36<01:06,  3.29it/s, v_num=0]Epoch 2, global step 800: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:39<01:12,  3.03it/s, v_num=0]`Trainer.fit` stopped: `max_steps=800` reached.\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:39<01:12,  3.03it/s, v_num=0]\n",
            "\n",
            "✓ MDLM checkpoint: /content/repro_runs/mdlm_tiny_owt_len1024/checkpoints/last.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# 3) BD3-LM BASE TRAINING (block_size = 1024 = L)\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "print(\"=\" * 60)\n",
        "print(\"Training BD3-LM BASE (block_size=1024)...\")\n",
        "print(\"=\" * 60)\n",
        "bd3lm_base_run = \"bd3lm_base_owt_len1024\"\n",
        "bd3lm_base_ckpt = train_run(\n",
        "    bd3lm_base_run,\n",
        "    algo=\"bd3lm\",\n",
        "    block_size=1024,\n",
        "    extra_overrides=[\n",
        "        \"training.resample=false\",\n",
        "        \"algo.var_min=false\",\n",
        "        \"algo.clip_search_widths=[]\",\n",
        "    ],\n",
        ")\n",
        "print(f\"✓ BD3-LM base checkpoint: {bd3lm_base_ckpt}\")"
      ],
      "metadata": {
        "id": "train_bd3lm_base",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9c4455-7b66-4c35-eb1b-649e23097f14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Training BD3-LM BASE (block_size=1024)...\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_train_samples=1200 data.max_valid_samples=100 data.max_test_samples=100 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 trainer.log_every_n_steps=10 trainer.val_check_interval=10 trainer.max_steps=800 checkpointing.save_dir=/content/repro_runs/bd3lm_base_owt_len1024 checkpointing.resume_from_ckpt=false wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=1024 training.resample=false algo.var_min=false algo.clip_search_widths=[]\n",
            "l/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:37<01:30,  2.66it/s, v_num=0]\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:37<01:30,  2.66it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 33.17it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 33.46it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:38<01:32,  2.60it/s, v_num=0]Epoch 2, global step 780: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 32.40it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 32.80it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  29%|██▉       | 100/340 [00:41<01:40,  2.39it/s, v_num=0]Epoch 2, global step 790: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:44<01:21,  2.71it/s, v_num=0]\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:44<01:21,  2.71it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 33.59it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 33.77it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:45<01:22,  2.65it/s, v_num=0]Epoch 2, global step 800: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:47<01:27,  2.52it/s, v_num=0]`Trainer.fit` stopped: `max_steps=800` reached.\n",
            "\n",
            "Epoch 2:  35%|███▌      | 120/340 [00:47<01:27,  2.52it/s, v_num=0]\n",
            "\n",
            "✓ BD3-LM base checkpoint: /content/repro_runs/bd3lm_base_owt_len1024/checkpoints/last.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# 4) BD3-LM FINE-TUNING (block_size = 16, 8, 4)\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "for Lprime in [16, 8, 4]:\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Fine-tuning BD3-LM (block_size={Lprime})...\")\n",
        "    print(\"=\" * 60)\n",
        "    finetune_run = f\"bd3lm_finetune_owt_Lp{Lprime}\"\n",
        "    CHECKPOINTS[f\"BD3-LM_L{Lprime}\"] = train_run(\n",
        "        finetune_run,\n",
        "        algo=\"bd3lm\",\n",
        "        block_size=Lprime,\n",
        "        from_pretrained=bd3lm_base_ckpt,\n",
        "        extra_overrides=[\n",
        "            \"training.resample=true\",\n",
        "            \"algo.var_min=false\",\n",
        "            \"algo.clip_search_widths=[]\",\n",
        "        ],\n",
        "    )\n",
        "    print(f\"✓ BD3-LM (L'={Lprime}) checkpoint: {CHECKPOINTS[f'BD3-LM_L{Lprime}']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ALL TRAINING COMPLETE!\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "train_bd3lm_finetune",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "591f89f0-b21c-4b59-b7e0-e734d653878a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Fine-tuning BD3-LM (block_size=16)...\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_train_samples=1200 data.max_valid_samples=100 data.max_test_samples=100 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 trainer.log_every_n_steps=10 trainer.val_check_interval=10 trainer.max_steps=800 checkpointing.save_dir=/content/repro_runs/bd3lm_finetune_owt_Lp16 checkpointing.resume_from_ckpt=false wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=16 training.from_pretrained=/content/repro_runs/bd3lm_base_owt_len1024/checkpoints/last.ckpt training.resample=true algo.var_min=false algo.clip_search_widths=[]\n",
            "l/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:15<00:40,  2.93it/s, v_num=0]\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:15<00:40,  2.93it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 33.85it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 34.12it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:15<00:41,  2.90it/s, v_num=0]Epoch 2, global step 780: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 33.66it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 33.94it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:20<00:43,  2.74it/s, v_num=0]Epoch 2, global step 790: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  71%|███████   | 240/340 [01:22<00:34,  2.90it/s, v_num=0]\n",
            "Epoch 2:  71%|███████   | 240/340 [01:22<00:34,  2.90it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 33.56it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 34.06it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  71%|███████   | 240/340 [01:25<00:35,  2.81it/s, v_num=0]Epoch 2, global step 800: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  71%|███████   | 240/340 [01:26<00:36,  2.76it/s, v_num=0]`Trainer.fit` stopped: `max_steps=800` reached.\n",
            "\n",
            "Epoch 2:  71%|███████   | 240/340 [01:26<00:36,  2.76it/s, v_num=0]\n",
            "\n",
            "✓ BD3-LM (L'=16) checkpoint: /content/repro_runs/bd3lm_finetune_owt_Lp16/checkpoints/last.ckpt\n",
            "============================================================\n",
            "Fine-tuning BD3-LM (block_size=8)...\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_train_samples=1200 data.max_valid_samples=100 data.max_test_samples=100 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 trainer.log_every_n_steps=10 trainer.val_check_interval=10 trainer.max_steps=800 checkpointing.save_dir=/content/repro_runs/bd3lm_finetune_owt_Lp8 checkpointing.resume_from_ckpt=false wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=8 training.from_pretrained=/content/repro_runs/bd3lm_base_owt_len1024/checkpoints/last.ckpt training.resample=true algo.var_min=false algo.clip_search_widths=[]\n",
            "l/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:16<00:41,  2.87it/s, v_num=0]\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:16<00:41,  2.87it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 32.26it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 32.59it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:17<00:42,  2.83it/s, v_num=0]Epoch 2, global step 780: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 31.91it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 32.29it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:21<00:44,  2.71it/s, v_num=0]Epoch 2, global step 790: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  71%|███████   | 240/340 [01:23<00:34,  2.87it/s, v_num=0]\n",
            "Epoch 2:  71%|███████   | 240/340 [01:23<00:34,  2.87it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 31.80it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 32.06it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  71%|███████   | 240/340 [01:24<00:35,  2.84it/s, v_num=0]Epoch 2, global step 800: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  71%|███████   | 240/340 [01:26<00:35,  2.79it/s, v_num=0]`Trainer.fit` stopped: `max_steps=800` reached.\n",
            "\n",
            "Epoch 2:  71%|███████   | 240/340 [01:26<00:35,  2.79it/s, v_num=0]\n",
            "\n",
            "✓ BD3-LM (L'=8) checkpoint: /content/repro_runs/bd3lm_finetune_owt_Lp8/checkpoints/last.ckpt\n",
            "============================================================\n",
            "Fine-tuning BD3-LM (block_size=4)...\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_train_samples=1200 data.max_valid_samples=100 data.max_test_samples=100 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 trainer.log_every_n_steps=10 trainer.val_check_interval=10 trainer.max_steps=800 checkpointing.save_dir=/content/repro_runs/bd3lm_finetune_owt_Lp4 checkpointing.resume_from_ckpt=false wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=4 training.from_pretrained=/content/repro_runs/bd3lm_base_owt_len1024/checkpoints/last.ckpt training.resample=true algo.var_min=false algo.clip_search_widths=[]\n",
            "l/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:18<00:42,  2.82it/s, v_num=0]\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:18<00:42,  2.82it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 32.68it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 33.01it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:19<00:43,  2.78it/s, v_num=0]Epoch 2, global step 780: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 32.61it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 32.81it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  65%|██████▍   | 220/340 [01:22<00:44,  2.67it/s, v_num=0]Epoch 2, global step 790: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  71%|███████   | 240/340 [01:25<00:35,  2.80it/s, v_num=0]\n",
            "Epoch 2:  71%|███████   | 240/340 [01:25<00:35,  2.80it/s, v_num=0]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 20/24 [00:00<00:00, 32.58it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 32.83it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 2:  71%|███████   | 240/340 [01:26<00:36,  2.77it/s, v_num=0]Epoch 2, global step 800: 'val/nll' was not in top 1\n",
            "\n",
            "Epoch 2:  71%|███████   | 240/340 [01:28<00:36,  2.71it/s, v_num=0]`Trainer.fit` stopped: `max_steps=800` reached.\n",
            "\n",
            "Epoch 2:  71%|███████   | 240/340 [01:28<00:36,  2.71it/s, v_num=0]\n",
            "\n",
            "✓ BD3-LM (L'=4) checkpoint: /content/repro_runs/bd3lm_finetune_owt_Lp4/checkpoints/last.ckpt\n",
            "\n",
            "============================================================\n",
            "ALL TRAINING COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_owt(algo, checkpoint_path, block_size=None, extra_overrides=None):\n",
        "    \"\"\"Evaluate on OWT (SANITY CHECK - should get ~2000 PPL like Table 4).\"\"\"\n",
        "    overrides = [\n",
        "        \"mode=ppl_eval\",\n",
        "        \"data=openwebtext-split\",\n",
        "        \"data.cache_dir=/content/bd3lms/data\",\n",
        "        \"data.streaming=true\",\n",
        "        \"data.max_test_samples=500\",\n",
        "        \"model=tiny\",\n",
        "        \"model.length=1024\",\n",
        "        \"model.attn_backend=sdpa\",\n",
        "        f\"algo={algo}\",\n",
        "        f\"eval.checkpoint_path={checkpoint_path}\",\n",
        "        \"trainer.accelerator=gpu\",\n",
        "        \"trainer.devices=1\",\n",
        "        \"trainer.num_nodes=1\",\n",
        "        \"trainer.precision=16-mixed\",\n",
        "        \"trainer.num_sanity_val_steps=0\",\n",
        "        \"wandb=null\",\n",
        "    ]\n",
        "    overrides.extend(_small_loader_overrides(batch_size=4, num_workers=2))\n",
        "\n",
        "    if block_size is not None:\n",
        "        overrides.append(f\"block_size={block_size}\")\n",
        "    if extra_overrides:\n",
        "        overrides.extend(extra_overrides)\n",
        "\n",
        "    log_text = run_main(overrides)\n",
        "    ppl = extract_val_ppl(log_text)\n",
        "    if ppl is None:\n",
        "        raise ValueError(\"Could not parse val/ppl from output.\")\n",
        "    return ppl"
      ],
      "metadata": {
        "id": "WGAC1EqPD9F6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# OWT SANITY CHECK - Should match Table 4 results (~2000 PPL)\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "owt_results = []\n",
        "\n",
        "EXPECTED_OWT_PPL = {\n",
        "    \"AR\": 2035, \"SEDD\": 2120, \"MDLM\": 2100,\n",
        "    \"BD3-LM L'=16\": 1940, \"BD3-LM L'=8\": 1940, \"BD3-LM L'=4\": 1935,\n",
        "}\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"OWT SANITY CHECK\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# AR\n",
        "ppl = eval_owt(\"ar\", CHECKPOINTS[\"AR\"])\n",
        "owt_results.append({\"Model\": \"AR\", \"OWT_PPL\": ppl, \"Expected\": 2035})\n",
        "print(f\"✓ AR: {ppl:.1f} (expected ~2035)\")\n",
        "\n",
        "# SEDD & MDLM\n",
        "for name, algo in [(\"SEDD\", \"sedd\"), (\"MDLM\", \"mdlm\")]:\n",
        "    ppl = eval_owt(algo, CHECKPOINTS[name], extra_overrides=[\"algo.var_min=false\"])\n",
        "    owt_results.append({\"Model\": name, \"OWT_PPL\": ppl, \"Expected\": EXPECTED_OWT_PPL[name]})\n",
        "    print(f\"✓ {name}: {ppl:.1f} (expected ~{EXPECTED_OWT_PPL[name]})\")\n",
        "\n",
        "# BD3-LM variants\n",
        "for Lprime in [16, 8, 4]:\n",
        "    name = f\"BD3-LM L'={Lprime}\"\n",
        "    ppl = eval_owt(\"bd3lm\", CHECKPOINTS[f\"BD3-LM_L{Lprime}\"], block_size=Lprime, extra_overrides=[\"algo.var_min=false\"])\n",
        "    owt_results.append({\"Model\": name, \"OWT_PPL\": ppl, \"Expected\": EXPECTED_OWT_PPL[name]})\n",
        "    print(f\"✓ {name}: {ppl:.1f} (expected ~{EXPECTED_OWT_PPL[name]})\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "owt_df = pd.DataFrame(owt_results)\n",
        "print(owt_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQIQL0stD-0I",
        "outputId": "157469fc-f46c-4876-e99e-b38505abf608"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "OWT SANITY CHECK\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=ar eval.checkpoint_path=/content/repro_runs/ar_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1\n",
            "| 26740/27619 [06:37<00:13, 67.23it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26760/27619 [06:38<00:12, 67.23it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26780/27619 [06:38<00:12, 67.23it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26800/27619 [06:38<00:12, 67.23it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26820/27619 [06:38<00:11, 67.23it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26840/27619 [06:39<00:11, 67.23it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26860/27619 [06:39<00:11, 67.23it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26880/27619 [06:39<00:10, 67.23it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26900/27619 [06:40<00:10, 67.23it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26920/27619 [06:40<00:10, 67.23it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26940/27619 [06:40<00:10, 67.23it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26960/27619 [06:41<00:09, 67.23it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26980/27619 [06:41<00:09, 67.23it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27000/27619 [06:41<00:09, 67.23it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27020/27619 [06:41<00:08, 67.23it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27040/27619 [06:42<00:08, 67.23it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27060/27619 [06:42<00:08, 67.23it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27080/27619 [06:42<00:08, 67.23it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27100/27619 [06:43<00:07, 67.23it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27120/27619 [06:43<00:07, 67.23it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27140/27619 [06:43<00:07, 67.22it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27160/27619 [06:44<00:06, 67.22it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27180/27619 [06:44<00:06, 67.22it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27200/27619 [06:44<00:06, 67.22it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27220/27619 [06:44<00:05, 67.22it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27240/27619 [06:45<00:05, 67.22it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27260/27619 [06:45<00:05, 67.23it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27280/27619 [06:45<00:05, 67.23it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27300/27619 [06:46<00:04, 67.23it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27320/27619 [06:46<00:04, 67.24it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27340/27619 [06:46<00:04, 67.24it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27360/27619 [06:46<00:03, 67.24it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27380/27619 [06:47<00:03, 67.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27400/27619 [06:47<00:03, 67.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27420/27619 [06:47<00:02, 67.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27440/27619 [06:48<00:02, 67.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27460/27619 [06:48<00:02, 67.26it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27480/27619 [06:48<00:02, 67.26it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27500/27619 [06:48<00:01, 67.26it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27520/27619 [06:49<00:01, 67.26it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27540/27619 [06:49<00:01, 67.26it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27560/27619 [06:49<00:00, 67.26it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27580/27619 [06:50<00:00, 67.26it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27600/27619 [06:50<00:00, 67.26it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [06:50<00:00, 67.26it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [06:50<00:00, 67.25it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    10.991169929504395     │\n",
            "│          val/nll          │     7.618498802185059     │\n",
            "│          val/ppl          │     2035.504150390625     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "✓ AR: 2035.5 (expected ~2035)\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=sedd eval.checkpoint_path=/content/repro_runs/sedd_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 algo.var_min=false\n",
            "| 26740/27619 [09:49<00:19, 45.40it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26760/27619 [09:49<00:18, 45.40it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26780/27619 [09:49<00:18, 45.40it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26800/27619 [09:50<00:18, 45.40it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26820/27619 [09:50<00:17, 45.40it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26840/27619 [09:51<00:17, 45.40it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26860/27619 [09:51<00:16, 45.40it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26880/27619 [09:52<00:16, 45.40it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26900/27619 [09:52<00:15, 45.40it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26920/27619 [09:52<00:15, 45.40it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26940/27619 [09:53<00:14, 45.40it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26960/27619 [09:53<00:14, 45.40it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26980/27619 [09:54<00:14, 45.40it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27000/27619 [09:54<00:13, 45.40it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27020/27619 [09:55<00:13, 45.40it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27040/27619 [09:55<00:12, 45.40it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27060/27619 [09:56<00:12, 45.40it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27080/27619 [09:56<00:11, 45.40it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27100/27619 [09:56<00:11, 45.40it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27120/27619 [09:57<00:10, 45.39it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27140/27619 [09:57<00:10, 45.39it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27160/27619 [09:58<00:10, 45.39it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27180/27619 [09:58<00:09, 45.39it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27200/27619 [09:59<00:09, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27220/27619 [09:59<00:08, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27240/27619 [10:00<00:08, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27260/27619 [10:00<00:07, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27280/27619 [10:00<00:07, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27300/27619 [10:01<00:07, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27320/27619 [10:01<00:06, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27340/27619 [10:02<00:06, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27360/27619 [10:02<00:05, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27380/27619 [10:03<00:05, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27400/27619 [10:03<00:04, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27420/27619 [10:04<00:04, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27440/27619 [10:04<00:03, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27460/27619 [10:04<00:03, 45.39it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27480/27619 [10:05<00:03, 45.39it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27500/27619 [10:05<00:02, 45.39it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27520/27619 [10:06<00:02, 45.39it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27540/27619 [10:06<00:01, 45.39it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27560/27619 [10:07<00:01, 45.39it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27580/27619 [10:07<00:00, 45.39it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27600/27619 [10:08<00:00, 45.39it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [10:08<00:00, 45.39it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [10:08<00:00, 45.39it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.050122261047363     │\n",
            "│          val/nll          │     7.659360885620117     │\n",
            "│          val/ppl          │     2120.40185546875      │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "✓ SEDD: 2120.4 (expected ~2120)\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=mdlm eval.checkpoint_path=/content/repro_runs/mdlm_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 algo.var_min=false\n",
            "| 26740/27619 [10:21<00:20, 43.03it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26760/27619 [10:21<00:19, 43.03it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26780/27619 [10:22<00:19, 43.03it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26800/27619 [10:22<00:19, 43.03it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26820/27619 [10:23<00:18, 43.03it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26840/27619 [10:23<00:18, 43.03it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26860/27619 [10:24<00:17, 43.03it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26880/27619 [10:24<00:17, 43.03it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26900/27619 [10:25<00:16, 43.03it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26920/27619 [10:25<00:16, 43.03it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26940/27619 [10:26<00:15, 43.03it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26960/27619 [10:26<00:15, 43.03it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26980/27619 [10:26<00:14, 43.03it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27000/27619 [10:27<00:14, 43.03it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27020/27619 [10:27<00:13, 43.03it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27040/27619 [10:28<00:13, 43.03it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27060/27619 [10:28<00:12, 43.03it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27080/27619 [10:29<00:12, 43.03it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27100/27619 [10:29<00:12, 43.03it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27120/27619 [10:30<00:11, 43.04it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27140/27619 [10:30<00:11, 43.04it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27160/27619 [10:31<00:10, 43.04it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27180/27619 [10:31<00:10, 43.04it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27200/27619 [10:32<00:09, 43.04it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27220/27619 [10:32<00:09, 43.03it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27240/27619 [10:32<00:08, 43.03it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27260/27619 [10:33<00:08, 43.03it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27280/27619 [10:33<00:07, 43.03it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27300/27619 [10:34<00:07, 43.04it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27320/27619 [10:34<00:06, 43.04it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27340/27619 [10:35<00:06, 43.04it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27360/27619 [10:35<00:06, 43.04it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27380/27619 [10:36<00:05, 43.04it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27400/27619 [10:36<00:05, 43.04it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27420/27619 [10:37<00:04, 43.04it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27440/27619 [10:37<00:04, 43.04it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27460/27619 [10:38<00:03, 43.04it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27480/27619 [10:38<00:03, 43.04it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27500/27619 [10:38<00:02, 43.04it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27520/27619 [10:39<00:02, 43.05it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27540/27619 [10:39<00:01, 43.05it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27560/27619 [10:40<00:01, 43.05it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27580/27619 [10:40<00:00, 43.05it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27600/27619 [10:41<00:00, 43.05it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [10:41<00:00, 43.05it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [10:41<00:00, 43.05it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │     11.03652572631836     │\n",
            "│          val/nll          │     7.649936676025391     │\n",
            "│          val/ppl          │     2100.512451171875     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "✓ MDLM: 2100.5 (expected ~2100)\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp16/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=16 algo.var_min=false\n",
            "| 26740/27619 [12:17<00:24, 36.25it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26760/27619 [12:18<00:23, 36.25it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26780/27619 [12:18<00:23, 36.25it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26800/27619 [12:19<00:22, 36.25it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26820/27619 [12:19<00:22, 36.25it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26840/27619 [12:20<00:21, 36.25it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26860/27619 [12:20<00:20, 36.25it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26880/27619 [12:21<00:20, 36.25it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26900/27619 [12:21<00:19, 36.25it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26920/27619 [12:22<00:19, 36.26it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26940/27619 [12:23<00:18, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26960/27619 [12:23<00:18, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26980/27619 [12:24<00:17, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27000/27619 [12:24<00:17, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27020/27619 [12:25<00:16, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27040/27619 [12:25<00:15, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27060/27619 [12:26<00:15, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27080/27619 [12:26<00:14, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27100/27619 [12:27<00:14, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27120/27619 [12:28<00:13, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27140/27619 [12:28<00:13, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27160/27619 [12:29<00:12, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27180/27619 [12:29<00:12, 36.25it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27200/27619 [12:30<00:11, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27220/27619 [12:30<00:11, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27240/27619 [12:31<00:10, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27260/27619 [12:31<00:09, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27280/27619 [12:32<00:09, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27300/27619 [12:33<00:08, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27320/27619 [12:33<00:08, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27340/27619 [12:34<00:07, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27360/27619 [12:34<00:07, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27380/27619 [12:35<00:06, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27400/27619 [12:35<00:06, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27420/27619 [12:36<00:05, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27440/27619 [12:36<00:04, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27460/27619 [12:37<00:04, 36.25it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27480/27619 [12:37<00:03, 36.26it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27500/27619 [12:38<00:03, 36.26it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27520/27619 [12:39<00:02, 36.26it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27540/27619 [12:39<00:02, 36.26it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27560/27619 [12:40<00:01, 36.25it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27580/27619 [12:40<00:01, 36.25it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27600/27619 [12:41<00:00, 36.25it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [12:41<00:00, 36.25it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [12:41<00:00, 36.25it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    10.902483940124512     │\n",
            "│          val/nll          │     7.557026386260986     │\n",
            "│          val/ppl          │     1914.14501953125      │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "✓ BD3-LM L'=16: 1914.1 (expected ~1940)\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp8/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=8 algo.var_min=false\n",
            "| 26740/27619 [12:14<00:24, 36.43it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26760/27619 [12:14<00:23, 36.43it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26780/27619 [12:15<00:23, 36.43it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26800/27619 [12:15<00:22, 36.43it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26820/27619 [12:16<00:21, 36.43it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26840/27619 [12:16<00:21, 36.43it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26860/27619 [12:17<00:20, 36.43it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26880/27619 [12:17<00:20, 36.43it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26900/27619 [12:18<00:19, 36.43it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26920/27619 [12:18<00:19, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26940/27619 [12:19<00:18, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26960/27619 [12:20<00:18, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26980/27619 [12:20<00:17, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27000/27619 [12:21<00:16, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27020/27619 [12:21<00:16, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27040/27619 [12:22<00:15, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27060/27619 [12:22<00:15, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27080/27619 [12:23<00:14, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27100/27619 [12:23<00:14, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27120/27619 [12:24<00:13, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27140/27619 [12:24<00:13, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27160/27619 [12:25<00:12, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27180/27619 [12:26<00:12, 36.43it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27200/27619 [12:26<00:11, 36.43it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27220/27619 [12:27<00:10, 36.43it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27240/27619 [12:27<00:10, 36.43it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27260/27619 [12:28<00:09, 36.43it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27280/27619 [12:28<00:09, 36.43it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27300/27619 [12:29<00:08, 36.43it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27320/27619 [12:29<00:08, 36.44it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27340/27619 [12:30<00:07, 36.44it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27360/27619 [12:30<00:07, 36.44it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27380/27619 [12:31<00:06, 36.44it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27400/27619 [12:31<00:06, 36.44it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27420/27619 [12:32<00:05, 36.44it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27440/27619 [12:33<00:04, 36.44it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27460/27619 [12:33<00:04, 36.44it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27480/27619 [12:34<00:03, 36.44it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27500/27619 [12:34<00:03, 36.44it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27520/27619 [12:35<00:02, 36.44it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27540/27619 [12:35<00:02, 36.44it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27560/27619 [12:36<00:01, 36.44it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27580/27619 [12:36<00:01, 36.44it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27600/27619 [12:37<00:00, 36.44it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [12:37<00:00, 36.44it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [12:38<00:00, 36.44it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    10.914432525634766     │\n",
            "│          val/nll          │     7.565308094024658     │\n",
            "│          val/ppl          │    1930.0633544921875     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "✓ BD3-LM L'=8: 1930.1 (expected ~1940)\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=openwebtext-split data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp4/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=4 algo.var_min=false\n",
            "| 26740/27619 [12:16<00:24, 36.32it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26760/27619 [12:16<00:23, 36.32it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26780/27619 [12:17<00:23, 36.32it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26800/27619 [12:17<00:22, 36.32it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26820/27619 [12:18<00:21, 36.32it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26840/27619 [12:18<00:21, 36.32it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26860/27619 [12:19<00:20, 36.32it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26880/27619 [12:20<00:20, 36.32it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26900/27619 [12:20<00:19, 36.32it/s]\n",
            "Validation DataLoader 0:  97%|█████████▋| 26920/27619 [12:21<00:19, 36.32it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26940/27619 [12:21<00:18, 36.32it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26960/27619 [12:22<00:18, 36.32it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 26980/27619 [12:22<00:17, 36.33it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27000/27619 [12:23<00:17, 36.33it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27020/27619 [12:23<00:16, 36.33it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27040/27619 [12:24<00:15, 36.33it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27060/27619 [12:24<00:15, 36.33it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27080/27619 [12:25<00:14, 36.33it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27100/27619 [12:26<00:14, 36.33it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27120/27619 [12:26<00:13, 36.33it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27140/27619 [12:27<00:13, 36.33it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27160/27619 [12:27<00:12, 36.32it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27180/27619 [12:28<00:12, 36.32it/s]\n",
            "Validation DataLoader 0:  98%|█████████▊| 27200/27619 [12:28<00:11, 36.32it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27220/27619 [12:29<00:10, 36.32it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27240/27619 [12:29<00:10, 36.32it/s]\n",
            "Validation DataLoader 0:  99%|█████████▊| 27260/27619 [12:30<00:09, 36.32it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27280/27619 [12:31<00:09, 36.32it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27300/27619 [12:31<00:08, 36.32it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27320/27619 [12:32<00:08, 36.32it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27340/27619 [12:32<00:07, 36.32it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27360/27619 [12:33<00:07, 36.32it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27380/27619 [12:33<00:06, 36.33it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27400/27619 [12:34<00:06, 36.33it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27420/27619 [12:34<00:05, 36.33it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27440/27619 [12:35<00:04, 36.33it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27460/27619 [12:35<00:04, 36.32it/s]\n",
            "Validation DataLoader 0:  99%|█████████▉| 27480/27619 [12:36<00:03, 36.32it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27500/27619 [12:37<00:03, 36.32it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27520/27619 [12:37<00:02, 36.32it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27540/27619 [12:38<00:02, 36.32it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27560/27619 [12:38<00:01, 36.32it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27580/27619 [12:39<00:01, 36.32it/s]\n",
            "Validation DataLoader 0: 100%|█████████▉| 27600/27619 [12:39<00:00, 36.32it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [12:40<00:00, 36.32it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 27619/27619 [12:40<00:00, 36.32it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    10.932023048400879     │\n",
            "│          val/nll          │     7.577500820159912     │\n",
            "│          val/ppl          │    1953.7401123046875     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "✓ BD3-LM L'=4: 1953.7 (expected ~1935)\n",
            "\n",
            "============================================================\n",
            "       Model     OWT_PPL  Expected\n",
            "          AR 2035.504150      2035\n",
            "        SEDD 2120.401855      2120\n",
            "        MDLM 2100.512451      2100\n",
            "BD3-LM L'=16 1914.145020      1940\n",
            " BD3-LM L'=8 1930.063354      1940\n",
            " BD3-LM L'=4 1953.740112      1935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-Shot Evaluation"
      ],
      "metadata": {
        "id": "eval_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# ZERO-SHOT DATASETS\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "ZEROSHOT_DATASETS = [\n",
        "    (\"Wikitext2\", \"wikitext2\"),        # ← FIXED (όχι \"wikitext\")\n",
        "    (\"Wikitext103\", \"wikitext103\"),    # ← επιπλέον option\n",
        "    (\"LM1B\", \"lm1b-gpt2\"),             # ← FIXED (όχι \"lm1b\")\n",
        "    (\"Lambada\", \"lambada\"),\n",
        "]\n",
        "\n",
        "# Models to evaluate\n",
        "EVAL_MODELS = [\n",
        "    (\"AR\", \"ar\", \"AR\", None),\n",
        "    (\"SEDD\", \"sedd\", \"SEDD\", None),\n",
        "    (\"MDLM\", \"mdlm\", \"MDLM\", None),\n",
        "    (\"BD3-LM L'=16\", \"bd3lm\", \"BD3-LM_L16\", 16),\n",
        "    (\"BD3-LM L'=8\", \"bd3lm\", \"BD3-LM_L8\", 8),\n",
        "    (\"BD3-LM L'=4\", \"bd3lm\", \"BD3-LM_L4\", 4),\n",
        "]"
      ],
      "metadata": {
        "id": "define_zeroshot"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run zero-shot evaluation\n",
        "zeroshot_results = []\n",
        "\n",
        "for dataset_name, data_cfg in ZEROSHOT_DATASETS:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ZERO-SHOT: {dataset_name}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for model_name, algo, ckpt_key, block_size in EVAL_MODELS:\n",
        "        ckpt = CHECKPOINTS.get(ckpt_key)\n",
        "        if not ckpt:\n",
        "            print(f\"  ⚠ Skip {model_name}: no checkpoint\")\n",
        "            continue\n",
        "\n",
        "        # Extra overrides for diffusion models\n",
        "        extra = [\"algo.var_min=false\"] if algo != \"ar\" else []\n",
        "\n",
        "        print(f\"\\n→ {model_name}...\")\n",
        "        try:\n",
        "            ppl = eval_zeroshot(algo, ckpt, data_cfg, block_size, extra)\n",
        "            print(f\"  ✓ PPL = {ppl}\")\n",
        "        except Exception as e:\n",
        "            ppl = None\n",
        "            print(f\"  ✗ Error: {str(e)[:100]}\")\n",
        "\n",
        "        zeroshot_results.append({\n",
        "            \"Model\": model_name,\n",
        "            \"Dataset\": dataset_name,\n",
        "            \"PPL\": ppl,\n",
        "        })\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ZERO-SHOT EVALUATION COMPLETE!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "run_zeroshot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b129f4-0d57-465f-f097-061ca64a2827"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ZERO-SHOT: Wikitext2\n",
            "============================================================\n",
            "\n",
            "→ AR...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=ar eval.checkpoint_path=/content/repro_runs/ar_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1\n",
            ".938160: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:53:14.958480: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349194.977794   42544 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349194.983410   42544 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349194.997958   42544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349194.997992   42544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349194.997995   42544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349194.997996   42544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:53:15.002467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:00<00:01, 30.51it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:00<00:00, 42.71it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:01<00:00, 48.96it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:01<00:00, 47.01it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.489519119262695     │\n",
            "│          val/nll          │     7.963927745819092     │\n",
            "│          val/ppl          │     2875.344482421875     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 2875.344482421875\n",
            "\n",
            "→ SEDD...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=sedd eval.checkpoint_path=/content/repro_runs/sedd_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 algo.var_min=false\n",
            ".799528: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:53:45.819927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349225.839976   42839 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349225.845718   42839 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349225.861000   42839 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349225.861031   42839 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349225.861033   42839 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349225.861035   42839 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:53:45.865540: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:00<00:01, 20.06it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:01<00:00, 28.20it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:01<00:00, 32.30it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:01<00:00, 31.77it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.703794479370117     │\n",
            "│          val/nll          │     8.112452507019043     │\n",
            "│          val/ppl          │     3335.748779296875     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 3335.748779296875\n",
            "\n",
            "→ MDLM...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=mdlm eval.checkpoint_path=/content/repro_runs/mdlm_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 algo.var_min=false\n",
            ".883208: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:54:16.901228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349256.920294   43085 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349256.925740   43085 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349256.939554   43085 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349256.939577   43085 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349256.939579   43085 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349256.939581   43085 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:54:16.943827: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:01<00:02, 18.35it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:01<00:00, 25.75it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:01<00:00, 29.52it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:01<00:00, 29.06it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.680761337280273     │\n",
            "│          val/nll          │     8.096487045288086     │\n",
            "│          val/ppl          │     3282.915283203125     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 3282.915283203125\n",
            "\n",
            "→ BD3-LM L'=16...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp16/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=16 algo.var_min=false\n",
            ".867493: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:54:47.886099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349287.905056   43331 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349287.910544   43331 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349287.924642   43331 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349287.924667   43331 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349287.924669   43331 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349287.924671   43331 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:54:47.929076: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:01<00:02, 17.22it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:01<00:00, 23.27it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 26.17it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 25.80it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │     11.6095552444458      │\n",
            "│          val/nll          │     8.047130584716797     │\n",
            "│          val/ppl          │     3124.815673828125     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 3124.815673828125\n",
            "\n",
            "→ BD3-LM L'=8...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp8/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=8 algo.var_min=false\n",
            ".568722: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:55:19.586924: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349319.606019   43581 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349319.611603   43581 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349319.625528   43581 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349319.625562   43581 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349319.625565   43581 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349319.625568   43581 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:55:19.629985: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:01<00:02, 16.58it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:01<00:00, 22.79it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 26.03it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 25.67it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │     11.63381290435791     │\n",
            "│          val/nll          │     8.063944816589355     │\n",
            "│          val/ppl          │     3177.80126953125      │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 3177.80126953125\n",
            "\n",
            "→ BD3-LM L'=4...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp4/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=4 algo.var_min=false\n",
            ".375427: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:55:51.393986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349351.413528   43827 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349351.419148   43827 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349351.433871   43827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349351.433902   43827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349351.433904   43827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349351.433906   43827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:55:51.438366: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:01<00:02, 17.06it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:01<00:00, 23.19it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 26.15it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 25.78it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.618261337280273     │\n",
            "│          val/nll          │     8.053165435791016     │\n",
            "│          val/ppl          │     3143.730712890625     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 3143.730712890625\n",
            "\n",
            "============================================================\n",
            "ZERO-SHOT: Wikitext103\n",
            "============================================================\n",
            "\n",
            "→ AR...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext103 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=ar eval.checkpoint_path=/content/repro_runs/ar_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1\n",
            ".356352: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:56:37.374429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349397.393711   44077 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349397.399254   44077 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349397.413252   44077 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349397.413286   44077 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349397.413289   44077 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349397.413291   44077 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:56:37.417681: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:00<00:01, 27.73it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:01<00:00, 38.69it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:01<00:00, 44.93it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:01<00:00, 43.27it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.489519119262695     │\n",
            "│          val/nll          │     7.963927745819092     │\n",
            "│          val/ppl          │     2875.344482421875     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 2875.344482421875\n",
            "\n",
            "→ SEDD...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext103 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=sedd eval.checkpoint_path=/content/repro_runs/sedd_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 algo.var_min=false\n",
            ".485112: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:57:07.503223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349427.522255   44450 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349427.527767   44450 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349427.541665   44450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349427.541695   44450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349427.541700   44450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349427.541703   44450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:57:07.546042: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:01<00:01, 19.80it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:01<00:00, 27.58it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:01<00:00, 31.46it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:01<00:00, 30.94it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.703794479370117     │\n",
            "│          val/nll          │     8.112452507019043     │\n",
            "│          val/ppl          │     3335.748779296875     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 3335.748779296875\n",
            "\n",
            "→ MDLM...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext103 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=mdlm eval.checkpoint_path=/content/repro_runs/mdlm_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 algo.var_min=false\n",
            ".175502: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:57:38.194089: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349458.213206   44692 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349458.218789   44692 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349458.233428   44692 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349458.233463   44692 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349458.233465   44692 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349458.233467   44692 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:57:38.237931: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:01<00:02, 17.83it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:01<00:00, 24.76it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 28.27it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 27.85it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.680761337280273     │\n",
            "│          val/nll          │     8.096487045288086     │\n",
            "│          val/ppl          │     3282.915283203125     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 3282.915283203125\n",
            "\n",
            "→ BD3-LM L'=16...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext103 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp16/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=16 algo.var_min=false\n",
            ".045295: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:58:09.063205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349489.082147   44938 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349489.087665   44938 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349489.101659   44938 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349489.101691   44938 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349489.101693   44938 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349489.101695   44938 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:58:09.105957: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:01<00:02, 16.89it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:01<00:00, 22.98it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 25.97it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 25.61it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │     11.6095552444458      │\n",
            "│          val/nll          │     8.047130584716797     │\n",
            "│          val/ppl          │     3124.815673828125     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 3124.815673828125\n",
            "\n",
            "→ BD3-LM L'=8...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext103 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp8/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=8 algo.var_min=false\n",
            ".076606: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:58:40.094447: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349520.113464   45184 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349520.118928   45184 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349520.132839   45184 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349520.132875   45184 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349520.132877   45184 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349520.132879   45184 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:58:40.137290: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:01<00:02, 16.86it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:01<00:00, 23.17it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 26.19it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 25.83it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │     11.63381290435791     │\n",
            "│          val/nll          │     8.063944816589355     │\n",
            "│          val/ppl          │     3177.80126953125      │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 3177.80126953125\n",
            "\n",
            "→ BD3-LM L'=4...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=wikitext103 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp4/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=4 algo.var_min=false\n",
            ".369722: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 13:59:11.387697: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769349551.406642   45430 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769349551.412057   45430 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769349551.425833   45430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349551.425860   45430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349551.425863   45430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769349551.425864   45430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 13:59:11.430121: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/58 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  34%|███▍      | 20/58 [00:01<00:02, 16.96it/s]\n",
            "Validation DataLoader 0:  69%|██████▉   | 40/58 [00:01<00:00, 22.97it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 25.86it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 58/58 [00:02<00:00, 25.50it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.618261337280273     │\n",
            "│          val/nll          │     8.053165435791016     │\n",
            "│          val/ppl          │     3143.730712890625     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 3143.730712890625\n",
            "\n",
            "============================================================\n",
            "ZERO-SHOT: LM1B\n",
            "============================================================\n",
            "\n",
            "→ AR...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=ar eval.checkpoint_path=/content/repro_runs/ar_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1\n",
            "      ignore_bos: false                                                       \n",
            "        cross_attn: false                                                       \n",
            "        var_min: false                                                          \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: ar                                                             \n",
            "        mdlm_loss_scale: false                                                  \n",
            "        reweight_loss: false                                                    \n",
            "        w_type: simple                                                          \n",
            "                                                                                \n",
            "[2026-01-25 13:59:34,411][__main__][INFO] - Starting Eval.\n",
            "Loading checkpoint at 800\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-25 13:59:36,491][dataloader][INFO] - Generating new data at: /content/bd3lms/data/lm1b_test_bs1024_wrapped.dat\n",
            "[2026-01-25 13:59:36,491][dataloader][INFO] - streaming=True\n",
            "Error executing job with overrides: ['mode=ppl_eval', 'data=lm1b-gpt2', 'data.cache_dir=/content/bd3lms/data', 'data.streaming=true', 'data.max_test_samples=500', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=ar', 'eval.checkpoint_path=/content/repro_runs/ar_tiny_owt_len1024/checkpoints/last.ckpt', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.num_nodes=1', 'trainer.precision=16-mixed', 'trainer.num_sanity_val_steps=0', 'wandb=null', 'loader.global_batch_size=4', 'loader.eval_global_batch_size=4', 'loader.batch_size=4', 'loader.eval_batch_size=4', 'loader.num_workers=2', 'trainer.accumulate_grad_batches=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 228, in main\n",
            "    _ppl_eval(config, logger, tokenizer)\n",
            "  File \"/content/bd3lms/main.py\", line 142, in _ppl_eval\n",
            "    _, valid_ds = dataloader.get_dataloaders(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 811, in get_dataloaders\n",
            "    valid_set = get_dataset(\n",
            "                ^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 589, in get_dataset\n",
            "    if i < total_skip:\n",
            "       ^^^^^^^^^^^^^^\n",
            "TypeError: '<' not supported between instances of 'int' and 'NoneType'\n",
            "\n",
            "  ✗ Error: Command failed with return code 1\n",
            "\n",
            "→ SEDD...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=sedd eval.checkpoint_path=/content/repro_runs/sedd_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 algo.var_min=false\n",
            "                                                    \n",
            "        cross_attn: false                                                       \n",
            "        var_min: false                                                          \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: analytic                                                       \n",
            "        mdlm_loss_scale: false                                                  \n",
            "        reweight_loss: false                                                    \n",
            "        w_type: simple                                                          \n",
            "                                                                                \n",
            "[2026-01-25 14:01:32,656][__main__][INFO] - Starting Eval.\n",
            "Loading checkpoint at 800\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-25 14:01:34,770][dataloader][INFO] - Generating new data at: /content/bd3lms/data/lm1b_test_bs1024_wrapped.dat\n",
            "[2026-01-25 14:01:34,770][dataloader][INFO] - streaming=True\n",
            "Error executing job with overrides: ['mode=ppl_eval', 'data=lm1b-gpt2', 'data.cache_dir=/content/bd3lms/data', 'data.streaming=true', 'data.max_test_samples=500', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'eval.checkpoint_path=/content/repro_runs/sedd_tiny_owt_len1024/checkpoints/last.ckpt', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.num_nodes=1', 'trainer.precision=16-mixed', 'trainer.num_sanity_val_steps=0', 'wandb=null', 'loader.global_batch_size=4', 'loader.eval_global_batch_size=4', 'loader.batch_size=4', 'loader.eval_batch_size=4', 'loader.num_workers=2', 'trainer.accumulate_grad_batches=1', 'algo.var_min=false']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 228, in main\n",
            "    _ppl_eval(config, logger, tokenizer)\n",
            "  File \"/content/bd3lms/main.py\", line 142, in _ppl_eval\n",
            "    _, valid_ds = dataloader.get_dataloaders(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 811, in get_dataloaders\n",
            "    valid_set = get_dataset(\n",
            "                ^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 589, in get_dataset\n",
            "    if i < total_skip:\n",
            "       ^^^^^^^^^^^^^^\n",
            "TypeError: '<' not supported between instances of 'int' and 'NoneType'\n",
            "\n",
            "  ✗ Error: Command failed with return code 1\n",
            "\n",
            "→ MDLM...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=mdlm eval.checkpoint_path=/content/repro_runs/mdlm_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 algo.var_min=false\n",
            "                                                    \n",
            "        cross_attn: false                                                       \n",
            "        var_min: false                                                          \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "        reweight_loss: false                                                    \n",
            "        w_type: simple                                                          \n",
            "                                                                                \n",
            "[2026-01-25 14:03:30,153][__main__][INFO] - Starting Eval.\n",
            "Loading checkpoint at 800\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-25 14:03:32,251][dataloader][INFO] - Generating new data at: /content/bd3lms/data/lm1b_test_bs1024_wrapped.dat\n",
            "[2026-01-25 14:03:32,251][dataloader][INFO] - streaming=True\n",
            "Error executing job with overrides: ['mode=ppl_eval', 'data=lm1b-gpt2', 'data.cache_dir=/content/bd3lms/data', 'data.streaming=true', 'data.max_test_samples=500', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=mdlm', 'eval.checkpoint_path=/content/repro_runs/mdlm_tiny_owt_len1024/checkpoints/last.ckpt', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.num_nodes=1', 'trainer.precision=16-mixed', 'trainer.num_sanity_val_steps=0', 'wandb=null', 'loader.global_batch_size=4', 'loader.eval_global_batch_size=4', 'loader.batch_size=4', 'loader.eval_batch_size=4', 'loader.num_workers=2', 'trainer.accumulate_grad_batches=1', 'algo.var_min=false']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 228, in main\n",
            "    _ppl_eval(config, logger, tokenizer)\n",
            "  File \"/content/bd3lms/main.py\", line 142, in _ppl_eval\n",
            "    _, valid_ds = dataloader.get_dataloaders(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 811, in get_dataloaders\n",
            "    valid_set = get_dataset(\n",
            "                ^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 589, in get_dataset\n",
            "    if i < total_skip:\n",
            "       ^^^^^^^^^^^^^^\n",
            "TypeError: '<' not supported between instances of 'int' and 'NoneType'\n",
            "\n",
            "  ✗ Error: Command failed with return code 1\n",
            "\n",
            "→ BD3-LM L'=16...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp16/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=16 algo.var_min=false\n",
            "    \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "        reweight_loss: false                                                    \n",
            "        w_type: simple                                                          \n",
            "                                                                                \n",
            "[2026-01-25 14:06:24,498][__main__][INFO] - Starting Eval.\n",
            "Loading checkpoint at 800\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['sampling_eps_min', 'sampling_eps_max']\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-25 14:06:26,643][dataloader][INFO] - Generating new data at: /content/bd3lms/data/lm1b_test_bs1024_wrapped.dat\n",
            "[2026-01-25 14:06:26,643][dataloader][INFO] - streaming=True\n",
            "Error executing job with overrides: ['mode=ppl_eval', 'data=lm1b-gpt2', 'data.cache_dir=/content/bd3lms/data', 'data.streaming=true', 'data.max_test_samples=500', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=bd3lm', 'eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp16/checkpoints/last.ckpt', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.num_nodes=1', 'trainer.precision=16-mixed', 'trainer.num_sanity_val_steps=0', 'wandb=null', 'loader.global_batch_size=4', 'loader.eval_global_batch_size=4', 'loader.batch_size=4', 'loader.eval_batch_size=4', 'loader.num_workers=2', 'trainer.accumulate_grad_batches=1', 'block_size=16', 'algo.var_min=false']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 228, in main\n",
            "    _ppl_eval(config, logger, tokenizer)\n",
            "  File \"/content/bd3lms/main.py\", line 142, in _ppl_eval\n",
            "    _, valid_ds = dataloader.get_dataloaders(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 811, in get_dataloaders\n",
            "    valid_set = get_dataset(\n",
            "                ^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 589, in get_dataset\n",
            "    if i < total_skip:\n",
            "       ^^^^^^^^^^^^^^\n",
            "TypeError: '<' not supported between instances of 'int' and 'NoneType'\n",
            "\n",
            "  ✗ Error: Command failed with return code 1\n",
            "\n",
            "→ BD3-LM L'=8...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp8/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=8 algo.var_min=false\n",
            "      \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "        reweight_loss: false                                                    \n",
            "        w_type: simple                                                          \n",
            "                                                                                \n",
            "[2026-01-25 14:08:21,080][__main__][INFO] - Starting Eval.\n",
            "Loading checkpoint at 800\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['sampling_eps_min', 'sampling_eps_max']\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-25 14:08:23,163][dataloader][INFO] - Generating new data at: /content/bd3lms/data/lm1b_test_bs1024_wrapped.dat\n",
            "[2026-01-25 14:08:23,163][dataloader][INFO] - streaming=True\n",
            "Error executing job with overrides: ['mode=ppl_eval', 'data=lm1b-gpt2', 'data.cache_dir=/content/bd3lms/data', 'data.streaming=true', 'data.max_test_samples=500', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=bd3lm', 'eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp8/checkpoints/last.ckpt', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.num_nodes=1', 'trainer.precision=16-mixed', 'trainer.num_sanity_val_steps=0', 'wandb=null', 'loader.global_batch_size=4', 'loader.eval_global_batch_size=4', 'loader.batch_size=4', 'loader.eval_batch_size=4', 'loader.num_workers=2', 'trainer.accumulate_grad_batches=1', 'block_size=8', 'algo.var_min=false']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 228, in main\n",
            "    _ppl_eval(config, logger, tokenizer)\n",
            "  File \"/content/bd3lms/main.py\", line 142, in _ppl_eval\n",
            "    _, valid_ds = dataloader.get_dataloaders(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 811, in get_dataloaders\n",
            "    valid_set = get_dataset(\n",
            "                ^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 589, in get_dataset\n",
            "    if i < total_skip:\n",
            "       ^^^^^^^^^^^^^^\n",
            "TypeError: '<' not supported between instances of 'int' and 'NoneType'\n",
            "\n",
            "  ✗ Error: Command failed with return code 1\n",
            "\n",
            "→ BD3-LM L'=4...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp4/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=4 algo.var_min=false\n",
            "      \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "        reweight_loss: false                                                    \n",
            "        w_type: simple                                                          \n",
            "                                                                                \n",
            "[2026-01-25 14:10:24,431][__main__][INFO] - Starting Eval.\n",
            "Loading checkpoint at 800\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['sampling_eps_min', 'sampling_eps_max']\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-25 14:10:26,535][dataloader][INFO] - Generating new data at: /content/bd3lms/data/lm1b_test_bs1024_wrapped.dat\n",
            "[2026-01-25 14:10:26,535][dataloader][INFO] - streaming=True\n",
            "Error executing job with overrides: ['mode=ppl_eval', 'data=lm1b-gpt2', 'data.cache_dir=/content/bd3lms/data', 'data.streaming=true', 'data.max_test_samples=500', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=bd3lm', 'eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp4/checkpoints/last.ckpt', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.num_nodes=1', 'trainer.precision=16-mixed', 'trainer.num_sanity_val_steps=0', 'wandb=null', 'loader.global_batch_size=4', 'loader.eval_global_batch_size=4', 'loader.batch_size=4', 'loader.eval_batch_size=4', 'loader.num_workers=2', 'trainer.accumulate_grad_batches=1', 'block_size=4', 'algo.var_min=false']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 228, in main\n",
            "    _ppl_eval(config, logger, tokenizer)\n",
            "  File \"/content/bd3lms/main.py\", line 142, in _ppl_eval\n",
            "    _, valid_ds = dataloader.get_dataloaders(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 811, in get_dataloaders\n",
            "    valid_set = get_dataset(\n",
            "                ^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/dataloader.py\", line 589, in get_dataset\n",
            "    if i < total_skip:\n",
            "       ^^^^^^^^^^^^^^\n",
            "TypeError: '<' not supported between instances of 'int' and 'NoneType'\n",
            "\n",
            "  ✗ Error: Command failed with return code 1\n",
            "\n",
            "============================================================\n",
            "ZERO-SHOT: Lambada\n",
            "============================================================\n",
            "\n",
            "→ AR...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lambada data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=ar eval.checkpoint_path=/content/repro_runs/ar_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1\n",
            "ronment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 14:12:28.544123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769350348.563907   49063 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769350348.569610   49063 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769350348.584921   49063 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350348.584956   49063 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350348.584960   49063 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350348.584962   49063 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 14:12:28.589780: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  19%|█▉        | 20/105 [00:00<00:02, 29.55it/s]\n",
            "Validation DataLoader 0:  38%|███▊      | 40/105 [00:00<00:01, 41.23it/s]\n",
            "Validation DataLoader 0:  57%|█████▋    | 60/105 [00:01<00:00, 47.40it/s]\n",
            "Validation DataLoader 0:  76%|███████▌  | 80/105 [00:01<00:00, 51.10it/s]\n",
            "Validation DataLoader 0:  95%|█████████▌| 100/105 [00:01<00:00, 53.68it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:01<00:00, 54.29it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:01<00:00, 52.92it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    10.598637580871582     │\n",
            "│          val/nll          │     7.346415996551514     │\n",
            "│          val/ppl          │    1550.6290283203125     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 1550.6290283203125\n",
            "\n",
            "→ SEDD...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lambada data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=sedd eval.checkpoint_path=/content/repro_runs/sedd_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 algo.var_min=false\n",
            "ronment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 14:12:57.535298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769350377.554889   49294 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769350377.560588   49294 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769350377.574553   49294 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350377.574580   49294 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350377.574583   49294 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350377.574584   49294 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 14:12:57.578910: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  19%|█▉        | 20/105 [00:00<00:04, 20.09it/s]\n",
            "Validation DataLoader 0:  38%|███▊      | 40/105 [00:01<00:02, 28.02it/s]\n",
            "Validation DataLoader 0:  57%|█████▋    | 60/105 [00:01<00:01, 32.20it/s]\n",
            "Validation DataLoader 0:  76%|███████▌  | 80/105 [00:02<00:00, 34.83it/s]\n",
            "Validation DataLoader 0:  95%|█████████▌| 100/105 [00:02<00:00, 36.63it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:02<00:00, 36.87it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:02<00:00, 36.47it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    10.609284400939941     │\n",
            "│          val/nll          │     7.353795528411865     │\n",
            "│          val/ppl          │    1562.1143798828125     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 1562.1143798828125\n",
            "\n",
            "→ MDLM...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lambada data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=mdlm eval.checkpoint_path=/content/repro_runs/mdlm_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 algo.var_min=false\n",
            "ronment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 14:13:27.472843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769350407.491512   49529 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769350407.496929   49529 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769350407.510519   49529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350407.510541   49529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350407.510543   49529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350407.510545   49529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 14:13:27.514897: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  19%|█▉        | 20/105 [00:01<00:04, 17.88it/s]\n",
            "Validation DataLoader 0:  38%|███▊      | 40/105 [00:01<00:02, 25.21it/s]\n",
            "Validation DataLoader 0:  57%|█████▋    | 60/105 [00:02<00:01, 29.17it/s]\n",
            "Validation DataLoader 0:  76%|███████▌  | 80/105 [00:02<00:00, 31.62it/s]\n",
            "Validation DataLoader 0:  95%|█████████▌| 100/105 [00:02<00:00, 33.46it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:03<00:00, 33.74it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:03<00:00, 33.40it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    10.603543281555176     │\n",
            "│          val/nll          │     7.34981632232666      │\n",
            "│          val/ppl          │    1555.9107666015625     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 1555.9107666015625\n",
            "\n",
            "→ BD3-LM L'=16...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lambada data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp16/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=16 algo.var_min=false\n",
            "ronment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 14:13:58.040541: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769350438.060052   49764 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769350438.065724   49764 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769350438.080389   49764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350438.080422   49764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350438.080425   49764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350438.080427   49764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 14:13:58.084815: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  19%|█▉        | 20/105 [00:01<00:04, 17.32it/s]\n",
            "Validation DataLoader 0:  38%|███▊      | 40/105 [00:01<00:02, 23.60it/s]\n",
            "Validation DataLoader 0:  57%|█████▋    | 60/105 [00:02<00:01, 26.71it/s]\n",
            "Validation DataLoader 0:  76%|███████▌  | 80/105 [00:02<00:00, 28.57it/s]\n",
            "Validation DataLoader 0:  95%|█████████▌| 100/105 [00:03<00:00, 29.77it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:03<00:00, 29.98it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:03<00:00, 29.70it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    10.466423988342285     │\n",
            "│          val/nll          │     7.254772186279297     │\n",
            "│          val/ppl          │    1414.8406982421875     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 1414.8406982421875\n",
            "\n",
            "→ BD3-LM L'=8...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lambada data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp8/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=8 algo.var_min=false\n",
            "ronment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 14:14:29.249098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769350469.268449   50003 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769350469.273999   50003 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769350469.287956   50003 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350469.287981   50003 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350469.287984   50003 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350469.287986   50003 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 14:14:29.292334: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  19%|█▉        | 20/105 [00:01<00:04, 17.22it/s]\n",
            "Validation DataLoader 0:  38%|███▊      | 40/105 [00:01<00:02, 23.34it/s]\n",
            "Validation DataLoader 0:  57%|█████▋    | 60/105 [00:02<00:01, 26.50it/s]\n",
            "Validation DataLoader 0:  76%|███████▌  | 80/105 [00:02<00:00, 28.37it/s]\n",
            "Validation DataLoader 0:  95%|█████████▌| 100/105 [00:03<00:00, 29.64it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:03<00:00, 29.89it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:03<00:00, 29.62it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    10.488348007202148     │\n",
            "│          val/nll          │    7.2699689865112305     │\n",
            "│          val/ppl          │      1436.505859375       │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 1436.505859375\n",
            "\n",
            "→ BD3-LM L'=4...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lambada data.cache_dir=/content/bd3lms/data data.streaming=true data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp4/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=4 loader.eval_global_batch_size=4 loader.batch_size=4 loader.eval_batch_size=4 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=4 algo.var_min=false\n",
            "ronment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 14:15:00.291224: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769350500.310060   50242 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769350500.315564   50242 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769350500.329220   50242 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350500.329242   50242 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350500.329245   50242 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769350500.329246   50242 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 14:15:00.333516: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/105 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:  19%|█▉        | 20/105 [00:01<00:05, 16.80it/s]\n",
            "Validation DataLoader 0:  38%|███▊      | 40/105 [00:01<00:02, 22.74it/s]\n",
            "Validation DataLoader 0:  57%|█████▋    | 60/105 [00:02<00:01, 25.86it/s]\n",
            "Validation DataLoader 0:  76%|███████▌  | 80/105 [00:02<00:00, 28.09it/s]\n",
            "Validation DataLoader 0:  95%|█████████▌| 100/105 [00:03<00:00, 29.49it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:03<00:00, 29.73it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 105/105 [00:03<00:00, 29.47it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    10.489388465881348     │\n",
            "│          val/nll          │     7.270689964294434     │\n",
            "│          val/ppl          │      1437.5419921875      │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 1437.5419921875\n",
            "\n",
            "============================================================\n",
            "ZERO-SHOT EVALUATION COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format results as Table 5\n",
        "df = pd.DataFrame(zeroshot_results)\n",
        "pivot = df.pivot(index=\"Model\", columns=\"Dataset\", values=\"PPL\")\n",
        "\n",
        "# Reorder\n",
        "model_order = [\"AR\", \"SEDD\", \"MDLM\", \"BD3-LM L'=16\", \"BD3-LM L'=8\", \"BD3-LM L'=4\"]\n",
        "pivot = pivot.reindex([m for m in model_order if m in pivot.index])\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TABLE 5: Zero-Shot Validation Perplexities\")\n",
        "print(\"=\"*70)\n",
        "print(pivot.to_string())"
      ],
      "metadata": {
        "id": "format_results",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6fae7c1-c374-45a1-ee23-057373960a3f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TABLE 5: Zero-Shot Validation Perplexities\n",
            "======================================================================\n",
            "Dataset       LM1B      Lambada  Wikitext103    Wikitext2\n",
            "Model                                                    \n",
            "AR             NaN  1550.629028  2875.344482  2875.344482\n",
            "SEDD           NaN  1562.114380  3335.748779  3335.748779\n",
            "MDLM           NaN  1555.910767  3282.915283  3282.915283\n",
            "BD3-LM L'=16   NaN  1414.840698  3124.815674  3124.815674\n",
            "BD3-LM L'=8    NaN  1436.505859  3177.801270  3177.801270\n",
            "BD3-LM L'=4    NaN  1437.541992  3143.730713  3143.730713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paper reference\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PAPER VALUES (Table 5):\")\n",
        "print(\"=\"*70)\n",
        "paper_df = pd.DataFrame({\n",
        "    \"Model\": [\"AR\", \"SEDD\", \"MDLM\", \"BD3-LM L'=4\"],\n",
        "    \"PTB\": [81.07, 96.33, 90.96, 96.81],\n",
        "    \"Wikitext\": [25.32, 35.98, 33.22, 31.31],\n",
        "    \"LM1B\": [51.14, 68.14, 64.94, 60.88],\n",
        "    \"Lambada\": [52.13, 48.93, 48.29, 50.03],\n",
        "}).set_index(\"Model\")\n",
        "print(paper_df.to_string())\n",
        "print(\"\\nExpected: BD3-LM < MDLM < SEDD for diffusion models\")"
      ],
      "metadata": {
        "id": "paper_ref",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddafc0b6-c817-429d-b50b-0f1909ef9901"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PAPER VALUES (Table 5):\n",
            "======================================================================\n",
            "               PTB  Wikitext   LM1B  Lambada\n",
            "Model                                       \n",
            "AR           81.07     25.32  51.14    52.13\n",
            "SEDD         96.33     35.98  68.14    48.93\n",
            "MDLM         90.96     33.22  64.94    48.29\n",
            "BD3-LM L'=4  96.81     31.31  60.88    50.03\n",
            "\n",
            "Expected: BD3-LM < MDLM < SEDD for diffusion models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check actual keys first\n",
        "print(\"Available CHECKPOINTS keys:\", list(CHECKPOINTS.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D37LcYS3m5x-",
        "outputId": "1f1d23d0-fa79-41cc-ff6d-e7db62ac3101"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available CHECKPOINTS keys: ['AR', 'SEDD', 'MDLM', 'BD3-LM_L16', 'BD3-LM_L8', 'BD3-LM_L4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete self-contained test for LM1B\n",
        "DATA_DIR = \"/content/bd3lms/data\"\n",
        "\n",
        "# Try lm1b-gpt2 WITHOUT streaming but WITH max_test_samples\n",
        "def eval_zeroshot_lm1b_gpt2(algo, checkpoint_path, block_size=None):\n",
        "    \"\"\"LM1B with GPT2 tokenizer, no streaming, limited samples.\"\"\"\n",
        "    overrides = [\n",
        "        f\"mode=ppl_eval\",\n",
        "        f\"data=lm1b-gpt2\",\n",
        "        f\"data.cache_dir={DATA_DIR}\",\n",
        "        f\"data.streaming=false\",\n",
        "        f\"data.max_test_samples=500\",    # ← Keep this\n",
        "        f\"model=tiny\",\n",
        "        f\"model.length=1024\",\n",
        "        f\"model.attn_backend=sdpa\",\n",
        "        f\"algo={algo}\",\n",
        "        f\"eval.checkpoint_path={checkpoint_path}\",\n",
        "        \"trainer.accelerator=gpu\",\n",
        "        \"trainer.devices=1\",\n",
        "        \"wandb=null\",\n",
        "        \"loader.eval_batch_size=4\",\n",
        "    ]\n",
        "\n",
        "    if algo in [\"sedd\", \"mdlm\", \"bd3lm\"]:\n",
        "        overrides.append(\"algo.var_min=false\")\n",
        "    if block_size:\n",
        "        overrides.append(f\"block_size={block_size}\")\n",
        "\n",
        "    try:\n",
        "        output = run_main(overrides, timeout=1800)\n",
        "        return extract_val_ppl(output)\n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test AR only first\n",
        "print(\"Testing LM1B-GPT2 (no streaming, 500 samples)...\")\n",
        "ppl = eval_zeroshot_lm1b_gpt2(\"ar\", CHECKPOINTS['AR'])\n",
        "print(f\"AR PPL: {ppl}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNR2X2mNnkSX",
        "outputId": "209ab7e3-d07b-4326-f3a7-589cba469e91"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing LM1B-GPT2 (no streaming, 500 samples)...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=false data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=ar eval.checkpoint_path=/content/repro_runs/ar_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 wandb=null loader.eval_batch_size=4\n",
            "ore details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-25 15:02:37.720109: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 15:02:37.741091: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769353357.762420   58981 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769353357.768546   58981 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769353357.784368   58981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353357.784389   58981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353357.784392   58981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353357.784393   58981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 15:02:37.789174: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  7.27it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  6.53it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.221715927124023     │\n",
            "│          val/nll          │     7.778300762176514     │\n",
            "│          val/ppl          │     2388.21337890625      │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "AR PPL: 2388.21337890625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# FULL LM1B EVALUATION (no streaming)\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ZERO-SHOT: LM1B (no streaming)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "lm1b_results = {\"AR\": 2388.21}  # Already have this!\n",
        "\n",
        "for model_name, algo, ckpt_key, block_size in [\n",
        "    # (\"AR\", \"ar\", \"AR\", None),  # Already done!\n",
        "    (\"SEDD\", \"sedd\", \"SEDD\", None),\n",
        "    (\"MDLM\", \"mdlm\", \"MDLM\", None),\n",
        "    (\"BD3-LM L'=16\", \"bd3lm\", \"BD3-LM_L16\", 16),\n",
        "    (\"BD3-LM L'=8\", \"bd3lm\", \"BD3-LM_L8\", 8),\n",
        "    (\"BD3-LM L'=4\", \"bd3lm\", \"BD3-LM_L4\", 4),\n",
        "]:\n",
        "    print(f\"\\n→ {model_name}...\")\n",
        "    ppl = eval_zeroshot_lm1b_gpt2(algo, CHECKPOINTS[ckpt_key], block_size=block_size)\n",
        "    lm1b_results[model_name] = ppl\n",
        "    if ppl:\n",
        "        print(f\"  ✓ PPL = {ppl}\")\n",
        "    else:\n",
        "        print(f\"  ✗ Failed\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LM1B Results Summary:\")\n",
        "print(\"=\"*60)\n",
        "for model, ppl in lm1b_results.items():\n",
        "    print(f\"{model:>15}: {ppl}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8jBapdKtaYK",
        "outputId": "33454523-ccd9-4f60-a821-789254737b0e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ZERO-SHOT: LM1B (no streaming)\n",
            "============================================================\n",
            "\n",
            "→ SEDD...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=false data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=sedd eval.checkpoint_path=/content/repro_runs/sedd_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 wandb=null loader.eval_batch_size=4 algo.var_min=false\n",
            "ore details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-25 15:11:38.748023: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 15:11:38.766890: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769353898.785906   64762 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769353898.791525   64762 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769353898.806229   64762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353898.806251   64762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353898.806254   64762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353898.806256   64762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 15:11:38.810694: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  5.05it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.80it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.421086311340332     │\n",
            "│          val/nll          │     7.916493892669678     │\n",
            "│          val/ppl          │     2742.139892578125     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 2742.139892578125\n",
            "\n",
            "→ MDLM...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=false data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=mdlm eval.checkpoint_path=/content/repro_runs/mdlm_tiny_owt_len1024/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 wandb=null loader.eval_batch_size=4 algo.var_min=false\n",
            "ore details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-25 15:12:01.743370: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 15:12:01.761500: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769353921.780223   64941 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769353921.785690   64941 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769353921.799532   64941 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353921.799552   64941 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353921.799555   64941 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353921.799557   64941 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 15:12:01.803744: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.56it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.37it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.410408973693848     │\n",
            "│          val/nll          │     7.909092903137207     │\n",
            "│          val/ppl          │     2721.92041015625      │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 2721.92041015625\n",
            "\n",
            "→ BD3-LM L'=16...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=false data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp16/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 wandb=null loader.eval_batch_size=4 algo.var_min=false block_size=16\n",
            "ore details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-25 15:12:24.604864: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 15:12:24.623407: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769353944.642208   65124 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769353944.647766   65124 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769353944.661698   65124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353944.661719   65124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353944.661721   65124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353944.661723   65124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 15:12:24.665862: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.44it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.26it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.094006538391113     │\n",
            "│          val/nll          │     7.689779758453369     │\n",
            "│          val/ppl          │     2185.89306640625      │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 2185.89306640625\n",
            "\n",
            "→ BD3-LM L'=8...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=false data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp8/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 wandb=null loader.eval_batch_size=4 algo.var_min=false block_size=8\n",
            "ore details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-25 15:12:47.634325: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 15:12:47.652595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769353967.671642   65309 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769353967.677224   65309 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769353967.690968   65309 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353967.690991   65309 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353967.690994   65309 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353967.690996   65309 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 15:12:47.695359: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.38it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.19it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │    11.105990409851074     │\n",
            "│          val/nll          │     7.698086261749268     │\n",
            "│          val/ppl          │     2204.125732421875     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 2204.125732421875\n",
            "\n",
            "→ BD3-LM L'=4...\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=ppl_eval data=lm1b-gpt2 data.cache_dir=/content/bd3lms/data data.streaming=false data.max_test_samples=500 model=tiny model.length=1024 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/content/repro_runs/bd3lm_finetune_owt_Lp4/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 wandb=null loader.eval_batch_size=4 algo.var_min=false block_size=4\n",
            "ore details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-25 15:13:10.707134: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-25 15:13:10.725093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769353990.743667   65490 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769353990.749086   65490 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769353990.762809   65490 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353990.762830   65490 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353990.762832   65490 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769353990.762834   65490 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-25 15:13:10.767117: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.25it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.08it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃      Validate metric      ┃       DataLoader 0        ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│          val/bpd          │     11.10080337524414     │\n",
            "│          val/nll          │     7.694490432739258     │\n",
            "│          val/ppl          │     2196.21435546875      │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "  ✓ PPL = 2196.21435546875\n",
            "\n",
            "============================================================\n",
            "LM1B Results Summary:\n",
            "============================================================\n",
            "             AR: 2388.21\n",
            "           SEDD: 2742.139892578125\n",
            "           MDLM: 2721.92041015625\n",
            "   BD3-LM L'=16: 2185.89306640625\n",
            "    BD3-LM L'=8: 2204.125732421875\n",
            "    BD3-LM L'=4: 2196.21435546875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v0Z3aCCRDwUv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}