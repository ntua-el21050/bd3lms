{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef238998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def run_main(overrides, timeout=None):\n",
    "    \"\"\"Run `python -u main.py ...` and return combined stdout/stderr text.\"\"\"\n",
    "    env = dict(os.environ)\n",
    "    env.setdefault(\"HYDRA_FULL_ERROR\", \"1\")\n",
    "    cmd = [sys.executable, \"-u\", \"./main.py\", *overrides]\n",
    "    print(\"\\n$\", \" \".join(cmd))\n",
    "    proc = subprocess.run(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        timeout=timeout,\n",
    "        check=False,\n",
    "        env=env,\n",
    "    )\n",
    "    print(proc.stdout[-4000:])  # tail for quick visibility\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError(f\"Command failed with return code {proc.returncode}\")\n",
    "    return proc.stdout\n",
    "\n",
    "_METRIC_PATTERNS = [\n",
    "    # Key: value (some loggers print this)\n",
    "    re.compile(r\"val/ppl\\s*[:=]\\s*([0-9]+(?:\\.[0-9]+)?(?:e[+-]?\\d+)?)\", re.IGNORECASE),\n",
    "    re.compile(r\"'val/ppl'\\s*:\\s*([0-9]+(?:\\.[0-9]+)?(?:e[+-]?\\d+)?)\", re.IGNORECASE),\n",
    "\n",
    "    # Lightning \"rich\" table row (note the unicode box character │)\n",
    "    re.compile(r\"val/ppl\\s*[│|]\\s*([0-9]+(?:\\.[0-9]+)?(?:e[+-]?\\d+)?)\", re.IGNORECASE),\n",
    "]\n",
    "\n",
    "# def extract_val_ppl(log_text: str):\n",
    "#     # First try line-based parse from the end (most reliable for tables)\n",
    "#     for line in reversed(log_text.splitlines()):\n",
    "#         if \"val/ppl\" in line.lower():\n",
    "#             m = re.search(r\"val/ppl.*?([0-9]+(?:\\.[0-9]+)?(?:e[+-]?\\d+)?)\", line, re.IGNORECASE)\n",
    "#             if m:\n",
    "#                 return float(m.group(1))\n",
    "\n",
    "#     # Fallback: scan entire text with known patterns\n",
    "#     hits = []\n",
    "#     for pat in _METRIC_PATTERNS:\n",
    "#         hits.extend(pat.findall(log_text))\n",
    "#     return float(hits[-1]) if hits else None\n",
    "\n",
    "def strip_ansi(text):\n",
    "    \"\"\"Αφαιρεί τους κρυφούς χαρακτήρες χρώματος/μορφοποίησης (ANSI codes).\"\"\"\n",
    "    ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
    "    return ansi_escape.sub('', text)\n",
    "\n",
    "def extract_val_ppl(log_text: str):\n",
    "    # 1. Καθαρίζουμε το κείμενο από χρώματα και ειδικούς χαρακτήρες\n",
    "    clean_text = strip_ansi(log_text)\n",
    "    \n",
    "    # 2. Ψάχνουμε από το τέλος προς την αρχή (για να βρούμε το τελικό αποτέλεσμα)\n",
    "    for line in reversed(clean_text.splitlines()):\n",
    "        # Εντοπισμός της γραμμής που περιέχει το metric\n",
    "        if \"val/ppl\" in line.lower():\n",
    "            # Ψάχνουμε για τον αριθμό (float) που ακολουθεί το \"val/ppl\"\n",
    "            # Το .*? επιτρέπει να υπάρχουν οσοιδήποτε χαρακτήρες (π.χ. │ ή κενά) ενδιάμεσα\n",
    "            m = re.search(r\"val/ppl.*?([0-9]+\\.[0-9]+(?:e[+-]?\\d+)?)\", line, re.IGNORECASE)\n",
    "            if m:\n",
    "                return float(m.group(1))\n",
    "\n",
    "    # Fallback σε περίπτωση που δεν βρεθεί στη γραμμική σάρωση\n",
    "    print(\"Warning: Could not parse ppl from line, trying patterns...\")\n",
    "    return 0.0\n",
    "\n",
    "def _small_loader_overrides(batch_size=8, num_workers=2):\n",
    "    \"\"\"Overrides needed to avoid huge default batch sizes on Colab.\"\"\"\n",
    "    return [\n",
    "        f\"loader.global_batch_size={batch_size}\",\n",
    "        f\"loader.eval_global_batch_size={batch_size}\",\n",
    "        f\"loader.batch_size={batch_size}\",\n",
    "        f\"loader.eval_batch_size={batch_size}\",\n",
    "        f\"loader.num_workers={num_workers}\",\n",
    "        \"trainer.accumulate_grad_batches=1\",\n",
    "    ]\n",
    "\n",
    "def train_run(run_name, algo, block_size=None, from_pretrained=None, max_steps=800, extra_overrides=None):\n",
    "    \"\"\"Train a model (optionally from a base checkpoint) and return the last.ckpt path.\"\"\"\n",
    "    save_dir = (Path(\"../repro_runs\") / run_name).resolve()\n",
    "    #save_dir = Path(\"../repro_runs\") / run_name\n",
    "    if save_dir.exists():\n",
    "        shutil.rmtree(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    overrides = [\n",
    "        \"mode=train\",\n",
    "        \"data=lm1b-wrap\",\n",
    "        \"data.cache_dir=./data\",\n",
    "        \"data.streaming=true\",\n",
    "        \"data.max_train_samples=5000\",\n",
    "        # For LM1B, validation uses the 'test' split in this codebase\n",
    "        \"model=tiny\",\n",
    "        \"model.length=128\",\n",
    "        \"model.attn_backend=sdpa\",\n",
    "        f\"algo={algo}\",\n",
    "        \"trainer.accelerator=gpu\",\n",
    "        \"trainer.devices=1\",\n",
    "        \"trainer.num_nodes=1\",\n",
    "        \"trainer.precision=16-mixed\",\n",
    "        \"trainer.num_sanity_val_steps=0\",\n",
    "        \"trainer.log_every_n_steps=10\",\n",
    "        \"trainer.val_check_interval=50\",\n",
    "        f\"trainer.max_steps={max_steps}\",\n",
    "        \"data.max_valid_samples=100\",\n",
    "        \"data.max_test_samples=100\",\n",
    "        f\"checkpointing.save_dir={str(save_dir)}\",\n",
    "        \"checkpointing.resume_from_ckpt=false\",\n",
    "        \"wandb=null\",\n",
    "    ]\n",
    "    overrides.extend(_small_loader_overrides(batch_size=8, num_workers=2))\n",
    "    if block_size is not None:\n",
    "        overrides.append(f\"block_size={block_size}\")\n",
    "    if from_pretrained is not None:\n",
    "        overrides.append(f\"training.from_pretrained={Path(from_pretrained).resolve()}\")\n",
    "    if extra_overrides:\n",
    "        overrides.extend(extra_overrides)\n",
    "\n",
    "    _ = run_main(overrides)\n",
    "    ckpt = save_dir / \"checkpoints\" / \"last.ckpt\"\n",
    "    if not ckpt.exists():\n",
    "        raise FileNotFoundError(f\"Expected checkpoint not found: {ckpt}\")\n",
    "    return str(ckpt)\n",
    "\n",
    "def eval_run(algo, checkpoint_path, block_size=None, extra_overrides=None):\n",
    "    \"\"\"Evaluate perplexity (val/ppl) for a given checkpoint.\"\"\"\n",
    "    overrides = [\n",
    "        \"mode=ppl_eval\",\n",
    "        \"data=lm1b-wrap\",\n",
    "        \"data.cache_dir=./data\",\n",
    "        \"data.streaming=true\",\n",
    "        # For LM1B, `get_dataloaders` maps validation to the 'test' split\n",
    "        \"data.max_test_samples=1000\",\n",
    "        \"model=tiny\",\n",
    "        \"model.length=128\",\n",
    "        \"model.attn_backend=sdpa\",\n",
    "        f\"algo={algo}\",\n",
    "        f\"eval.checkpoint_path={checkpoint_path}\",\n",
    "        \"trainer.accelerator=gpu\",\n",
    "        \"trainer.devices=1\",\n",
    "        \"trainer.num_nodes=1\",\n",
    "        \"trainer.precision=16-mixed\",\n",
    "        \"trainer.num_sanity_val_steps=0\",\n",
    "        \"wandb=null\",\n",
    "    ]\n",
    "    overrides.extend(_small_loader_overrides(batch_size=8, num_workers=2))\n",
    "    if block_size is not None:\n",
    "        overrides.append(f\"block_size={block_size}\")\n",
    "    if extra_overrides:\n",
    "        overrides.extend(extra_overrides)\n",
    "\n",
    "    log_text = run_main(overrides)\n",
    "    ppl = extract_val_ppl(log_text)\n",
    "    if ppl is None:\n",
    "        raise ValueError(\"Could not parse val/ppl from output. Try increasing the log tail or printing full logs.\")\n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f0d35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$ /home/orion/.venvs/ai/bin/python -u ./main.py mode=train data=lm1b-wrap data.cache_dir=./data data.streaming=true data.max_train_samples=5000 model=tiny model.length=128 model.attn_backend=sdpa algo=bd3lm trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 trainer.log_every_n_steps=10 trainer.val_check_interval=50 trainer.max_steps=800 data.max_valid_samples=100 data.max_test_samples=100 checkpointing.save_dir=/home/orion/Desktop/ntua/semester9/pattrec/repro_runs/bd3lm_base_len128 checkpointing.resume_from_ckpt=false wandb=null loader.global_batch_size=8 loader.eval_global_batch_size=8 loader.batch_size=8 loader.eval_batch_size=8 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=128 training.resample=false algo.var_min=false algo.clip_search_widths=[]\n",
      ", v_num=0]\n",
      "Epoch 5:  32%|███▏      | 47/146 [00:17<00:37,  2.63it/s, v_num=0]\n",
      "Epoch 5:  32%|███▏      | 47/146 [00:17<00:37,  2.63it/s, v_num=0]\n",
      "Epoch 5:  33%|███▎      | 48/146 [00:17<00:36,  2.67it/s, v_num=0]\n",
      "Epoch 5:  33%|███▎      | 48/146 [00:17<00:36,  2.67it/s, v_num=0]\n",
      "Epoch 5:  34%|███▎      | 49/146 [00:18<00:35,  2.72it/s, v_num=0]\n",
      "Epoch 5:  34%|███▎      | 49/146 [00:18<00:35,  2.72it/s, v_num=0]\n",
      "Epoch 5:  34%|███▍      | 50/146 [00:18<00:34,  2.76it/s, v_num=0]\n",
      "Epoch 5:  34%|███▍      | 50/146 [00:18<00:34,  2.76it/s, v_num=0]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 41.88it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:00<00:00, 43.92it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 47.01it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 5:  34%|███▍      | 50/146 [00:25<00:48,  1.99it/s, v_num=0]Epoch 5, global step 780: 'val/nll' was not in top 1\n",
      "\n",
      "Epoch 5:  35%|███▍      | 51/146 [00:26<00:48,  1.96it/s, v_num=0]\n",
      "Epoch 5:  35%|███▍      | 51/146 [00:26<00:48,  1.96it/s, v_num=0]\n",
      "Epoch 5:  36%|███▌      | 52/146 [00:26<00:47,  1.99it/s, v_num=0]\n",
      "Epoch 5:  36%|███▌      | 52/146 [00:26<00:47,  1.99it/s, v_num=0]\n",
      "Epoch 5:  36%|███▋      | 53/146 [00:26<00:46,  2.02it/s, v_num=0]\n",
      "Epoch 5:  36%|███▋      | 53/146 [00:26<00:46,  2.02it/s, v_num=0]\n",
      "Epoch 5:  37%|███▋      | 54/146 [00:26<00:44,  2.05it/s, v_num=0]\n",
      "Epoch 5:  37%|███▋      | 54/146 [00:26<00:44,  2.05it/s, v_num=0]\n",
      "Epoch 5:  38%|███▊      | 55/146 [00:26<00:43,  2.08it/s, v_num=0]\n",
      "Epoch 5:  38%|███▊      | 55/146 [00:26<00:43,  2.08it/s, v_num=0]\n",
      "Epoch 5:  38%|███▊      | 56/146 [00:26<00:42,  2.11it/s, v_num=0]\n",
      "Epoch 5:  38%|███▊      | 56/146 [00:26<00:42,  2.11it/s, v_num=0]\n",
      "Epoch 5:  39%|███▉      | 57/146 [00:26<00:41,  2.14it/s, v_num=0]\n",
      "Epoch 5:  39%|███▉      | 57/146 [00:26<00:41,  2.14it/s, v_num=0]\n",
      "Epoch 5:  40%|███▉      | 58/146 [00:26<00:40,  2.17it/s, v_num=0]\n",
      "Epoch 5:  40%|███▉      | 58/146 [00:26<00:40,  2.17it/s, v_num=0]\n",
      "Epoch 5:  40%|████      | 59/146 [00:26<00:39,  2.20it/s, v_num=0]\n",
      "Epoch 5:  40%|████      | 59/146 [00:26<00:39,  2.20it/s, v_num=0]\n",
      "Epoch 5:  41%|████      | 60/146 [00:26<00:38,  2.23it/s, v_num=0]\n",
      "Epoch 5:  41%|████      | 60/146 [00:26<00:38,  2.23it/s, v_num=0]\n",
      "Epoch 5:  42%|████▏     | 61/146 [00:30<00:42,  2.01it/s, v_num=0]\n",
      "Epoch 5:  42%|████▏     | 61/146 [00:30<00:42,  2.01it/s, v_num=0]\n",
      "Epoch 5:  42%|████▏     | 62/146 [00:30<00:41,  2.04it/s, v_num=0]\n",
      "Epoch 5:  42%|████▏     | 62/146 [00:30<00:41,  2.04it/s, v_num=0]\n",
      "Epoch 5:  43%|████▎     | 63/146 [00:30<00:40,  2.06it/s, v_num=0]\n",
      "Epoch 5:  43%|████▎     | 63/146 [00:30<00:40,  2.06it/s, v_num=0]\n",
      "Epoch 5:  44%|████▍     | 64/146 [00:30<00:39,  2.09it/s, v_num=0]\n",
      "Epoch 5:  44%|████▍     | 64/146 [00:30<00:39,  2.09it/s, v_num=0]\n",
      "Epoch 5:  45%|████▍     | 65/146 [00:30<00:38,  2.12it/s, v_num=0]\n",
      "Epoch 5:  45%|████▍     | 65/146 [00:30<00:38,  2.12it/s, v_num=0]\n",
      "Epoch 5:  45%|████▌     | 66/146 [00:30<00:37,  2.14it/s, v_num=0]\n",
      "Epoch 5:  45%|████▌     | 66/146 [00:30<00:37,  2.14it/s, v_num=0]\n",
      "Epoch 5:  46%|████▌     | 67/146 [00:30<00:36,  2.17it/s, v_num=0]\n",
      "Epoch 5:  46%|████▌     | 67/146 [00:30<00:36,  2.17it/s, v_num=0]\n",
      "Epoch 5:  47%|████▋     | 68/146 [00:30<00:35,  2.20it/s, v_num=0]\n",
      "Epoch 5:  47%|████▋     | 68/146 [00:30<00:35,  2.20it/s, v_num=0]\n",
      "Epoch 5:  47%|████▋     | 69/146 [00:31<00:34,  2.22it/s, v_num=0]\n",
      "Epoch 5:  47%|████▋     | 69/146 [00:31<00:34,  2.22it/s, v_num=0]\n",
      "Epoch 5:  48%|████▊     | 70/146 [00:34<00:37,  2.03it/s, v_num=0]\n",
      "Epoch 5:  48%|████▊     | 70/146 [00:34<00:37,  2.03it/s, v_num=0]\n",
      "Epoch 5:  48%|████▊     | 70/146 [00:41<00:44,  1.70it/s, v_num=0]`Trainer.fit` stopped: `max_steps=800` reached.\n",
      "\n",
      "Epoch 5:  48%|████▊     | 70/146 [00:41<00:44,  1.70it/s, v_num=0]\n",
      "\n",
      "\n",
      "$ /home/orion/.venvs/ai/bin/python -u ./main.py mode=train data=lm1b-wrap data.cache_dir=./data data.streaming=true data.max_train_samples=5000 model=tiny model.length=128 model.attn_backend=sdpa algo=bd3lm trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 trainer.log_every_n_steps=10 trainer.val_check_interval=50 trainer.max_steps=800 data.max_valid_samples=100 data.max_test_samples=100 checkpointing.save_dir=/home/orion/Desktop/ntua/semester9/pattrec/repro_runs/bd3lm_finetune_Lp16 checkpointing.resume_from_ckpt=false wandb=null loader.global_batch_size=8 loader.eval_global_batch_size=8 loader.batch_size=8 loader.eval_batch_size=8 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=16 training.from_pretrained=/home/orion/Desktop/ntua/semester9/pattrec/repro_runs/bd3lm_base_len128/checkpoints/last.ckpt training.resample=true algo.var_min=false algo.clip_search_widths=[]\n",
      "00:50<00:25,  1.91it/s, v_num=0]\n",
      "Epoch 5:  66%|██████▋   | 97/146 [00:50<00:25,  1.91it/s, v_num=0]\n",
      "Epoch 5:  67%|██████▋   | 98/146 [00:50<00:24,  1.93it/s, v_num=0]\n",
      "Epoch 5:  67%|██████▋   | 98/146 [00:50<00:24,  1.93it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 99/146 [00:50<00:24,  1.94it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 99/146 [00:50<00:24,  1.94it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 100/146 [00:51<00:23,  1.96it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 100/146 [00:51<00:23,  1.96it/s, v_num=0]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 43.39it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:00<00:00, 45.42it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 47.33it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 5:  68%|██████▊   | 100/146 [00:58<00:26,  1.72it/s, v_num=0]Epoch 5, global step 780: 'val/nll' was not in top 1\n",
      "\n",
      "Epoch 5:  69%|██████▉   | 101/146 [00:59<00:26,  1.71it/s, v_num=0]\n",
      "Epoch 5:  69%|██████▉   | 101/146 [00:59<00:26,  1.71it/s, v_num=0]\n",
      "Epoch 5:  70%|██████▉   | 102/146 [00:59<00:25,  1.72it/s, v_num=0]\n",
      "Epoch 5:  70%|██████▉   | 102/146 [00:59<00:25,  1.72it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 103/146 [00:59<00:24,  1.74it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 103/146 [00:59<00:24,  1.74it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 104/146 [00:59<00:23,  1.75it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 104/146 [00:59<00:23,  1.75it/s, v_num=0]\n",
      "Epoch 5:  72%|███████▏  | 105/146 [00:59<00:23,  1.77it/s, v_num=0]\n",
      "Epoch 5:  72%|███████▏  | 105/146 [00:59<00:23,  1.77it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 106/146 [00:59<00:22,  1.78it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 106/146 [00:59<00:22,  1.78it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 107/146 [00:59<00:21,  1.79it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 107/146 [00:59<00:21,  1.79it/s, v_num=0]\n",
      "Epoch 5:  74%|███████▍  | 108/146 [00:59<00:21,  1.81it/s, v_num=0]\n",
      "Epoch 5:  74%|███████▍  | 108/146 [00:59<00:21,  1.81it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▍  | 109/146 [00:59<00:20,  1.82it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▍  | 109/146 [00:59<00:20,  1.82it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▌  | 110/146 [00:59<00:19,  1.84it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▌  | 110/146 [00:59<00:19,  1.84it/s, v_num=0]\n",
      "Epoch 5:  76%|███████▌  | 111/146 [01:03<00:19,  1.75it/s, v_num=0]\n",
      "Epoch 5:  76%|███████▌  | 111/146 [01:03<00:19,  1.75it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 112/146 [01:03<00:19,  1.76it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 112/146 [01:03<00:19,  1.76it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 113/146 [01:03<00:18,  1.78it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 113/146 [01:03<00:18,  1.78it/s, v_num=0]\n",
      "Epoch 5:  78%|███████▊  | 114/146 [01:03<00:17,  1.79it/s, v_num=0]\n",
      "Epoch 5:  78%|███████▊  | 114/146 [01:03<00:17,  1.79it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 115/146 [01:03<00:17,  1.80it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 115/146 [01:03<00:17,  1.80it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 116/146 [01:03<00:16,  1.82it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 116/146 [01:03<00:16,  1.82it/s, v_num=0]\n",
      "Epoch 5:  80%|████████  | 117/146 [01:03<00:15,  1.83it/s, v_num=0]\n",
      "Epoch 5:  80%|████████  | 117/146 [01:03<00:15,  1.83it/s, v_num=0]\n",
      "Epoch 5:  81%|████████  | 118/146 [01:03<00:15,  1.84it/s, v_num=0]\n",
      "Epoch 5:  81%|████████  | 118/146 [01:03<00:15,  1.84it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 119/146 [01:04<00:14,  1.86it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 119/146 [01:04<00:14,  1.86it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:07<00:14,  1.78it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:07<00:14,  1.78it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:14<00:16,  1.61it/s, v_num=0]`Trainer.fit` stopped: `max_steps=800` reached.\n",
      "\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:14<00:16,  1.61it/s, v_num=0]\n",
      "\n",
      "\n",
      "$ /home/orion/.venvs/ai/bin/python -u ./main.py mode=ppl_eval data=lm1b-wrap data.cache_dir=./data data.streaming=true data.max_test_samples=1000 model=tiny model.length=128 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/home/orion/Desktop/ntua/semester9/pattrec/repro_runs/bd3lm_finetune_Lp16/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=8 loader.eval_global_batch_size=8 loader.batch_size=8 loader.eval_batch_size=8 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=16 algo.var_min=false\n",
      "r performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/orion/.venvs/ai/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/orion/.venvs/ai/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/29 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/29 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   3%|▎         | 1/29 [00:00<00:13,  2.13it/s]\n",
      "Validation DataLoader 0:   7%|▋         | 2/29 [00:00<00:06,  4.08it/s]\n",
      "Validation DataLoader 0:  10%|█         | 3/29 [00:00<00:04,  5.84it/s]\n",
      "Validation DataLoader 0:  14%|█▍        | 4/29 [00:00<00:03,  7.45it/s]\n",
      "Validation DataLoader 0:  17%|█▋        | 5/29 [00:00<00:02,  8.95it/s]\n",
      "Validation DataLoader 0:  21%|██        | 6/29 [00:00<00:02, 10.36it/s]\n",
      "Validation DataLoader 0:  24%|██▍       | 7/29 [00:00<00:01, 11.69it/s]\n",
      "Validation DataLoader 0:  28%|██▊       | 8/29 [00:00<00:01, 12.91it/s]\n",
      "Validation DataLoader 0:  31%|███       | 9/29 [00:00<00:01, 14.03it/s]\n",
      "Validation DataLoader 0:  34%|███▍      | 10/29 [00:00<00:01, 15.08it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 11/29 [00:00<00:01, 16.06it/s]\n",
      "Validation DataLoader 0:  41%|████▏     | 12/29 [00:00<00:01, 16.99it/s]\n",
      "Validation DataLoader 0:  45%|████▍     | 13/29 [00:00<00:00, 17.83it/s]\n",
      "Validation DataLoader 0:  48%|████▊     | 14/29 [00:00<00:00, 18.68it/s]\n",
      "Validation DataLoader 0:  52%|█████▏    | 15/29 [00:00<00:00, 19.49it/s]\n",
      "Validation DataLoader 0:  55%|█████▌    | 16/29 [00:00<00:00, 20.24it/s]\n",
      "Validation DataLoader 0:  59%|█████▊    | 17/29 [00:00<00:00, 20.95it/s]\n",
      "Validation DataLoader 0:  62%|██████▏   | 18/29 [00:00<00:00, 21.60it/s]\n",
      "Validation DataLoader 0:  66%|██████▌   | 19/29 [00:00<00:00, 22.23it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 20/29 [00:00<00:00, 22.82it/s]\n",
      "Validation DataLoader 0:  72%|███████▏  | 21/29 [00:00<00:00, 23.41it/s]\n",
      "Validation DataLoader 0:  76%|███████▌  | 22/29 [00:00<00:00, 23.95it/s]\n",
      "Validation DataLoader 0:  79%|███████▉  | 23/29 [00:00<00:00, 24.46it/s]\n",
      "Validation DataLoader 0:  83%|████████▎ | 24/29 [00:00<00:00, 24.96it/s]\n",
      "Validation DataLoader 0:  86%|████████▌ | 25/29 [00:00<00:00, 25.42it/s]\n",
      "Validation DataLoader 0:  90%|████████▉ | 26/29 [00:01<00:00, 25.94it/s]\n",
      "Validation DataLoader 0:  93%|█████████▎| 27/29 [00:01<00:00, 26.37it/s]\n",
      "Validation DataLoader 0:  97%|█████████▋| 28/29 [00:01<00:00, 26.83it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 29/29 [00:01<00:00, 27.31it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 29/29 [00:04<00:00,  6.50it/s]\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[36m \u001b[0m\u001b[36m         val/bpd         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.640501976013184    \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m         val/nll         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.909698009490967    \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m         val/ppl         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    49.88388442993164    \u001b[0m\u001b[35m \u001b[0m│\n",
      "└───────────────────────────┴───────────────────────────┘\n",
      "\n",
      "\n",
      "$ /home/orion/.venvs/ai/bin/python -u ./main.py mode=train data=lm1b-wrap data.cache_dir=./data data.streaming=true data.max_train_samples=5000 model=tiny model.length=128 model.attn_backend=sdpa algo=bd3lm trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 trainer.log_every_n_steps=10 trainer.val_check_interval=50 trainer.max_steps=800 data.max_valid_samples=100 data.max_test_samples=100 checkpointing.save_dir=/home/orion/Desktop/ntua/semester9/pattrec/repro_runs/bd3lm_finetune_Lp8 checkpointing.resume_from_ckpt=false wandb=null loader.global_batch_size=8 loader.eval_global_batch_size=8 loader.batch_size=8 loader.eval_batch_size=8 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=8 training.from_pretrained=/home/orion/Desktop/ntua/semester9/pattrec/repro_runs/bd3lm_base_len128/checkpoints/last.ckpt training.resample=true algo.var_min=false algo.clip_search_widths=[]\n",
      "00:50<00:25,  1.91it/s, v_num=0]\n",
      "Epoch 5:  66%|██████▋   | 97/146 [00:50<00:25,  1.91it/s, v_num=0]\n",
      "Epoch 5:  67%|██████▋   | 98/146 [00:50<00:24,  1.93it/s, v_num=0]\n",
      "Epoch 5:  67%|██████▋   | 98/146 [00:50<00:24,  1.93it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 99/146 [00:50<00:24,  1.94it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 99/146 [00:50<00:24,  1.94it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 100/146 [00:51<00:23,  1.96it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 100/146 [00:51<00:23,  1.96it/s, v_num=0]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 45.56it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:00<00:00, 45.48it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 47.38it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 5:  68%|██████▊   | 100/146 [00:58<00:26,  1.72it/s, v_num=0]Epoch 5, global step 780: 'val/nll' was not in top 1\n",
      "\n",
      "Epoch 5:  69%|██████▉   | 101/146 [00:59<00:26,  1.71it/s, v_num=0]\n",
      "Epoch 5:  69%|██████▉   | 101/146 [00:59<00:26,  1.71it/s, v_num=0]\n",
      "Epoch 5:  70%|██████▉   | 102/146 [00:59<00:25,  1.72it/s, v_num=0]\n",
      "Epoch 5:  70%|██████▉   | 102/146 [00:59<00:25,  1.72it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 103/146 [00:59<00:24,  1.74it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 103/146 [00:59<00:24,  1.74it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 104/146 [00:59<00:23,  1.75it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 104/146 [00:59<00:23,  1.75it/s, v_num=0]\n",
      "Epoch 5:  72%|███████▏  | 105/146 [00:59<00:23,  1.77it/s, v_num=0]\n",
      "Epoch 5:  72%|███████▏  | 105/146 [00:59<00:23,  1.77it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 106/146 [00:59<00:22,  1.78it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 106/146 [00:59<00:22,  1.78it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 107/146 [00:59<00:21,  1.79it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 107/146 [00:59<00:21,  1.79it/s, v_num=0]\n",
      "Epoch 5:  74%|███████▍  | 108/146 [00:59<00:21,  1.81it/s, v_num=0]\n",
      "Epoch 5:  74%|███████▍  | 108/146 [00:59<00:21,  1.81it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▍  | 109/146 [00:59<00:20,  1.82it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▍  | 109/146 [00:59<00:20,  1.82it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▌  | 110/146 [00:59<00:19,  1.84it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▌  | 110/146 [00:59<00:19,  1.84it/s, v_num=0]\n",
      "Epoch 5:  76%|███████▌  | 111/146 [01:03<00:19,  1.75it/s, v_num=0]\n",
      "Epoch 5:  76%|███████▌  | 111/146 [01:03<00:19,  1.75it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 112/146 [01:03<00:19,  1.76it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 112/146 [01:03<00:19,  1.76it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 113/146 [01:03<00:18,  1.78it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 113/146 [01:03<00:18,  1.78it/s, v_num=0]\n",
      "Epoch 5:  78%|███████▊  | 114/146 [01:03<00:17,  1.79it/s, v_num=0]\n",
      "Epoch 5:  78%|███████▊  | 114/146 [01:03<00:17,  1.79it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 115/146 [01:03<00:17,  1.80it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 115/146 [01:03<00:17,  1.80it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 116/146 [01:03<00:16,  1.82it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 116/146 [01:03<00:16,  1.82it/s, v_num=0]\n",
      "Epoch 5:  80%|████████  | 117/146 [01:03<00:15,  1.83it/s, v_num=0]\n",
      "Epoch 5:  80%|████████  | 117/146 [01:03<00:15,  1.83it/s, v_num=0]\n",
      "Epoch 5:  81%|████████  | 118/146 [01:04<00:15,  1.84it/s, v_num=0]\n",
      "Epoch 5:  81%|████████  | 118/146 [01:04<00:15,  1.84it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 119/146 [01:04<00:14,  1.86it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 119/146 [01:04<00:14,  1.86it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:07<00:14,  1.78it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:07<00:14,  1.78it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:14<00:16,  1.61it/s, v_num=0]`Trainer.fit` stopped: `max_steps=800` reached.\n",
      "\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:14<00:16,  1.61it/s, v_num=0]\n",
      "\n",
      "\n",
      "$ /home/orion/.venvs/ai/bin/python -u ./main.py mode=ppl_eval data=lm1b-wrap data.cache_dir=./data data.streaming=true data.max_test_samples=1000 model=tiny model.length=128 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/home/orion/Desktop/ntua/semester9/pattrec/repro_runs/bd3lm_finetune_Lp8/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=8 loader.eval_global_batch_size=8 loader.batch_size=8 loader.eval_batch_size=8 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=8 algo.var_min=false\n",
      "r performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/orion/.venvs/ai/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/orion/.venvs/ai/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/29 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/29 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   3%|▎         | 1/29 [00:00<00:13,  2.14it/s]\n",
      "Validation DataLoader 0:   7%|▋         | 2/29 [00:00<00:06,  4.09it/s]\n",
      "Validation DataLoader 0:  10%|█         | 3/29 [00:00<00:04,  5.88it/s]\n",
      "Validation DataLoader 0:  14%|█▍        | 4/29 [00:00<00:03,  7.50it/s]\n",
      "Validation DataLoader 0:  17%|█▋        | 5/29 [00:00<00:02,  9.02it/s]\n",
      "Validation DataLoader 0:  21%|██        | 6/29 [00:00<00:02, 10.42it/s]\n",
      "Validation DataLoader 0:  24%|██▍       | 7/29 [00:00<00:01, 11.73it/s]\n",
      "Validation DataLoader 0:  28%|██▊       | 8/29 [00:00<00:01, 12.94it/s]\n",
      "Validation DataLoader 0:  31%|███       | 9/29 [00:00<00:01, 14.09it/s]\n",
      "Validation DataLoader 0:  34%|███▍      | 10/29 [00:00<00:01, 15.15it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 11/29 [00:00<00:01, 16.14it/s]\n",
      "Validation DataLoader 0:  41%|████▏     | 12/29 [00:00<00:00, 17.07it/s]\n",
      "Validation DataLoader 0:  45%|████▍     | 13/29 [00:00<00:00, 17.93it/s]\n",
      "Validation DataLoader 0:  48%|████▊     | 14/29 [00:00<00:00, 18.81it/s]\n",
      "Validation DataLoader 0:  52%|█████▏    | 15/29 [00:00<00:00, 19.63it/s]\n",
      "Validation DataLoader 0:  55%|█████▌    | 16/29 [00:00<00:00, 20.38it/s]\n",
      "Validation DataLoader 0:  59%|█████▊    | 17/29 [00:00<00:00, 21.10it/s]\n",
      "Validation DataLoader 0:  62%|██████▏   | 18/29 [00:00<00:00, 21.78it/s]\n",
      "Validation DataLoader 0:  66%|██████▌   | 19/29 [00:00<00:00, 22.44it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 20/29 [00:00<00:00, 23.01it/s]\n",
      "Validation DataLoader 0:  72%|███████▏  | 21/29 [00:00<00:00, 23.58it/s]\n",
      "Validation DataLoader 0:  76%|███████▌  | 22/29 [00:00<00:00, 24.14it/s]\n",
      "Validation DataLoader 0:  79%|███████▉  | 23/29 [00:00<00:00, 24.64it/s]\n",
      "Validation DataLoader 0:  83%|████████▎ | 24/29 [00:00<00:00, 25.15it/s]\n",
      "Validation DataLoader 0:  86%|████████▌ | 25/29 [00:00<00:00, 25.64it/s]\n",
      "Validation DataLoader 0:  90%|████████▉ | 26/29 [00:00<00:00, 26.12it/s]\n",
      "Validation DataLoader 0:  93%|█████████▎| 27/29 [00:01<00:00, 26.58it/s]\n",
      "Validation DataLoader 0:  97%|█████████▋| 28/29 [00:01<00:00, 27.02it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 29/29 [00:01<00:00, 27.48it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 29/29 [00:04<00:00,  6.13it/s]\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[36m \u001b[0m\u001b[36m         val/bpd         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   5.6189351081848145    \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m         val/nll         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.894749164581299    \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m         val/ppl         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    49.14372634887695    \u001b[0m\u001b[35m \u001b[0m│\n",
      "└───────────────────────────┴───────────────────────────┘\n",
      "\n",
      "\n",
      "$ /home/orion/.venvs/ai/bin/python -u ./main.py mode=train data=lm1b-wrap data.cache_dir=./data data.streaming=true data.max_train_samples=5000 model=tiny model.length=128 model.attn_backend=sdpa algo=bd3lm trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 trainer.log_every_n_steps=10 trainer.val_check_interval=50 trainer.max_steps=800 data.max_valid_samples=100 data.max_test_samples=100 checkpointing.save_dir=/home/orion/Desktop/ntua/semester9/pattrec/repro_runs/bd3lm_finetune_Lp4 checkpointing.resume_from_ckpt=false wandb=null loader.global_batch_size=8 loader.eval_global_batch_size=8 loader.batch_size=8 loader.eval_batch_size=8 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=4 training.from_pretrained=/home/orion/Desktop/ntua/semester9/pattrec/repro_runs/bd3lm_base_len128/checkpoints/last.ckpt training.resample=true algo.var_min=false algo.clip_search_widths=[]\n",
      "00:49<00:25,  1.95it/s, v_num=0]\n",
      "Epoch 5:  66%|██████▋   | 97/146 [00:49<00:25,  1.95it/s, v_num=0]\n",
      "Epoch 5:  67%|██████▋   | 98/146 [00:49<00:24,  1.96it/s, v_num=0]\n",
      "Epoch 5:  67%|██████▋   | 98/146 [00:49<00:24,  1.96it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 99/146 [00:50<00:23,  1.98it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 99/146 [00:50<00:23,  1.98it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 100/146 [00:50<00:23,  2.00it/s, v_num=0]\n",
      "Epoch 5:  68%|██████▊   | 100/146 [00:50<00:23,  2.00it/s, v_num=0]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 46.62it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:00<00:00, 46.14it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 46.18it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 5:  68%|██████▊   | 100/146 [00:57<00:26,  1.74it/s, v_num=0]Epoch 5, global step 780: 'val/nll' was not in top 1\n",
      "\n",
      "Epoch 5:  69%|██████▉   | 101/146 [00:58<00:25,  1.73it/s, v_num=0]\n",
      "Epoch 5:  69%|██████▉   | 101/146 [00:58<00:25,  1.73it/s, v_num=0]\n",
      "Epoch 5:  70%|██████▉   | 102/146 [00:58<00:25,  1.75it/s, v_num=0]\n",
      "Epoch 5:  70%|██████▉   | 102/146 [00:58<00:25,  1.75it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 103/146 [00:58<00:24,  1.76it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 103/146 [00:58<00:24,  1.76it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 104/146 [00:58<00:23,  1.78it/s, v_num=0]\n",
      "Epoch 5:  71%|███████   | 104/146 [00:58<00:23,  1.78it/s, v_num=0]\n",
      "Epoch 5:  72%|███████▏  | 105/146 [00:58<00:22,  1.79it/s, v_num=0]\n",
      "Epoch 5:  72%|███████▏  | 105/146 [00:58<00:22,  1.79it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 106/146 [00:58<00:22,  1.81it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 106/146 [00:58<00:22,  1.81it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 107/146 [00:58<00:21,  1.82it/s, v_num=0]\n",
      "Epoch 5:  73%|███████▎  | 107/146 [00:58<00:21,  1.82it/s, v_num=0]\n",
      "Epoch 5:  74%|███████▍  | 108/146 [00:58<00:20,  1.83it/s, v_num=0]\n",
      "Epoch 5:  74%|███████▍  | 108/146 [00:58<00:20,  1.83it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▍  | 109/146 [00:58<00:20,  1.85it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▍  | 109/146 [00:58<00:20,  1.85it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▌  | 110/146 [00:59<00:19,  1.86it/s, v_num=0]\n",
      "Epoch 5:  75%|███████▌  | 110/146 [00:59<00:19,  1.86it/s, v_num=0]\n",
      "Epoch 5:  76%|███████▌  | 111/146 [01:02<00:19,  1.77it/s, v_num=0]\n",
      "Epoch 5:  76%|███████▌  | 111/146 [01:02<00:19,  1.77it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 112/146 [01:02<00:19,  1.79it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 112/146 [01:02<00:19,  1.79it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 113/146 [01:02<00:18,  1.80it/s, v_num=0]\n",
      "Epoch 5:  77%|███████▋  | 113/146 [01:02<00:18,  1.80it/s, v_num=0]\n",
      "Epoch 5:  78%|███████▊  | 114/146 [01:02<00:17,  1.81it/s, v_num=0]\n",
      "Epoch 5:  78%|███████▊  | 114/146 [01:02<00:17,  1.81it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 115/146 [01:02<00:16,  1.83it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 115/146 [01:02<00:16,  1.83it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 116/146 [01:03<00:16,  1.84it/s, v_num=0]\n",
      "Epoch 5:  79%|███████▉  | 116/146 [01:03<00:16,  1.84it/s, v_num=0]\n",
      "Epoch 5:  80%|████████  | 117/146 [01:03<00:15,  1.85it/s, v_num=0]\n",
      "Epoch 5:  80%|████████  | 117/146 [01:03<00:15,  1.85it/s, v_num=0]\n",
      "Epoch 5:  81%|████████  | 118/146 [01:03<00:14,  1.87it/s, v_num=0]\n",
      "Epoch 5:  81%|████████  | 118/146 [01:03<00:14,  1.87it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 119/146 [01:03<00:14,  1.88it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 119/146 [01:03<00:14,  1.88it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:06<00:14,  1.80it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:06<00:14,  1.80it/s, v_num=0]\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:13<00:15,  1.63it/s, v_num=0]`Trainer.fit` stopped: `max_steps=800` reached.\n",
      "\n",
      "Epoch 5:  82%|████████▏ | 120/146 [01:13<00:15,  1.63it/s, v_num=0]\n",
      "\n",
      "\n",
      "$ /home/orion/.venvs/ai/bin/python -u ./main.py mode=ppl_eval data=lm1b-wrap data.cache_dir=./data data.streaming=true data.max_test_samples=1000 model=tiny model.length=128 model.attn_backend=sdpa algo=bd3lm eval.checkpoint_path=/home/orion/Desktop/ntua/semester9/pattrec/repro_runs/bd3lm_finetune_Lp4/checkpoints/last.ckpt trainer.accelerator=gpu trainer.devices=1 trainer.num_nodes=1 trainer.precision=16-mixed trainer.num_sanity_val_steps=0 wandb=null loader.global_batch_size=8 loader.eval_global_batch_size=8 loader.batch_size=8 loader.eval_batch_size=8 loader.num_workers=2 trainer.accumulate_grad_batches=1 block_size=4 algo.var_min=false\n",
      "r performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/orion/.venvs/ai/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/orion/.venvs/ai/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/29 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/29 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   3%|▎         | 1/29 [00:00<00:13,  2.12it/s]\n",
      "Validation DataLoader 0:   7%|▋         | 2/29 [00:00<00:06,  4.05it/s]\n",
      "Validation DataLoader 0:  10%|█         | 3/29 [00:00<00:04,  5.82it/s]\n",
      "Validation DataLoader 0:  14%|█▍        | 4/29 [00:00<00:03,  7.46it/s]\n",
      "Validation DataLoader 0:  17%|█▋        | 5/29 [00:00<00:02,  8.98it/s]\n",
      "Validation DataLoader 0:  21%|██        | 6/29 [00:00<00:02, 10.36it/s]\n",
      "Validation DataLoader 0:  24%|██▍       | 7/29 [00:00<00:01, 11.65it/s]\n",
      "Validation DataLoader 0:  28%|██▊       | 8/29 [00:00<00:01, 12.87it/s]\n",
      "Validation DataLoader 0:  31%|███       | 9/29 [00:00<00:01, 14.00it/s]\n",
      "Validation DataLoader 0:  34%|███▍      | 10/29 [00:00<00:01, 15.08it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 11/29 [00:00<00:01, 16.03it/s]\n",
      "Validation DataLoader 0:  41%|████▏     | 12/29 [00:00<00:01, 16.95it/s]\n",
      "Validation DataLoader 0:  45%|████▍     | 13/29 [00:00<00:00, 17.82it/s]\n",
      "Validation DataLoader 0:  48%|████▊     | 14/29 [00:00<00:00, 18.66it/s]\n",
      "Validation DataLoader 0:  52%|█████▏    | 15/29 [00:00<00:00, 19.45it/s]\n",
      "Validation DataLoader 0:  55%|█████▌    | 16/29 [00:00<00:00, 20.20it/s]\n",
      "Validation DataLoader 0:  59%|█████▊    | 17/29 [00:00<00:00, 20.92it/s]\n",
      "Validation DataLoader 0:  62%|██████▏   | 18/29 [00:00<00:00, 21.62it/s]\n",
      "Validation DataLoader 0:  66%|██████▌   | 19/29 [00:00<00:00, 22.27it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 20/29 [00:00<00:00, 22.87it/s]\n",
      "Validation DataLoader 0:  72%|███████▏  | 21/29 [00:00<00:00, 23.43it/s]\n",
      "Validation DataLoader 0:  76%|███████▌  | 22/29 [00:00<00:00, 23.99it/s]\n",
      "Validation DataLoader 0:  79%|███████▉  | 23/29 [00:00<00:00, 24.51it/s]\n",
      "Validation DataLoader 0:  83%|████████▎ | 24/29 [00:00<00:00, 25.02it/s]\n",
      "Validation DataLoader 0:  86%|████████▌ | 25/29 [00:00<00:00, 25.48it/s]\n",
      "Validation DataLoader 0:  90%|████████▉ | 26/29 [00:01<00:00, 25.97it/s]\n",
      "Validation DataLoader 0:  93%|█████████▎| 27/29 [00:01<00:00, 26.47it/s]\n",
      "Validation DataLoader 0:  97%|█████████▋| 28/29 [00:01<00:00, 26.95it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 29/29 [00:01<00:00, 27.43it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 29/29 [00:04<00:00,  6.11it/s]\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[36m \u001b[0m\u001b[36m         val/bpd         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.615124702453613    \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m         val/nll         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   3.8921079635620117    \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m         val/ppl         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    49.01409912109375    \u001b[0m\u001b[35m \u001b[0m│\n",
      "└───────────────────────────┴───────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "results = []\n",
    "\n",
    "bd3lm_base_run = \"bd3lm_base_len128\"\n",
    "bd3lm_base_ckpt = train_run(\n",
    "    bd3lm_base_run,\n",
    "    algo=\"bd3lm\",\n",
    "    block_size=128,\n",
    "    extra_overrides=[\n",
    "        \"training.resample=false\",\n",
    "        \"algo.var_min=false\",\n",
    "        \"algo.clip_search_widths=[]\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "for Lprime in [16, 8, 4]:\n",
    "    finetune_run = f\"bd3lm_finetune_Lp{Lprime}\"\n",
    "    finetune_ckpt = train_run(\n",
    "        finetune_run,\n",
    "        algo=\"bd3lm\",\n",
    "        block_size=Lprime,\n",
    "        from_pretrained=bd3lm_base_ckpt,\n",
    "        extra_overrides=[\n",
    "            \"training.resample=true\",\n",
    "            \"algo.var_min=false\",\n",
    "            \"algo.clip_search_widths=[]\",\n",
    "        ],\n",
    "    )\n",
    "    ppl = eval_run(\n",
    "        algo=\"bd3lm\",\n",
    "        checkpoint_path=finetune_ckpt,\n",
    "        block_size=Lprime,\n",
    "        extra_overrides=[\n",
    "            \"algo.var_min=false\",\n",
    "        ],\n",
    "    )\n",
    "    results.append({\"model\": \"Block diffusion (BD3LM)\", \"block_size_Lprime\": Lprime, \"val_ppl\": ppl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b803b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------+-------------------+\n",
      "| model                   | block_size_Lprime | val_ppl           |\n",
      "+-------------------------+-------------------+-------------------+\n",
      "| Block diffusion (BD3LM) | 16                | 49.88388442993164 |\n",
      "| Block diffusion (BD3LM) | 8                 | 49.14372634887695 |\n",
      "| Block diffusion (BD3LM) | 4                 | 49.01409912109375 |\n",
      "+-------------------------+-------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "def print_table(rows):\n",
    "    if not rows:\n",
    "        print(\"No data to display.\")\n",
    "        return\n",
    "\n",
    "    columns = list(rows[0].keys())\n",
    "\n",
    "    str_rows = [\n",
    "        {col: str(row.get(col, \"\")) for col in columns}\n",
    "        for row in rows\n",
    "    ]\n",
    "\n",
    "    widths = {\n",
    "        col: max(len(col), max(len(row[col]) for row in str_rows))\n",
    "        for col in columns\n",
    "    }\n",
    "\n",
    "    def print_separator():\n",
    "        print(\"+\" + \"+\".join(\"-\" * (widths[col] + 2) for col in columns) + \"+\")\n",
    "\n",
    "    def print_row(row):\n",
    "        print(\n",
    "            \"| \" +\n",
    "            \" | \".join(row[col].ljust(widths[col]) for col in columns) +\n",
    "            \" |\"\n",
    "        )\n",
    "\n",
    "    # Print table\n",
    "    print_separator()\n",
    "    print_row({col: col for col in columns})\n",
    "    print_separator()\n",
    "    for row in str_rows:\n",
    "        print_row(row)\n",
    "    print_separator()\n",
    "\n",
    "print_table(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
