{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#%env TORCH_FABRIC_DISABLE_ATOMIC_SAVE=1\n",
        "#%env PL_DISABLE_FSSPEC=1"
      ],
      "metadata": {
        "id": "eGSLJb268HeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/bd3lms"
      ],
      "metadata": {
        "id": "_dXcqGWMo0Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1py4CMBxo284",
        "outputId": "3b3ba64a-0a93-4a18-86e6-78a650141b60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && git clone https://github.com/ntua-el21050/bd3lms.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w68mC8-V0yLd",
        "outputId": "c5cc7d21-4ceb-4a30-aac8-14b235947ef8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bd3lms'...\n",
            "remote: Enumerating objects: 753, done.\u001b[K\n",
            "remote: Counting objects: 100% (214/214), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 753 (delta 192), reused 168 (delta 168), pack-reused 539 (from 2)\u001b[K\n",
            "Receiving objects: 100% (753/753), 1.12 MiB | 18.80 MiB/s, done.\n",
            "Resolving deltas: 100% (488/488), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply fix to diffusion.py: Override sampling_eps from config when resuming checkpoint\n",
        "import os\n",
        "\n",
        "diffusion_file = '/content/bd3lms/diffusion.py'\n",
        "\n",
        "with open(diffusion_file, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Find and replace the on_load_checkpoint method\n",
        "old_code = '''  def on_load_checkpoint(self, checkpoint):\n",
        "    print('Loading checkpoint at', checkpoint['global_step'])\n",
        "    self._restarting_skip_val_flag = True\n",
        "\n",
        "    # for models compiled with `torch.compile`\n",
        "    if '_orig_mod.' in list(checkpoint['state_dict'].keys())[0]:\n",
        "      checkpoint = self._replace_ckpt_keys(checkpoint)\n",
        "\n",
        "    if self.ema:\n",
        "      self.ema.load_state_dict(checkpoint['ema'])\n",
        "    if 'sampling_eps_min' in checkpoint.keys():\n",
        "      self.sampling_eps_min = checkpoint['sampling_eps_min']\n",
        "      self.sampling_eps_max = checkpoint['sampling_eps_max']\n",
        "    # Copied from:\n",
        "    # https://github.com/Dao-AILab/flash-attention/blob/main/training/src/datamodules/language_modeling_hf.py#L41\n",
        "    self.fast_forward_epochs = checkpoint['loops'][\n",
        "      'fit_loop']['epoch_progress']['current']['completed']\n",
        "    self.fast_forward_batches = checkpoint['loops'][\n",
        "      'fit_loop']['epoch_loop.batch_progress'][\n",
        "        'current']['completed']'''\n",
        "\n",
        "new_code = '''  def on_load_checkpoint(self, checkpoint):\n",
        "    print('Loading checkpoint at', checkpoint['global_step'])\n",
        "    self._restarting_skip_val_flag = True\n",
        "\n",
        "    # for models compiled with `torch.compile`\n",
        "    if '_orig_mod.' in list(checkpoint['state_dict'].keys())[0]:\n",
        "      checkpoint = self._replace_ckpt_keys(checkpoint)\n",
        "\n",
        "    if self.ema:\n",
        "      self.ema.load_state_dict(checkpoint['ema'])\n",
        "    if 'sampling_eps_min' in checkpoint.keys():\n",
        "      self.sampling_eps_min = checkpoint['sampling_eps_min']\n",
        "      self.sampling_eps_max = checkpoint['sampling_eps_max']\n",
        "\n",
        "    # Override sampling_eps in the checkpoint state_dict BEFORE Lightning loads it\n",
        "    # This is the only reliable way to change buffer values when resuming\n",
        "    if self.var_min and 'sampling_eps_min' in checkpoint['state_dict']:\n",
        "      checkpoint['state_dict']['sampling_eps_min'] = torch.tensor(\n",
        "        self.config.training.sampling_eps_min)\n",
        "      checkpoint['state_dict']['sampling_eps_max'] = torch.tensor(\n",
        "        self.config.training.sampling_eps_max)\n",
        "      print(f'✓ Overriding sampling_eps in checkpoint before load: '\n",
        "            f'min={self.config.training.sampling_eps_min}, '\n",
        "            f'max={self.config.training.sampling_eps_max}')\n",
        "\n",
        "    # Copied from:\n",
        "    # https://github.com/Dao-AILab/flash-attention/blob/main/training/src/datamodules/language_modeling_hf.py#L41\n",
        "    self.fast_forward_epochs = checkpoint['loops'][\n",
        "      'fit_loop']['epoch_progress']['current']['completed']\n",
        "    self.fast_forward_batches = checkpoint['loops'][\n",
        "      'fit_loop']['epoch_loop.batch_progress'][\n",
        "        'current']['completed']'''\n",
        "\n",
        "if old_code in content:\n",
        "    content = content.replace(old_code, new_code)\n",
        "    with open(diffusion_file, 'w') as f:\n",
        "        f.write(content)\n",
        "    print('✅ Successfully patched diffusion.py - sampling_eps override applied!')\n",
        "else:\n",
        "    print('⚠️ Could not find the code to patch. It may already be patched or the format differs.')\n",
        "    print('Checking if patch is already applied...')\n",
        "    if 'Overriding sampling_eps in checkpoint before load' in content:\n",
        "        print('✅ Patch already exists in diffusion.py!')\n",
        "    else:\n",
        "        print('❌ Patch not found and could not be applied.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aqQYPN0t8l0",
        "outputId": "d046e712-9293-4306-e909-69b881d64a8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully patched diffusion.py - sampling_eps override applied!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch main.py to disable TQDMProgressBar when resuming from checkpoint\n",
        "import os\n",
        "\n",
        "main_file = '/content/bd3lms/main.py'\n",
        "\n",
        "with open(main_file, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Find the trainer initialization section and add progress bar disable\n",
        "old_code = '''  trainer = hydra.utils.instantiate(\n",
        "    config.trainer,\n",
        "    default_root_dir=os.getcwd(),\n",
        "    callbacks=callbacks,\n",
        "    strategy=hydra.utils.instantiate(config.strategy),\n",
        "    logger=wandb_logger)'''\n",
        "\n",
        "new_code = '''  # Disable TQDMProgressBar when resuming from checkpoint (Lightning bug workaround)\n",
        "  enable_pb = not config.checkpointing.resume_ckpt_path\n",
        "\n",
        "  trainer = hydra.utils.instantiate(\n",
        "    config.trainer,\n",
        "    default_root_dir=os.getcwd(),\n",
        "    callbacks=callbacks,\n",
        "    strategy=hydra.utils.instantiate(config.strategy),\n",
        "    logger=wandb_logger,\n",
        "    enable_progress_bar=enable_pb)'''\n",
        "\n",
        "if old_code in content:\n",
        "    content = content.replace(old_code, new_code)\n",
        "    with open(main_file, 'w') as f:\n",
        "        f.write(content)\n",
        "    print('✅ Successfully patched main.py - TQDMProgressBar disabled for checkpoint resumption!')\n",
        "else:\n",
        "    print('⚠️ Could not find the code to patch. It may already be patched or the format differs.')\n",
        "    print('Checking if patch is already applied...')\n",
        "    if 'Disable TQDMProgressBar when resuming from checkpoint' in content:\n",
        "        print('✅ Patch already exists in main.py!')\n",
        "    else:\n",
        "        print('❌ Patch not found and could not be applied.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4POBUdF0i34",
        "outputId": "3f7c147a-5a98-4dd6-91a3-d24c7c3797b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully patched main.py - TQDMProgressBar disabled for checkpoint resumption!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch utils.py to fix checkpoint path detection (fsspec issue with Google Drive)\n",
        "import os\n",
        "\n",
        "utils_file = '/content/bd3lms/utils.py'\n",
        "\n",
        "with open(utils_file, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "old_code = '''def fsspec_exists(filename):\n",
        "  \"\"\"Check if a file exists using fsspec.\"\"\"\n",
        "  fs, _ = fsspec.core.url_to_fs(filename)\n",
        "  return fs.exists(filename)'''\n",
        "\n",
        "new_code = '''def fsspec_exists(filename):\n",
        "  \"\"\"Check if a file exists using fsspec.\"\"\"\n",
        "  try:\n",
        "    fs, _ = fsspec.core.url_to_fs(filename)\n",
        "    exists = fs.exists(filename)\n",
        "    if not exists:\n",
        "      # Fallback to os.path.exists for local paths (Google Drive in Colab)\n",
        "      import os\n",
        "      exists = os.path.exists(filename)\n",
        "    return exists\n",
        "  except Exception as e:\n",
        "    # If fsspec fails, try standard os.path.exists\n",
        "    import os\n",
        "    return os.path.exists(filename)'''\n",
        "\n",
        "if old_code in content:\n",
        "    content = content.replace(old_code, new_code)\n",
        "    with open(utils_file, 'w') as f:\n",
        "        f.write(content)\n",
        "    print('✅ Successfully patched utils.py - checkpoint detection fixed!')\n",
        "else:\n",
        "    print('⚠️ Could not find the code to patch. It may already be patched.')\n",
        "    if 'Fallback to os.path.exists' in content:\n",
        "        print('✅ Patch already exists in utils.py!')\n",
        "    else:\n",
        "        print('❌ Patch not found and could not be applied.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70xvLksFntmg",
        "outputId": "0d582c0a-00d2-4740-ebc5-1ff465a2ac48"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully patched utils.py - checkpoint detection fixed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \\\n",
        "    torchmetrics==1.6.2 \\\n",
        "    datasets==3.3.2 \\\n",
        "    einops==0.8.1 \\\n",
        "    fsspec==2024.2.0 \\\n",
        "    hydra-core==1.3.2 \\\n",
        "    lightning==2.5.0.post0 \\\n",
        "    omegaconf==2.3.0 \\\n",
        "    packaging==23.2 \\\n",
        "    pandas==2.2.1 \\\n",
        "    rich==13.7.1 \\\n",
        "    scikit-learn==1.5.1 \\\n",
        "    timm==0.9.16 \\\n",
        "    transformers==4.49.0 \\\n",
        "    matplotlib==3.10.0 \\\n",
        "    wandb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWoOq4945J6F",
        "outputId": "38902b03-cd8d-4400-b7cf-e3d56ba6f2ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m931.6/931.6 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.1 which is incompatible.\n",
            "db-dtypes 1.4.4 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.2.0 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "xarray 2025.12.0 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-bigquery 3.38.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.1 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content\")\n"
      ],
      "metadata": {
        "id": "LVlHOQl-5VG1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train base mdoel\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=train \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=128 \\\n",
        "  trainer.devices=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  trainer.max_steps=500 \\\n",
        "  data.max_train_samples=500 \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100 \\\n",
        "  training.nll_diagram=False \\\n",
        "  algo.fix_clipping=False \\\n",
        "  training.sampling_eps_min=0.0 \\\n",
        "  training.sampling_eps_max=1.0"
      ],
      "metadata": {
        "id": "_-ytqo6-6eNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1462e9b8-b5c0-4433-dc6a-216621e60ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "\u001b[2mCONFIG\u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmode\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mtrain                                                                   \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdiffusion\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mabsorbing_state                                                         \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mseed\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m1                                                                       \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mblock_size\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m128                                                                     \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdata\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mmax_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_train_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m500                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_valid_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_test_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtrain\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvalid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtokenizer_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbert-base-uncased                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcache_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/share/kuleshov/ssahoo/textdiffusion/data                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mwrap\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mstreaming\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mloader\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mglobal_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_global_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbatch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_workers\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mpin_memory\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2msampling\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mnoise_removal\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sample_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_length\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlogdir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m./samples_bd3lm_len128_blocksize128                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnucleus_p\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfirst_hitting\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mkv_cache\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtraining\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9999                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mantithetic_sampling\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcoeff_clip\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1.0                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresample\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnll_diagram\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfrom_pretrained\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_nll\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2meval\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoi\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdisable_ema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mperplexity_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcompute_perplexity_on_sanity\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgen_ppl_eval_model_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mgpt2-large                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgenerate_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2moptim\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mweight_decay\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlr\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0003                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta1\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta2\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.999                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0e-08                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtrainer\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.Trainer                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccelerator\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mcuda                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_nodes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdevices\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccumulate_grad_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgradient_clip_val\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mprecision\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbf16                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sanity_val_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m500                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlog_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1000                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_train_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_val_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mval_check_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mwandb\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mproject\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBD3-LMs                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnotes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBlock Denoising Discrete Diffusion Language Models               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgroup\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mjob_type\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mNone_1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtags\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcheckpointing\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40msave_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/022135                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_from_ckpt\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_ckpt_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpo\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcallbacks\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mevery_n_train_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m500                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcheckpoint_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmonitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mval/nll                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmode\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mmin                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mfilename\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbest                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlearning_rate_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.LearningRateMonitor             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mlogging_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mstep                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmodel\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtiny                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mddit                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mhidden_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m256                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcond_dim\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m64                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlength\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m128                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_blocks\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_heads\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mscale_by_sigma\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtie_word_embeddings\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40madaln\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mattn_backend\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msdpa                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mstrategy\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.strategies.DDPStrategy                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfind_unused_parameters\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mnoise\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0001                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m20                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mlr_scheduler\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtransformers.get_constant_schedule_with_warmup                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_warmup_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2500                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m└── \u001b[0m\u001b[2malgo\u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbd3lm                                                             \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbackbone\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mdit                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mparameterization\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msubs                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtime_conditioning\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mT\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                                    \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcausal_attention\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0                                                            \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mignore_bos\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcross_attn\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_delta\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.05                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_widths\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m[]                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfix_clipping\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                     \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampler\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msemi_ar                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmdlm_loss_scale\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 333kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 43.9MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 1.10MB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 4.03MB/s]\n",
            "[2026-01-05 02:21:38,492][__main__][INFO] - Starting Training.\n",
            "[2026-01-05 02:21:38,540][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_train_bs128_wrapped.dat\n",
            "[2026-01-05 02:21:38,540][dataloader][INFO] - streaming=True\n",
            "README.md: 5.66kB [00:00, 10.7MB/s]\n",
            "lm1b.py: 3.86kB [00:00, 22.1MB/s]\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 500 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 500 samples\n",
            "============================================================\n",
            "Map: 100% 500/500 [00:00<00:00, 2133.97 examples/s]\n",
            "Map: 100% 500/500 [00:00<00:00, 23735.25 examples/s]\n",
            "[2026-01-05 02:21:44,038][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 02:21:44,038][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100% 100/100 [00:00<00:00, 2046.41 examples/s]\n",
            "Map: 100% 100/100 [00:00<00:00, 22137.03 examples/s]\n",
            "Printing train dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] while athletes in different professions dealt with doping scandals and other controversies, woods continued to do what he did best : dominate the field of professional golf and rake in endorsements. [CLS] the minutes could shed light on an internal debate, which has been evident in fed officials'recent speeches, over when to consider raising rates.\n",
            "ids: tensor([  101,  2096,  7576,  1999,  2367, 22797,  9411,  2007, 23799, 29609,\n",
            "         1998,  2060, 25962,  1010,  5249,  2506,  2000,  2079,  2054,  2002,\n",
            "         2106,  2190,  1024, 16083,  1996,  2492,  1997,  2658,  5439,  1998,\n",
            "        26008,  1999, 20380,  2015,  1012,   101,  1996,  2781,  2071,  8328,\n",
            "         2422,  2006,  2019,  4722,  5981,  1010,  2029,  2038,  2042, 10358,\n",
            "         1999,  7349,  4584,  1005,  3522, 13867,  1010,  2058,  2043,  2000,\n",
            "         5136,  6274,  6165,  1012])\n",
            "Last 64 tokens: [CLS] but metro's definition of \" urbanite \" is not accurate, says matthew gandy, director of the urban laboratory at university college london. [CLS] goodrich petroleum is an independent oil and gas exploration and production company listed on the new york stock exchange. [CLS] the support from spears is to end on november 15 [CLS]\n",
            "ids: tensor([  101,  2021,  6005,  1005,  1055,  6210,  1997,  1000,  3923,  4221,\n",
            "         1000,  2003,  2025,  8321,  1010,  2758,  5487, 25957,  5149,  1010,\n",
            "         2472,  1997,  1996,  3923,  5911,  2012,  2118,  2267,  2414,  1012,\n",
            "          101,  2204, 13149, 11540,  2003,  2019,  2981,  3514,  1998,  3806,\n",
            "         8993,  1998,  2537,  2194,  3205,  2006,  1996,  2047,  2259,  4518,\n",
            "         3863,  1012,   101,  1996,  2490,  2013, 13957,  2003,  2000,  2203,\n",
            "         2006,  2281,  2321,   101])\n",
            "Printing valid dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] in medieval times, the townspeople from norcia were so practised at butchering pigs that they gained an in - depth knowledge of anatomy and were allowed to practise as surgeons along with members of the clergy. [CLS] the satellite weighs some 660 pounds, the israeli haaretz newspaper reported, citing unnamed company officials.\n",
            "ids: tensor([  101,  1999,  5781,  2335,  1010,  1996, 27938,  2013,  4496,  7405,\n",
            "         2020,  2061, 20439,  2012, 14998,  2075, 14695,  2008,  2027,  4227,\n",
            "         2019,  1999,  1011,  5995,  3716,  1997, 13336,  1998,  2020,  3039,\n",
            "         2000, 10975, 18908,  5562,  2004, 16804,  2247,  2007,  2372,  1997,\n",
            "         1996, 11646,  1012,   101,  1996,  5871, 21094,  2070, 20982,  7038,\n",
            "         1010,  1996,  5611,  5292, 12069,  5753,  3780,  2988,  1010,  8951,\n",
            "        13294,  2194,  4584,  1012])\n",
            "Last 64 tokens: [CLS] the situation has been further complicated by growing indications that the us treasury is preparing to make funds available for recapitalsing us banks. [CLS] as north korea's close neighbor, traditional ally and main provider of economic aid, china is widely believed to hold the key to solving the north korea conundrum. [CLS]\n",
            "ids: tensor([  101,  1996,  3663,  2038,  2042,  2582,  8552,  2011,  3652, 24936,\n",
            "         2008,  1996,  2149,  9837,  2003,  8225,  2000,  2191,  5029,  2800,\n",
            "         2005, 28667,  9331, 18400,  7741,  2149,  5085,  1012,   101,  2004,\n",
            "         2167,  4420,  1005,  1055,  2485, 11429,  1010,  3151,  9698,  1998,\n",
            "         2364, 10802,  1997,  3171,  4681,  1010,  2859,  2003,  4235,  3373,\n",
            "         2000,  2907,  1996,  3145,  2000, 13729,  1996,  2167,  4420,  9530,\n",
            "         8630,  6824,  1012,   101])\n",
            "[2026-01-05 02:23:23,562][__main__][INFO] - Initializing new model\n",
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 177kB/s]\n",
            "config.json: 100% 666/666 [00:00<00:00, 5.61MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 4.86MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 31.3MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 6.15MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type           | Params | Mode \n",
            "----------------------------------------------------\n",
            "0 | backbone | DIT            | 22.8 M | train\n",
            "1 | noise    | LogLinearNoise | 0      | train\n",
            "----------------------------------------------------\n",
            "22.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "22.8 M    Total params\n",
            "91.266    Total estimated model params size (MB)\n",
            "110       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 0, global step 2: 'val/nll' reached 10.63847 (best 10.63847), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 0, global step 4: 'val/nll' reached 9.98874 (best 9.98874), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 0, global step 6: 'val/nll' was not in top 1\n",
            "Epoch 0, global step 8: 'val/nll' was not in top 1\n",
            "Epoch 0, global step 10: 'val/nll' was not in top 1\n",
            "Epoch 0, global step 12: 'val/nll' reached 9.94745 (best 9.94745), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 0, global step 14: 'val/nll' was not in top 1\n",
            "Epoch 0, global step 16: 'val/nll' reached 9.65283 (best 9.65283), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 0, global step 18: 'val/nll' was not in top 1\n",
            "Epoch 0, global step 20: 'val/nll' was not in top 1\n",
            "Epoch 0, global step 22: 'val/nll' was not in top 1\n",
            "Epoch 0, global step 24: 'val/nll' was not in top 1\n",
            "Epoch 0, global step 26: 'val/nll' was not in top 1\n",
            "Epoch 0, global step 28: 'val/nll' was not in top 1\n",
            "Epoch 0, global step 30: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 32: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 34: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 36: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 38: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 40: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 42: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 44: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 46: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 48: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 50: 'val/nll' reached 9.60091 (best 9.60091), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 1, global step 52: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 54: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 56: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 58: 'val/nll' was not in top 1\n",
            "Epoch 1, global step 60: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 62: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 64: 'val/nll' reached 9.55951 (best 9.55951), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 2, global step 66: 'val/nll' reached 9.14393 (best 9.14393), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 2, global step 68: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 70: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 72: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 74: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 76: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 78: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 80: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 82: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 84: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 86: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 88: 'val/nll' was not in top 1\n",
            "Epoch 2, global step 90: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 92: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 94: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 96: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 98: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 100: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 102: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 104: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 106: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 108: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 110: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 112: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 114: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 116: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 118: 'val/nll' was not in top 1\n",
            "Epoch 3, global step 120: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 122: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 124: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 126: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 128: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 130: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 132: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 134: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 136: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 138: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 140: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 142: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 144: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 146: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 148: 'val/nll' was not in top 1\n",
            "Epoch 4, global step 150: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 152: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 154: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 156: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 158: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 160: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 162: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 164: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 166: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 168: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 170: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 172: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 174: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 176: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 178: 'val/nll' was not in top 1\n",
            "Epoch 5, global step 180: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 182: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 184: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 186: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 188: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 190: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 192: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 194: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 196: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 198: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 200: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 202: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 204: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 206: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 208: 'val/nll' was not in top 1\n",
            "Epoch 6, global step 210: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 212: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 214: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 216: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 218: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 220: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 222: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 224: 'val/nll' reached 9.06009 (best 9.06009), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 7, global step 226: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 228: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 230: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 232: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 234: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 236: 'val/nll' was not in top 1\n",
            "Epoch 7, global step 238: 'val/nll' reached 9.04196 (best 9.04196), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 7, global step 240: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 242: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 244: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 246: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 248: 'val/nll' reached 8.94764 (best 8.94764), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 8, global step 250: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 252: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 254: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 256: 'val/nll' reached 8.84502 (best 8.84502), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 8, global step 258: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 260: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 262: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 264: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 266: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 268: 'val/nll' was not in top 1\n",
            "Epoch 8, global step 270: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 272: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 274: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 276: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 278: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 280: 'val/nll' reached 8.72743 (best 8.72743), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 9, global step 282: 'val/nll' reached 8.03800 (best 8.03800), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 9, global step 284: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 286: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 288: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 290: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 292: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 294: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 296: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 298: 'val/nll' was not in top 1\n",
            "Epoch 9, global step 300: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 302: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 304: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 306: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 308: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 310: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 312: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 314: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 316: 'val/nll' reached 7.83112 (best 7.83112), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 10, global step 318: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 320: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 322: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 324: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 326: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 328: 'val/nll' was not in top 1\n",
            "Epoch 10, global step 330: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 332: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 334: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 336: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 338: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 340: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 342: 'val/nll' reached 7.78536 (best 7.78536), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 11, global step 344: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 346: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 348: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 350: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 352: 'val/nll' reached 7.71949 (best 7.71949), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 11, global step 354: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 356: 'val/nll' was not in top 1\n",
            "Epoch 11, global step 358: 'val/nll' reached 7.59446 (best 7.59446), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 11, global step 360: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 362: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 364: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 366: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 368: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 370: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 372: 'val/nll' reached 7.55546 (best 7.55546), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 12, global step 374: 'val/nll' reached 7.19592 (best 7.19592), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 12, global step 376: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 378: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 380: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 382: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 384: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 386: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 388: 'val/nll' was not in top 1\n",
            "Epoch 12, global step 390: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 392: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 394: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 396: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 398: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 400: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 402: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 404: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 406: 'val/nll' reached 7.13093 (best 7.13093), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 13, global step 408: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 410: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 412: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 414: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 416: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 418: 'val/nll' was not in top 1\n",
            "Epoch 13, global step 420: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 422: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 424: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 426: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 428: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 430: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 432: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 434: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 436: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 438: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 440: 'val/nll' reached 7.02582 (best 7.02582), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 14, global step 442: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 444: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 446: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 448: 'val/nll' was not in top 1\n",
            "Epoch 14, global step 450: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 452: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 454: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 456: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 458: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 460: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 462: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 464: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 466: 'val/nll' reached 6.73915 (best 6.73915), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints/best.ckpt' as top 1\n",
            "Epoch 15, global step 468: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 470: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 472: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 474: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 476: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 478: 'val/nll' was not in top 1\n",
            "Epoch 15, global step 480: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 482: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 484: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 486: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 488: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 490: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 492: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 494: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 496: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 498: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 500: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=500` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sync to drive\n",
        "!mkdir -p /content/drive/MyDrive/bd3lms_storage_final\n",
        "!rsync -av \\\n",
        "  /content/bd3lms/outputs/lm1b \\\n",
        "  /content/drive/MyDrive/bd3lms_storage_final\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFT7DD9v5oKW",
        "outputId": "3036d648-1382-4581-82c7-8034db90edb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending incremental file list\n",
            "lm1b/\n",
            "lm1b/2026.01.05/\n",
            "lm1b/2026.01.05/022135/\n",
            "lm1b/2026.01.05/022135/config_tree.txt\n",
            "lm1b/2026.01.05/022135/main.log\n",
            "lm1b/2026.01.05/022135/.hydra/\n",
            "lm1b/2026.01.05/022135/.hydra/config.yaml\n",
            "lm1b/2026.01.05/022135/.hydra/hydra.yaml\n",
            "lm1b/2026.01.05/022135/.hydra/overrides.yaml\n",
            "lm1b/2026.01.05/022135/checkpoints/\n",
            "lm1b/2026.01.05/022135/checkpoints/16-500.ckpt\n",
            "lm1b/2026.01.05/022135/checkpoints/best.ckpt\n",
            "lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "\n",
            "sent 1,098,513,284 bytes  received 196 bytes  169,002,073.85 bytes/sec\n",
            "total size is 1,098,244,406  speedup is 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune block size 128, clipping\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=train \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=128 \\\n",
        "  trainer.devices=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  trainer.max_steps=600 \\\n",
        "  data.max_train_samples=500 \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100 \\\n",
        "  training.nll_diagram=False \\\n",
        "  algo.fix_clipping=False \\\n",
        "  training.sampling_eps_min=0 \\\n",
        "  training.sampling_eps_max=0.5 \\\n",
        "  checkpointing.resume_ckpt_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt 2>&1 | grep -v \"TQDMProgressBar\\|val_progress_bar\""
      ],
      "metadata": {
        "id": "UycF7-nb6eKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac4aee8-3025-4b5b-8c0c-045e36bedc4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "CONFIG\n",
            "├── mode\n",
            "│   └── train                                                                   \n",
            "├── diffusion\n",
            "│   └── absorbing_state                                                         \n",
            "├── seed\n",
            "│   └── 1                                                                       \n",
            "├── block_size\n",
            "│   └── 128                                                                     \n",
            "├── data\n",
            "│   └── max_samples: null                                                       \n",
            "│       max_train_samples: 500                                                  \n",
            "│       max_valid_samples: 100                                                  \n",
            "│       max_test_samples: 100                                                   \n",
            "│       train: lm1b                                                             \n",
            "│       valid: lm1b                                                             \n",
            "│       tokenizer_name_or_path: bert-base-uncased                               \n",
            "│       cache_dir: /share/kuleshov/ssahoo/textdiffusion/data                    \n",
            "│       wrap: true                                                              \n",
            "│       streaming: true                                                         \n",
            "│                                                                               \n",
            "├── loader\n",
            "│   └── global_batch_size: 4                                                    \n",
            "│       eval_global_batch_size: 4                                               \n",
            "│       batch_size: 4                                                           \n",
            "│       eval_batch_size: 4                                                      \n",
            "│       num_workers: 1                                                          \n",
            "│       pin_memory: true                                                        \n",
            "│                                                                               \n",
            "├── sampling\n",
            "│   └── noise_removal: false                                                    \n",
            "│       num_sample_batches: 1                                                   \n",
            "│       var_length: false                                                       \n",
            "│       logdir: ./samples_bd3lm_len128_blocksize128                             \n",
            "│       nucleus_p: 1.0                                                          \n",
            "│       first_hitting: true                                                     \n",
            "│       kv_cache: false                                                         \n",
            "│                                                                               \n",
            "├── training\n",
            "│   └── ema: 0.9999                                                             \n",
            "│       antithetic_sampling: true                                               \n",
            "│       sampling_eps: 0.001                                                     \n",
            "│       coeff_clip: -1.0                                                        \n",
            "│       resample: false                                                         \n",
            "│       sampling_eps_min: 0                                                     \n",
            "│       sampling_eps_max: 0.5                                                   \n",
            "│       nll_diagram: false                                                      \n",
            "│       from_pretrained: null                                                   \n",
            "│       eval_nll: true                                                          \n",
            "│                                                                               \n",
            "├── eval\n",
            "│   └── checkpoint_path: /content/bd3lms/outputs/lm1b/2026.01.05/024407/checkpoi\n",
            "│       disable_ema: false                                                      \n",
            "│       perplexity_batch_size: 8                                                \n",
            "│       compute_perplexity_on_sanity: false                                     \n",
            "│       gen_ppl_eval_model_name_or_path: gpt2-large                             \n",
            "│       generate_samples: false                                                 \n",
            "│                                                                               \n",
            "├── optim\n",
            "│   └── weight_decay: 0                                                         \n",
            "│       lr: 0.0003                                                              \n",
            "│       beta1: 0.9                                                              \n",
            "│       beta2: 0.999                                                            \n",
            "│       eps: 1.0e-08                                                            \n",
            "│                                                                               \n",
            "├── trainer\n",
            "│   └── _target_: lightning.Trainer                                             \n",
            "│       accelerator: cuda                                                       \n",
            "│       num_nodes: 1                                                            \n",
            "│       devices: 1                                                              \n",
            "│       accumulate_grad_batches: 1                                              \n",
            "│       gradient_clip_val: 1.0                                                  \n",
            "│       precision: bf16                                                         \n",
            "│       num_sanity_val_steps: 2                                                 \n",
            "│       max_steps: 600                                                          \n",
            "│       log_every_n_steps: 1000                                                 \n",
            "│       limit_train_batches: 1.0                                                \n",
            "│       limit_val_batches: 1.0                                                  \n",
            "│       val_check_interval: 2                                                   \n",
            "│                                                                               \n",
            "├── wandb\n",
            "│   └── project: BD3-LMs                                                        \n",
            "│       notes: Block Denoising Discrete Diffusion Language Models               \n",
            "│       group: null                                                             \n",
            "│       job_type: null                                                          \n",
            "│       name: null                                                              \n",
            "│       id: None_1                                                              \n",
            "│       tags:                                                                   \n",
            "│       - loglinear                                                             \n",
            "│       - lm1b                                                                  \n",
            "│       - lm1b                                                                  \n",
            "│                                                                               \n",
            "├── checkpointing\n",
            "│   └── save_dir: /content/bd3lms/outputs/lm1b/2026.01.05/024407                \n",
            "│       resume_from_ckpt: true                                                  \n",
            "│       resume_ckpt_path: /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.\n",
            "│                                                                               \n",
            "├── callbacks\n",
            "│   └── checkpoint_every_n_steps:                                               \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         save_top_k: -1                                                        \n",
            "│         save_last: true                                                       \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/024407/checkpoints   \n",
            "│         verbose: true                                                         \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         every_n_train_steps: 500                                              \n",
            "│       checkpoint_monitor:                                                     \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         monitor: val/nll                                                      \n",
            "│         mode: min                                                             \n",
            "│         save_top_k: 1                                                         \n",
            "│         save_last: false                                                      \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/024407/checkpoints   \n",
            "│         filename: best                                                        \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         verbose: true                                                         \n",
            "│       learning_rate_monitor:                                                  \n",
            "│         _target_: lightning.pytorch.callbacks.LearningRateMonitor             \n",
            "│         logging_interval: step                                                \n",
            "│                                                                               \n",
            "├── model\n",
            "│   └── name: tiny                                                              \n",
            "│       type: ddit                                                              \n",
            "│       hidden_size: 256                                                        \n",
            "│       cond_dim: 64                                                            \n",
            "│       length: 128                                                             \n",
            "│       n_blocks: 8                                                             \n",
            "│       n_heads: 8                                                              \n",
            "│       scale_by_sigma: true                                                    \n",
            "│       dropout: 0.1                                                            \n",
            "│       tie_word_embeddings: true                                               \n",
            "│       adaln: false                                                            \n",
            "│       attn_backend: sdpa                                                      \n",
            "│                                                                               \n",
            "├── strategy\n",
            "│   └── _target_: lightning.pytorch.strategies.DDPStrategy                      \n",
            "│       find_unused_parameters: false                                           \n",
            "│                                                                               \n",
            "├── noise\n",
            "│   └── type: loglinear                                                         \n",
            "│       sigma_min: 0.0001                                                       \n",
            "│       sigma_max: 20                                                           \n",
            "│                                                                               \n",
            "├── lr_scheduler\n",
            "│   └── _target_: transformers.get_constant_schedule_with_warmup                \n",
            "│       num_warmup_steps: 2500                                                  \n",
            "│                                                                               \n",
            "└── algo\n",
            "    └── name: bd3lm                                                             \n",
            "        backbone: dit                                                           \n",
            "        parameterization: subs                                                  \n",
            "        time_conditioning: false                                                \n",
            "        T: 0                                                                    \n",
            "        causal_attention: false                                                 \n",
            "        dropout: 0.0                                                            \n",
            "        ignore_bos: true                                                        \n",
            "        cross_attn: true                                                        \n",
            "        var_min: true                                                           \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "                                                                                \n",
            "[2026-01-05 02:44:08,223][__main__][INFO] - Starting Training.\n",
            "[2026-01-05 02:44:08,232][__main__][INFO] - Resuming training at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "[2026-01-05 02:44:08,258][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_train_bs128_wrapped.dat\n",
            "[2026-01-05 02:44:08,258][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 500 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 500 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 2200.06 examples/s]\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 34369.96 examples/s]\n",
            "[2026-01-05 02:44:13,100][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 02:44:13,101][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 2261.42 examples/s]\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 22027.75 examples/s]\n",
            "Printing train dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] while athletes in different professions dealt with doping scandals and other controversies, woods continued to do what he did best : dominate the field of professional golf and rake in endorsements. [CLS] the minutes could shed light on an internal debate, which has been evident in fed officials'recent speeches, over when to consider raising rates.\n",
            "ids: tensor([  101,  2096,  7576,  1999,  2367, 22797,  9411,  2007, 23799, 29609,\n",
            "         1998,  2060, 25962,  1010,  5249,  2506,  2000,  2079,  2054,  2002,\n",
            "         2106,  2190,  1024, 16083,  1996,  2492,  1997,  2658,  5439,  1998,\n",
            "        26008,  1999, 20380,  2015,  1012,   101,  1996,  2781,  2071,  8328,\n",
            "         2422,  2006,  2019,  4722,  5981,  1010,  2029,  2038,  2042, 10358,\n",
            "         1999,  7349,  4584,  1005,  3522, 13867,  1010,  2058,  2043,  2000,\n",
            "         5136,  6274,  6165,  1012])\n",
            "Last 64 tokens: [CLS] but metro's definition of \" urbanite \" is not accurate, says matthew gandy, director of the urban laboratory at university college london. [CLS] goodrich petroleum is an independent oil and gas exploration and production company listed on the new york stock exchange. [CLS] the support from spears is to end on november 15 [CLS]\n",
            "ids: tensor([  101,  2021,  6005,  1005,  1055,  6210,  1997,  1000,  3923,  4221,\n",
            "         1000,  2003,  2025,  8321,  1010,  2758,  5487, 25957,  5149,  1010,\n",
            "         2472,  1997,  1996,  3923,  5911,  2012,  2118,  2267,  2414,  1012,\n",
            "          101,  2204, 13149, 11540,  2003,  2019,  2981,  3514,  1998,  3806,\n",
            "         8993,  1998,  2537,  2194,  3205,  2006,  1996,  2047,  2259,  4518,\n",
            "         3863,  1012,   101,  1996,  2490,  2013, 13957,  2003,  2000,  2203,\n",
            "         2006,  2281,  2321,   101])\n",
            "Printing valid dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] in medieval times, the townspeople from norcia were so practised at butchering pigs that they gained an in - depth knowledge of anatomy and were allowed to practise as surgeons along with members of the clergy. [CLS] the satellite weighs some 660 pounds, the israeli haaretz newspaper reported, citing unnamed company officials.\n",
            "ids: tensor([  101,  1999,  5781,  2335,  1010,  1996, 27938,  2013,  4496,  7405,\n",
            "         2020,  2061, 20439,  2012, 14998,  2075, 14695,  2008,  2027,  4227,\n",
            "         2019,  1999,  1011,  5995,  3716,  1997, 13336,  1998,  2020,  3039,\n",
            "         2000, 10975, 18908,  5562,  2004, 16804,  2247,  2007,  2372,  1997,\n",
            "         1996, 11646,  1012,   101,  1996,  5871, 21094,  2070, 20982,  7038,\n",
            "         1010,  1996,  5611,  5292, 12069,  5753,  3780,  2988,  1010,  8951,\n",
            "        13294,  2194,  4584,  1012])\n",
            "Last 64 tokens: [CLS] the situation has been further complicated by growing indications that the us treasury is preparing to make funds available for recapitalsing us banks. [CLS] as north korea's close neighbor, traditional ally and main provider of economic aid, china is widely believed to hold the key to solving the north korea conundrum. [CLS]\n",
            "ids: tensor([  101,  1996,  3663,  2038,  2042,  2582,  8552,  2011,  3652, 24936,\n",
            "         2008,  1996,  2149,  9837,  2003,  8225,  2000,  2191,  5029,  2800,\n",
            "         2005, 28667,  9331, 18400,  7741,  2149,  5085,  1012,   101,  2004,\n",
            "         2167,  4420,  1005,  1055,  2485, 11429,  1010,  3151,  9698,  1998,\n",
            "         2364, 10802,  1997,  3171,  4681,  1010,  2859,  2003,  4235,  3373,\n",
            "         2000,  2907,  1996,  3145,  2000, 13729,  1996,  2167,  4420,  9530,\n",
            "         8630,  6824,  1012,   101])\n",
            "[2026-01-05 02:45:54,101][__main__][INFO] - Initializing new model\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "wandb: WARNING The anonymous setting has no effect and will be removed in a future version.\n",
            "Restoring states from the checkpoint path at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:362: The dirpath has changed from '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints' to '/content/bd3lms/outputs/lm1b/2026.01.05/024407/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type           | Params | Mode \n",
            "----------------------------------------------------\n",
            "0 | backbone | DIT            | 22.8 M | train\n",
            "1 | noise    | LogLinearNoise | 0      | train\n",
            "----------------------------------------------------\n",
            "22.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "22.8 M    Total params\n",
            "91.266    Total estimated model params size (MB)\n",
            "110       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Restored all states from the checkpoint at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "Loading checkpoint at 500\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0, max=0.5\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py:221: You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.\n",
            "Epoch 16, global step 504: 'val/nll' reached 7.85400 (best 7.85400), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/024407/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 506: 'val/nll' reached 7.46223 (best 7.46223), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/024407/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 508: 'val/nll' reached 6.94701 (best 6.94701), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/024407/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 510: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 512: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 514: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 516: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 518: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 520: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 522: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 524: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 526: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 528: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 530: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 532: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 534: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 536: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 538: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 540: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 542: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 544: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 546: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 548: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 550: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 552: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 554: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 556: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 558: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 560: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 562: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 564: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 566: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 568: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 570: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 572: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 574: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 576: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 578: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 580: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 582: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 584: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 586: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 588: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 590: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 592: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 594: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 596: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 598: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 600: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=600` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eval_bd3lm_best block size 128, clipping\n",
        "\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=ppl_eval \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=128 \\\n",
        "  trainer.devices=1 \\\n",
        "  trainer.num_nodes=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  eval.checkpoint_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/024407/checkpoints/best.ckpt \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWnuK8SB-Tm_",
        "outputId": "486a15c5-3cf8-42fc-a818-4f70ef58e2b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "\u001b[2mCONFIG\u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmode\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mppl_eval                                                                \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdiffusion\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mabsorbing_state                                                         \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mseed\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m1                                                                       \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mblock_size\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m128                                                                     \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdata\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mmax_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_train_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_valid_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_test_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtrain\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvalid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtokenizer_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbert-base-uncased                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcache_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/share/kuleshov/ssahoo/textdiffusion/data                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mwrap\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mstreaming\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mloader\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mglobal_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_global_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbatch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_workers\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mpin_memory\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2msampling\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mnoise_removal\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sample_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_length\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlogdir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m./samples_bd3lm_len128_blocksize128                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnucleus_p\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfirst_hitting\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mkv_cache\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtraining\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9999                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mantithetic_sampling\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcoeff_clip\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1.0                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresample\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnll_diagram\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfrom_pretrained\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_nll\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2meval\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.0\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdisable_ema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mperplexity_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcompute_perplexity_on_sanity\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgen_ppl_eval_model_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mgpt2-large                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgenerate_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2moptim\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mweight_decay\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlr\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0003                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta1\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta2\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.999                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0e-08                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtrainer\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.Trainer                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccelerator\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mcuda                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_nodes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdevices\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccumulate_grad_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgradient_clip_val\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mprecision\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbf16                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sanity_val_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m300                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlog_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1000                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_train_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_val_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mval_check_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mwandb\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mproject\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBD3-LMs                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnotes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBlock Denoising Discrete Diffusion Language Models               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgroup\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mjob_type\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mNone_1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtags\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcheckpointing\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40msave_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/180304                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_from_ckpt\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_ckpt_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/180304/checkpo\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcallbacks\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/180304/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mevery_n_train_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m500                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcheckpoint_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmonitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mval/nll                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmode\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mmin                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/180304/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mfilename\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbest                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlearning_rate_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.LearningRateMonitor             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mlogging_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mstep                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmodel\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtiny                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mddit                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mhidden_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m256                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcond_dim\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m64                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlength\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m128                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_blocks\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_heads\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mscale_by_sigma\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtie_word_embeddings\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40madaln\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mattn_backend\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msdpa                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mstrategy\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.strategies.DDPStrategy                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfind_unused_parameters\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mnoise\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0001                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m20                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mlr_scheduler\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtransformers.get_constant_schedule_with_warmup                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_warmup_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2500                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m└── \u001b[0m\u001b[2malgo\u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbd3lm                                                             \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbackbone\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mdit                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mparameterization\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msubs                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtime_conditioning\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mT\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                                    \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcausal_attention\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0                                                            \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mignore_bos\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcross_attn\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_delta\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.05                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_widths\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m[]                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfix_clipping\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                     \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampler\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msemi_ar                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmdlm_loss_scale\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 318kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 2.76MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 2.76MB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 5.02MB/s]\n",
            "[2026-01-05 18:03:06,243][__main__][INFO] - Starting Eval.\n",
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 223kB/s]\n",
            "config.json: 100% 666/666 [00:00<00:00, 5.13MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 4.22MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 2.75MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 4.66MB/s]\n",
            "Loading checkpoint at 508\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0.001, max=1.0\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-05 18:03:25,012][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 18:03:25,012][dataloader][INFO] - streaming=True\n",
            "README.md: 5.66kB [00:00, 18.1MB/s]\n",
            "lm1b.py: 3.86kB [00:00, 7.47MB/s]\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100% 100/100 [00:00<00:00, 1493.15 examples/s]\n",
            "Map: 100% 100/100 [00:00<00:00, 18883.90 examples/s]\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-05 18:04:29.831374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767636269.849608    2940 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767636269.854973    2940 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767636269.868517    2940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636269.868538    2940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636269.868542    2940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636269.868547    2940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-05 18:04:29.872579: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_max     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_min     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0010000000474974513  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/bpd         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   11.024203300476074    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/nll         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    7.641395568847656    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/ppl         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2082.648193359375    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    valid_var_0.0 - 1    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8089386820793152    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune block size 128, no clipping\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=train \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=128 \\\n",
        "  trainer.devices=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  trainer.max_steps=600 \\\n",
        "  data.max_train_samples=500 \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100 \\\n",
        "  training.nll_diagram=False \\\n",
        "  algo.fix_clipping=False \\\n",
        "  training.sampling_eps_min=0 \\\n",
        "  training.sampling_eps_max=1 \\\n",
        "  checkpointing.resume_ckpt_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt 2>&1 | grep -v \"TQDMProgressBar\\|val_progress_bar\""
      ],
      "metadata": {
        "id": "ouG0tF8R6dvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74cbfd13-d495-466b-d149-e8e0acaf5376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "CONFIG\n",
            "├── mode\n",
            "│   └── train                                                                   \n",
            "├── diffusion\n",
            "│   └── absorbing_state                                                         \n",
            "├── seed\n",
            "│   └── 1                                                                       \n",
            "├── block_size\n",
            "│   └── 128                                                                     \n",
            "├── data\n",
            "│   └── max_samples: null                                                       \n",
            "│       max_train_samples: 500                                                  \n",
            "│       max_valid_samples: 100                                                  \n",
            "│       max_test_samples: 100                                                   \n",
            "│       train: lm1b                                                             \n",
            "│       valid: lm1b                                                             \n",
            "│       tokenizer_name_or_path: bert-base-uncased                               \n",
            "│       cache_dir: /share/kuleshov/ssahoo/textdiffusion/data                    \n",
            "│       wrap: true                                                              \n",
            "│       streaming: true                                                         \n",
            "│                                                                               \n",
            "├── loader\n",
            "│   └── global_batch_size: 4                                                    \n",
            "│       eval_global_batch_size: 4                                               \n",
            "│       batch_size: 4                                                           \n",
            "│       eval_batch_size: 4                                                      \n",
            "│       num_workers: 1                                                          \n",
            "│       pin_memory: true                                                        \n",
            "│                                                                               \n",
            "├── sampling\n",
            "│   └── noise_removal: false                                                    \n",
            "│       num_sample_batches: 1                                                   \n",
            "│       var_length: false                                                       \n",
            "│       logdir: ./samples_bd3lm_len128_blocksize128                             \n",
            "│       nucleus_p: 1.0                                                          \n",
            "│       first_hitting: true                                                     \n",
            "│       kv_cache: false                                                         \n",
            "│                                                                               \n",
            "├── training\n",
            "│   └── ema: 0.9999                                                             \n",
            "│       antithetic_sampling: true                                               \n",
            "│       sampling_eps: 0.001                                                     \n",
            "│       coeff_clip: -1.0                                                        \n",
            "│       resample: false                                                         \n",
            "│       sampling_eps_min: 0                                                     \n",
            "│       sampling_eps_max: 1                                                     \n",
            "│       nll_diagram: false                                                      \n",
            "│       from_pretrained: null                                                   \n",
            "│       eval_nll: true                                                          \n",
            "│                                                                               \n",
            "├── eval\n",
            "│   └── checkpoint_path: /content/bd3lms/outputs/lm1b/2026.01.05/025009/checkpoi\n",
            "│       disable_ema: false                                                      \n",
            "│       perplexity_batch_size: 8                                                \n",
            "│       compute_perplexity_on_sanity: false                                     \n",
            "│       gen_ppl_eval_model_name_or_path: gpt2-large                             \n",
            "│       generate_samples: false                                                 \n",
            "│                                                                               \n",
            "├── optim\n",
            "│   └── weight_decay: 0                                                         \n",
            "│       lr: 0.0003                                                              \n",
            "│       beta1: 0.9                                                              \n",
            "│       beta2: 0.999                                                            \n",
            "│       eps: 1.0e-08                                                            \n",
            "│                                                                               \n",
            "├── trainer\n",
            "│   └── _target_: lightning.Trainer                                             \n",
            "│       accelerator: cuda                                                       \n",
            "│       num_nodes: 1                                                            \n",
            "│       devices: 1                                                              \n",
            "│       accumulate_grad_batches: 1                                              \n",
            "│       gradient_clip_val: 1.0                                                  \n",
            "│       precision: bf16                                                         \n",
            "│       num_sanity_val_steps: 2                                                 \n",
            "│       max_steps: 600                                                          \n",
            "│       log_every_n_steps: 1000                                                 \n",
            "│       limit_train_batches: 1.0                                                \n",
            "│       limit_val_batches: 1.0                                                  \n",
            "│       val_check_interval: 2                                                   \n",
            "│                                                                               \n",
            "├── wandb\n",
            "│   └── project: BD3-LMs                                                        \n",
            "│       notes: Block Denoising Discrete Diffusion Language Models               \n",
            "│       group: null                                                             \n",
            "│       job_type: null                                                          \n",
            "│       name: null                                                              \n",
            "│       id: None_1                                                              \n",
            "│       tags:                                                                   \n",
            "│       - loglinear                                                             \n",
            "│       - lm1b                                                                  \n",
            "│       - lm1b                                                                  \n",
            "│                                                                               \n",
            "├── checkpointing\n",
            "│   └── save_dir: /content/bd3lms/outputs/lm1b/2026.01.05/025009                \n",
            "│       resume_from_ckpt: true                                                  \n",
            "│       resume_ckpt_path: /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.\n",
            "│                                                                               \n",
            "├── callbacks\n",
            "│   └── checkpoint_every_n_steps:                                               \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         save_top_k: -1                                                        \n",
            "│         save_last: true                                                       \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/025009/checkpoints   \n",
            "│         verbose: true                                                         \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         every_n_train_steps: 500                                              \n",
            "│       checkpoint_monitor:                                                     \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         monitor: val/nll                                                      \n",
            "│         mode: min                                                             \n",
            "│         save_top_k: 1                                                         \n",
            "│         save_last: false                                                      \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/025009/checkpoints   \n",
            "│         filename: best                                                        \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         verbose: true                                                         \n",
            "│       learning_rate_monitor:                                                  \n",
            "│         _target_: lightning.pytorch.callbacks.LearningRateMonitor             \n",
            "│         logging_interval: step                                                \n",
            "│                                                                               \n",
            "├── model\n",
            "│   └── name: tiny                                                              \n",
            "│       type: ddit                                                              \n",
            "│       hidden_size: 256                                                        \n",
            "│       cond_dim: 64                                                            \n",
            "│       length: 128                                                             \n",
            "│       n_blocks: 8                                                             \n",
            "│       n_heads: 8                                                              \n",
            "│       scale_by_sigma: true                                                    \n",
            "│       dropout: 0.1                                                            \n",
            "│       tie_word_embeddings: true                                               \n",
            "│       adaln: false                                                            \n",
            "│       attn_backend: sdpa                                                      \n",
            "│                                                                               \n",
            "├── strategy\n",
            "│   └── _target_: lightning.pytorch.strategies.DDPStrategy                      \n",
            "│       find_unused_parameters: false                                           \n",
            "│                                                                               \n",
            "├── noise\n",
            "│   └── type: loglinear                                                         \n",
            "│       sigma_min: 0.0001                                                       \n",
            "│       sigma_max: 20                                                           \n",
            "│                                                                               \n",
            "├── lr_scheduler\n",
            "│   └── _target_: transformers.get_constant_schedule_with_warmup                \n",
            "│       num_warmup_steps: 2500                                                  \n",
            "│                                                                               \n",
            "└── algo\n",
            "    └── name: bd3lm                                                             \n",
            "        backbone: dit                                                           \n",
            "        parameterization: subs                                                  \n",
            "        time_conditioning: false                                                \n",
            "        T: 0                                                                    \n",
            "        causal_attention: false                                                 \n",
            "        dropout: 0.0                                                            \n",
            "        ignore_bos: true                                                        \n",
            "        cross_attn: true                                                        \n",
            "        var_min: true                                                           \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "                                                                                \n",
            "[2026-01-05 02:50:10,179][__main__][INFO] - Starting Training.\n",
            "[2026-01-05 02:50:10,187][__main__][INFO] - Resuming training at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "[2026-01-05 02:50:10,210][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_train_bs128_wrapped.dat\n",
            "[2026-01-05 02:50:10,210][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 500 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 500 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 2084.46 examples/s]\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 33737.97 examples/s]\n",
            "[2026-01-05 02:50:14,930][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 02:50:14,931][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 2033.18 examples/s]\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 22800.09 examples/s]\n",
            "Printing train dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] while athletes in different professions dealt with doping scandals and other controversies, woods continued to do what he did best : dominate the field of professional golf and rake in endorsements. [CLS] the minutes could shed light on an internal debate, which has been evident in fed officials'recent speeches, over when to consider raising rates.\n",
            "ids: tensor([  101,  2096,  7576,  1999,  2367, 22797,  9411,  2007, 23799, 29609,\n",
            "         1998,  2060, 25962,  1010,  5249,  2506,  2000,  2079,  2054,  2002,\n",
            "         2106,  2190,  1024, 16083,  1996,  2492,  1997,  2658,  5439,  1998,\n",
            "        26008,  1999, 20380,  2015,  1012,   101,  1996,  2781,  2071,  8328,\n",
            "         2422,  2006,  2019,  4722,  5981,  1010,  2029,  2038,  2042, 10358,\n",
            "         1999,  7349,  4584,  1005,  3522, 13867,  1010,  2058,  2043,  2000,\n",
            "         5136,  6274,  6165,  1012])\n",
            "Last 64 tokens: [CLS] but metro's definition of \" urbanite \" is not accurate, says matthew gandy, director of the urban laboratory at university college london. [CLS] goodrich petroleum is an independent oil and gas exploration and production company listed on the new york stock exchange. [CLS] the support from spears is to end on november 15 [CLS]\n",
            "ids: tensor([  101,  2021,  6005,  1005,  1055,  6210,  1997,  1000,  3923,  4221,\n",
            "         1000,  2003,  2025,  8321,  1010,  2758,  5487, 25957,  5149,  1010,\n",
            "         2472,  1997,  1996,  3923,  5911,  2012,  2118,  2267,  2414,  1012,\n",
            "          101,  2204, 13149, 11540,  2003,  2019,  2981,  3514,  1998,  3806,\n",
            "         8993,  1998,  2537,  2194,  3205,  2006,  1996,  2047,  2259,  4518,\n",
            "         3863,  1012,   101,  1996,  2490,  2013, 13957,  2003,  2000,  2203,\n",
            "         2006,  2281,  2321,   101])\n",
            "Printing valid dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] in medieval times, the townspeople from norcia were so practised at butchering pigs that they gained an in - depth knowledge of anatomy and were allowed to practise as surgeons along with members of the clergy. [CLS] the satellite weighs some 660 pounds, the israeli haaretz newspaper reported, citing unnamed company officials.\n",
            "ids: tensor([  101,  1999,  5781,  2335,  1010,  1996, 27938,  2013,  4496,  7405,\n",
            "         2020,  2061, 20439,  2012, 14998,  2075, 14695,  2008,  2027,  4227,\n",
            "         2019,  1999,  1011,  5995,  3716,  1997, 13336,  1998,  2020,  3039,\n",
            "         2000, 10975, 18908,  5562,  2004, 16804,  2247,  2007,  2372,  1997,\n",
            "         1996, 11646,  1012,   101,  1996,  5871, 21094,  2070, 20982,  7038,\n",
            "         1010,  1996,  5611,  5292, 12069,  5753,  3780,  2988,  1010,  8951,\n",
            "        13294,  2194,  4584,  1012])\n",
            "Last 64 tokens: [CLS] the situation has been further complicated by growing indications that the us treasury is preparing to make funds available for recapitalsing us banks. [CLS] as north korea's close neighbor, traditional ally and main provider of economic aid, china is widely believed to hold the key to solving the north korea conundrum. [CLS]\n",
            "ids: tensor([  101,  1996,  3663,  2038,  2042,  2582,  8552,  2011,  3652, 24936,\n",
            "         2008,  1996,  2149,  9837,  2003,  8225,  2000,  2191,  5029,  2800,\n",
            "         2005, 28667,  9331, 18400,  7741,  2149,  5085,  1012,   101,  2004,\n",
            "         2167,  4420,  1005,  1055,  2485, 11429,  1010,  3151,  9698,  1998,\n",
            "         2364, 10802,  1997,  3171,  4681,  1010,  2859,  2003,  4235,  3373,\n",
            "         2000,  2907,  1996,  3145,  2000, 13729,  1996,  2167,  4420,  9530,\n",
            "         8630,  6824,  1012,   101])\n",
            "[2026-01-05 02:53:31,580][__main__][INFO] - Initializing new model\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "wandb: WARNING The anonymous setting has no effect and will be removed in a future version.\n",
            "Restoring states from the checkpoint path at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:362: The dirpath has changed from '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints' to '/content/bd3lms/outputs/lm1b/2026.01.05/025009/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type           | Params | Mode \n",
            "----------------------------------------------------\n",
            "0 | backbone | DIT            | 22.8 M | train\n",
            "1 | noise    | LogLinearNoise | 0      | train\n",
            "----------------------------------------------------\n",
            "22.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "22.8 M    Total params\n",
            "91.266    Total estimated model params size (MB)\n",
            "110       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Restored all states from the checkpoint at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "Loading checkpoint at 500\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0, max=1\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py:221: You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.\n",
            "Epoch 16, global step 504: 'val/nll' reached 7.85403 (best 7.85403), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/025009/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 506: 'val/nll' reached 7.46222 (best 7.46222), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/025009/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 508: 'val/nll' reached 6.94708 (best 6.94708), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/025009/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 510: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 512: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 514: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 516: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 518: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 520: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 522: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 524: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 526: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 528: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 530: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 532: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 534: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 536: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 538: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 540: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 542: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 544: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 546: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 548: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 550: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 552: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 554: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 556: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 558: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 560: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 562: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 564: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 566: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 568: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 570: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 572: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 574: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 576: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 578: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 580: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 582: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 584: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 586: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 588: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 590: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 592: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 594: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 596: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 598: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 600: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=600` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/025009/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UyLYpFOTNPO",
        "outputId": "83aa4f24-70e1-4b8d-ed56-90f62a3457ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoints  config_tree.txt  main.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eval_bd3lm_best block size 128, no clipping\n",
        "\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=ppl_eval \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=128 \\\n",
        "  trainer.devices=1 \\\n",
        "  trainer.num_nodes=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  eval.checkpoint_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/025009/checkpoints/best.ckpt \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100"
      ],
      "metadata": {
        "id": "ShIIzdkF6dt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ed4a21-8553-4517-aaad-38d5d6816e20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "\u001b[2mCONFIG\u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmode\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mppl_eval                                                                \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdiffusion\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mabsorbing_state                                                         \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mseed\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m1                                                                       \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mblock_size\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m128                                                                     \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdata\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mmax_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_train_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_valid_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_test_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtrain\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvalid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtokenizer_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbert-base-uncased                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcache_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/share/kuleshov/ssahoo/textdiffusion/data                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mwrap\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mstreaming\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mloader\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mglobal_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_global_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbatch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_workers\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mpin_memory\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2msampling\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mnoise_removal\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sample_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_length\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlogdir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m./samples_bd3lm_len128_blocksize128                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnucleus_p\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfirst_hitting\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mkv_cache\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtraining\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9999                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mantithetic_sampling\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcoeff_clip\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1.0                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresample\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnll_diagram\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfrom_pretrained\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_nll\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2meval\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.0\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdisable_ema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mperplexity_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcompute_perplexity_on_sanity\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgen_ppl_eval_model_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mgpt2-large                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgenerate_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2moptim\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mweight_decay\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlr\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0003                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta1\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta2\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.999                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0e-08                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtrainer\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.Trainer                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccelerator\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mcuda                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_nodes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdevices\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccumulate_grad_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgradient_clip_val\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mprecision\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbf16                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sanity_val_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m300                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlog_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1000                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_train_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_val_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mval_check_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mwandb\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mproject\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBD3-LMs                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnotes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBlock Denoising Discrete Diffusion Language Models               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgroup\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mjob_type\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mNone_1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtags\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcheckpointing\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40msave_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/180456                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_from_ckpt\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_ckpt_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/180456/checkpo\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcallbacks\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/180456/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mevery_n_train_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m500                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcheckpoint_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmonitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mval/nll                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmode\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mmin                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/180456/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mfilename\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbest                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlearning_rate_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.LearningRateMonitor             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mlogging_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mstep                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmodel\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtiny                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mddit                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mhidden_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m256                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcond_dim\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m64                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlength\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m128                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_blocks\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_heads\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mscale_by_sigma\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtie_word_embeddings\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40madaln\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mattn_backend\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msdpa                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mstrategy\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.strategies.DDPStrategy                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfind_unused_parameters\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mnoise\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0001                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m20                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mlr_scheduler\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtransformers.get_constant_schedule_with_warmup                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_warmup_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2500                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m└── \u001b[0m\u001b[2malgo\u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbd3lm                                                             \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbackbone\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mdit                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mparameterization\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msubs                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtime_conditioning\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mT\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                                    \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcausal_attention\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0                                                            \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mignore_bos\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcross_attn\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_delta\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.05                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_widths\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m[]                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfix_clipping\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                     \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampler\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msemi_ar                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmdlm_loss_scale\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "[2026-01-05 18:04:57,134][__main__][INFO] - Starting Eval.\n",
            "Loading checkpoint at 508\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0.001, max=1.0\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-05 18:05:07,408][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 18:05:07,408][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100% 100/100 [00:00<00:00, 2039.87 examples/s]\n",
            "Map: 100% 100/100 [00:00<00:00, 20842.30 examples/s]\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-05 18:06:10.943772: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767636370.961570    3499 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767636370.966849    3499 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767636370.980459    3499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636370.980485    3499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636370.980489    3499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636370.980493    3499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-05 18:06:10.984977: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_max     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_min     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0010000000474974513  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/bpd         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   11.024055480957031    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/nll         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    7.641293048858643    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/ppl         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     2082.4345703125     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    valid_var_0.0 - 1    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8090143203735352    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sync to drive\n",
        "!mkdir -p /content/drive/MyDrive/bd3lms_storage_final\n",
        "!rsync -av \\\n",
        "  /content/bd3lms/outputs/lm1b \\\n",
        "  /content/drive/MyDrive/bd3lms_storage_final"
      ],
      "metadata": {
        "id": "PXUuKN1n6dsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4449ae1c-f6f1-48d8-d771-053a2dbe68b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending incremental file list\n",
            "lm1b/\n",
            "lm1b/2026.01.05/\n",
            "lm1b/2026.01.05/022135/\n",
            "lm1b/2026.01.05/022135/.hydra/\n",
            "lm1b/2026.01.05/022135/checkpoints/\n",
            "lm1b/2026.01.05/024407/\n",
            "lm1b/2026.01.05/024407/config_tree.txt\n",
            "lm1b/2026.01.05/024407/main.log\n",
            "lm1b/2026.01.05/024407/.hydra/\n",
            "lm1b/2026.01.05/024407/.hydra/config.yaml\n",
            "lm1b/2026.01.05/024407/.hydra/hydra.yaml\n",
            "lm1b/2026.01.05/024407/.hydra/overrides.yaml\n",
            "lm1b/2026.01.05/024407/checkpoints/\n",
            "lm1b/2026.01.05/024407/checkpoints/best.ckpt\n",
            "lm1b/2026.01.05/024407/checkpoints/last.ckpt\n",
            "lm1b/2026.01.05/025009/\n",
            "lm1b/2026.01.05/025009/config_tree.txt\n",
            "lm1b/2026.01.05/025009/main.log\n",
            "lm1b/2026.01.05/025009/.hydra/\n",
            "lm1b/2026.01.05/025009/.hydra/config.yaml\n",
            "lm1b/2026.01.05/025009/.hydra/hydra.yaml\n",
            "lm1b/2026.01.05/025009/.hydra/overrides.yaml\n",
            "lm1b/2026.01.05/025009/checkpoints/\n",
            "lm1b/2026.01.05/025009/checkpoints/best.ckpt\n",
            "lm1b/2026.01.05/025009/checkpoints/last.ckpt\n",
            "\n",
            "sent 1,464,700,511 bytes  received 357 bytes  108,496,360.59 bytes/sec\n",
            "total size is 2,562,585,768  speedup is 1.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune block size 16, clipping\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=train \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=16 \\\n",
        "  trainer.devices=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  trainer.max_steps=600 \\\n",
        "  data.max_train_samples=500 \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100 \\\n",
        "  training.nll_diagram=False \\\n",
        "  algo.fix_clipping=False \\\n",
        "  training.sampling_eps_min=0.3 \\\n",
        "  training.sampling_eps_max=0.8 \\\n",
        "  checkpointing.resume_ckpt_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt 2>&1 | grep -v \"TQDMProgressBar\\|val_progress_bar\""
      ],
      "metadata": {
        "id": "pfmFJWQK6dei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd10d9e-72af-4934-a2fd-1ae1a94d333e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "CONFIG\n",
            "├── mode\n",
            "│   └── train                                                                   \n",
            "├── diffusion\n",
            "│   └── absorbing_state                                                         \n",
            "├── seed\n",
            "│   └── 1                                                                       \n",
            "├── block_size\n",
            "│   └── 16                                                                      \n",
            "├── data\n",
            "│   └── max_samples: null                                                       \n",
            "│       max_train_samples: 500                                                  \n",
            "│       max_valid_samples: 100                                                  \n",
            "│       max_test_samples: 100                                                   \n",
            "│       train: lm1b                                                             \n",
            "│       valid: lm1b                                                             \n",
            "│       tokenizer_name_or_path: bert-base-uncased                               \n",
            "│       cache_dir: /share/kuleshov/ssahoo/textdiffusion/data                    \n",
            "│       wrap: true                                                              \n",
            "│       streaming: true                                                         \n",
            "│                                                                               \n",
            "├── loader\n",
            "│   └── global_batch_size: 4                                                    \n",
            "│       eval_global_batch_size: 4                                               \n",
            "│       batch_size: 4                                                           \n",
            "│       eval_batch_size: 4                                                      \n",
            "│       num_workers: 1                                                          \n",
            "│       pin_memory: true                                                        \n",
            "│                                                                               \n",
            "├── sampling\n",
            "│   └── noise_removal: false                                                    \n",
            "│       num_sample_batches: 1                                                   \n",
            "│       var_length: false                                                       \n",
            "│       logdir: ./samples_bd3lm_len128_blocksize16                              \n",
            "│       nucleus_p: 1.0                                                          \n",
            "│       first_hitting: true                                                     \n",
            "│       kv_cache: false                                                         \n",
            "│                                                                               \n",
            "├── training\n",
            "│   └── ema: 0.9999                                                             \n",
            "│       antithetic_sampling: true                                               \n",
            "│       sampling_eps: 0.001                                                     \n",
            "│       coeff_clip: -1.0                                                        \n",
            "│       resample: false                                                         \n",
            "│       sampling_eps_min: 0.3                                                   \n",
            "│       sampling_eps_max: 0.8                                                   \n",
            "│       nll_diagram: false                                                      \n",
            "│       from_pretrained: null                                                   \n",
            "│       eval_nll: true                                                          \n",
            "│                                                                               \n",
            "├── eval\n",
            "│   └── checkpoint_path: /content/bd3lms/outputs/lm1b/2026.01.05/025849/checkpoi\n",
            "│       disable_ema: false                                                      \n",
            "│       perplexity_batch_size: 8                                                \n",
            "│       compute_perplexity_on_sanity: false                                     \n",
            "│       gen_ppl_eval_model_name_or_path: gpt2-large                             \n",
            "│       generate_samples: false                                                 \n",
            "│                                                                               \n",
            "├── optim\n",
            "│   └── weight_decay: 0                                                         \n",
            "│       lr: 0.0003                                                              \n",
            "│       beta1: 0.9                                                              \n",
            "│       beta2: 0.999                                                            \n",
            "│       eps: 1.0e-08                                                            \n",
            "│                                                                               \n",
            "├── trainer\n",
            "│   └── _target_: lightning.Trainer                                             \n",
            "│       accelerator: cuda                                                       \n",
            "│       num_nodes: 1                                                            \n",
            "│       devices: 1                                                              \n",
            "│       accumulate_grad_batches: 1                                              \n",
            "│       gradient_clip_val: 1.0                                                  \n",
            "│       precision: bf16                                                         \n",
            "│       num_sanity_val_steps: 2                                                 \n",
            "│       max_steps: 600                                                          \n",
            "│       log_every_n_steps: 1000                                                 \n",
            "│       limit_train_batches: 1.0                                                \n",
            "│       limit_val_batches: 1.0                                                  \n",
            "│       val_check_interval: 2                                                   \n",
            "│                                                                               \n",
            "├── wandb\n",
            "│   └── project: BD3-LMs                                                        \n",
            "│       notes: Block Denoising Discrete Diffusion Language Models               \n",
            "│       group: null                                                             \n",
            "│       job_type: null                                                          \n",
            "│       name: null                                                              \n",
            "│       id: None_1                                                              \n",
            "│       tags:                                                                   \n",
            "│       - loglinear                                                             \n",
            "│       - lm1b                                                                  \n",
            "│       - lm1b                                                                  \n",
            "│                                                                               \n",
            "├── checkpointing\n",
            "│   └── save_dir: /content/bd3lms/outputs/lm1b/2026.01.05/025849                \n",
            "│       resume_from_ckpt: true                                                  \n",
            "│       resume_ckpt_path: /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.\n",
            "│                                                                               \n",
            "├── callbacks\n",
            "│   └── checkpoint_every_n_steps:                                               \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         save_top_k: -1                                                        \n",
            "│         save_last: true                                                       \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/025849/checkpoints   \n",
            "│         verbose: true                                                         \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         every_n_train_steps: 500                                              \n",
            "│       checkpoint_monitor:                                                     \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         monitor: val/nll                                                      \n",
            "│         mode: min                                                             \n",
            "│         save_top_k: 1                                                         \n",
            "│         save_last: false                                                      \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/025849/checkpoints   \n",
            "│         filename: best                                                        \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         verbose: true                                                         \n",
            "│       learning_rate_monitor:                                                  \n",
            "│         _target_: lightning.pytorch.callbacks.LearningRateMonitor             \n",
            "│         logging_interval: step                                                \n",
            "│                                                                               \n",
            "├── model\n",
            "│   └── name: tiny                                                              \n",
            "│       type: ddit                                                              \n",
            "│       hidden_size: 256                                                        \n",
            "│       cond_dim: 64                                                            \n",
            "│       length: 128                                                             \n",
            "│       n_blocks: 8                                                             \n",
            "│       n_heads: 8                                                              \n",
            "│       scale_by_sigma: true                                                    \n",
            "│       dropout: 0.1                                                            \n",
            "│       tie_word_embeddings: true                                               \n",
            "│       adaln: false                                                            \n",
            "│       attn_backend: sdpa                                                      \n",
            "│                                                                               \n",
            "├── strategy\n",
            "│   └── _target_: lightning.pytorch.strategies.DDPStrategy                      \n",
            "│       find_unused_parameters: false                                           \n",
            "│                                                                               \n",
            "├── noise\n",
            "│   └── type: loglinear                                                         \n",
            "│       sigma_min: 0.0001                                                       \n",
            "│       sigma_max: 20                                                           \n",
            "│                                                                               \n",
            "├── lr_scheduler\n",
            "│   └── _target_: transformers.get_constant_schedule_with_warmup                \n",
            "│       num_warmup_steps: 2500                                                  \n",
            "│                                                                               \n",
            "└── algo\n",
            "    └── name: bd3lm                                                             \n",
            "        backbone: dit                                                           \n",
            "        parameterization: subs                                                  \n",
            "        time_conditioning: false                                                \n",
            "        T: 0                                                                    \n",
            "        causal_attention: false                                                 \n",
            "        dropout: 0.0                                                            \n",
            "        ignore_bos: true                                                        \n",
            "        cross_attn: true                                                        \n",
            "        var_min: true                                                           \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "                                                                                \n",
            "[2026-01-05 02:58:50,228][__main__][INFO] - Starting Training.\n",
            "[2026-01-05 02:58:50,238][__main__][INFO] - Resuming training at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "[2026-01-05 02:58:50,264][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_train_bs128_wrapped.dat\n",
            "[2026-01-05 02:58:50,264][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 500 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 500 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 2278.63 examples/s]\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 33380.85 examples/s]\n",
            "[2026-01-05 02:58:57,443][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 02:58:57,443][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 1231.68 examples/s]\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 12834.86 examples/s]\n",
            "Printing train dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] while athletes in different professions dealt with doping scandals and other controversies, woods continued to do what he did best : dominate the field of professional golf and rake in endorsements. [CLS] the minutes could shed light on an internal debate, which has been evident in fed officials'recent speeches, over when to consider raising rates.\n",
            "ids: tensor([  101,  2096,  7576,  1999,  2367, 22797,  9411,  2007, 23799, 29609,\n",
            "         1998,  2060, 25962,  1010,  5249,  2506,  2000,  2079,  2054,  2002,\n",
            "         2106,  2190,  1024, 16083,  1996,  2492,  1997,  2658,  5439,  1998,\n",
            "        26008,  1999, 20380,  2015,  1012,   101,  1996,  2781,  2071,  8328,\n",
            "         2422,  2006,  2019,  4722,  5981,  1010,  2029,  2038,  2042, 10358,\n",
            "         1999,  7349,  4584,  1005,  3522, 13867,  1010,  2058,  2043,  2000,\n",
            "         5136,  6274,  6165,  1012])\n",
            "Last 64 tokens: [CLS] but metro's definition of \" urbanite \" is not accurate, says matthew gandy, director of the urban laboratory at university college london. [CLS] goodrich petroleum is an independent oil and gas exploration and production company listed on the new york stock exchange. [CLS] the support from spears is to end on november 15 [CLS]\n",
            "ids: tensor([  101,  2021,  6005,  1005,  1055,  6210,  1997,  1000,  3923,  4221,\n",
            "         1000,  2003,  2025,  8321,  1010,  2758,  5487, 25957,  5149,  1010,\n",
            "         2472,  1997,  1996,  3923,  5911,  2012,  2118,  2267,  2414,  1012,\n",
            "          101,  2204, 13149, 11540,  2003,  2019,  2981,  3514,  1998,  3806,\n",
            "         8993,  1998,  2537,  2194,  3205,  2006,  1996,  2047,  2259,  4518,\n",
            "         3863,  1012,   101,  1996,  2490,  2013, 13957,  2003,  2000,  2203,\n",
            "         2006,  2281,  2321,   101])\n",
            "Printing valid dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] in medieval times, the townspeople from norcia were so practised at butchering pigs that they gained an in - depth knowledge of anatomy and were allowed to practise as surgeons along with members of the clergy. [CLS] the satellite weighs some 660 pounds, the israeli haaretz newspaper reported, citing unnamed company officials.\n",
            "ids: tensor([  101,  1999,  5781,  2335,  1010,  1996, 27938,  2013,  4496,  7405,\n",
            "         2020,  2061, 20439,  2012, 14998,  2075, 14695,  2008,  2027,  4227,\n",
            "         2019,  1999,  1011,  5995,  3716,  1997, 13336,  1998,  2020,  3039,\n",
            "         2000, 10975, 18908,  5562,  2004, 16804,  2247,  2007,  2372,  1997,\n",
            "         1996, 11646,  1012,   101,  1996,  5871, 21094,  2070, 20982,  7038,\n",
            "         1010,  1996,  5611,  5292, 12069,  5753,  3780,  2988,  1010,  8951,\n",
            "        13294,  2194,  4584,  1012])\n",
            "Last 64 tokens: [CLS] the situation has been further complicated by growing indications that the us treasury is preparing to make funds available for recapitalsing us banks. [CLS] as north korea's close neighbor, traditional ally and main provider of economic aid, china is widely believed to hold the key to solving the north korea conundrum. [CLS]\n",
            "ids: tensor([  101,  1996,  3663,  2038,  2042,  2582,  8552,  2011,  3652, 24936,\n",
            "         2008,  1996,  2149,  9837,  2003,  8225,  2000,  2191,  5029,  2800,\n",
            "         2005, 28667,  9331, 18400,  7741,  2149,  5085,  1012,   101,  2004,\n",
            "         2167,  4420,  1005,  1055,  2485, 11429,  1010,  3151,  9698,  1998,\n",
            "         2364, 10802,  1997,  3171,  4681,  1010,  2859,  2003,  4235,  3373,\n",
            "         2000,  2907,  1996,  3145,  2000, 13729,  1996,  2167,  4420,  9530,\n",
            "         8630,  6824,  1012,   101])\n",
            "[2026-01-05 03:00:38,868][__main__][INFO] - Initializing new model\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "wandb: WARNING The anonymous setting has no effect and will be removed in a future version.\n",
            "Restoring states from the checkpoint path at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:362: The dirpath has changed from '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints' to '/content/bd3lms/outputs/lm1b/2026.01.05/025849/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type           | Params | Mode \n",
            "----------------------------------------------------\n",
            "0 | backbone | DIT            | 22.8 M | train\n",
            "1 | noise    | LogLinearNoise | 0      | train\n",
            "----------------------------------------------------\n",
            "22.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "22.8 M    Total params\n",
            "91.266    Total estimated model params size (MB)\n",
            "110       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Restored all states from the checkpoint at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "Loading checkpoint at 500\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0.3, max=0.8\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py:221: You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.\n",
            "Epoch 16, global step 504: 'val/nll' reached 8.15932 (best 8.15932), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/025849/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 506: 'val/nll' reached 7.08118 (best 7.08118), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/025849/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 508: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 510: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 512: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 514: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 516: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 518: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 520: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 522: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 524: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 526: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 528: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 530: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 532: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 534: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 536: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 538: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 540: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 542: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 544: 'val/nll' reached 7.05970 (best 7.05970), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/025849/checkpoints/best.ckpt' as top 1\n",
            "Epoch 18, global step 546: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 548: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 550: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 552: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 554: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 556: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 558: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 560: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 562: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 564: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 566: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 568: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 570: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 572: 'val/nll' reached 6.87732 (best 6.87732), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/025849/checkpoints/best.ckpt' as top 1\n",
            "Epoch 19, global step 574: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 576: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 578: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 580: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 582: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 584: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 586: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 588: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 590: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 592: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 594: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 596: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 598: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 600: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=600` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eval_bd3lm_best block size 16, clipping\n",
        "\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=ppl_eval \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=16 \\\n",
        "  trainer.devices=1 \\\n",
        "  trainer.num_nodes=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  eval.checkpoint_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/025849/checkpoints/best.ckpt \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100"
      ],
      "metadata": {
        "id": "r6SQkFUT6dbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d387d67-a995-4da4-d159-a4bed810469a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "\u001b[2mCONFIG\u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmode\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mppl_eval                                                                \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdiffusion\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mabsorbing_state                                                         \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mseed\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m1                                                                       \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mblock_size\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m16                                                                      \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdata\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mmax_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_train_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_valid_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_test_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtrain\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvalid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtokenizer_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbert-base-uncased                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcache_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/share/kuleshov/ssahoo/textdiffusion/data                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mwrap\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mstreaming\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mloader\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mglobal_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_global_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbatch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_workers\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mpin_memory\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2msampling\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mnoise_removal\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sample_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_length\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlogdir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m./samples_bd3lm_len128_blocksize16                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnucleus_p\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfirst_hitting\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mkv_cache\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtraining\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9999                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mantithetic_sampling\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcoeff_clip\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1.0                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresample\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnll_diagram\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfrom_pretrained\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_nll\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2meval\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.0\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdisable_ema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mperplexity_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcompute_perplexity_on_sanity\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgen_ppl_eval_model_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mgpt2-large                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgenerate_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2moptim\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mweight_decay\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlr\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0003                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta1\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta2\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.999                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0e-08                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtrainer\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.Trainer                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccelerator\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mcuda                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_nodes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdevices\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccumulate_grad_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgradient_clip_val\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mprecision\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbf16                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sanity_val_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m300                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlog_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1000                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_train_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_val_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mval_check_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mwandb\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mproject\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBD3-LMs                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnotes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBlock Denoising Discrete Diffusion Language Models               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgroup\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mjob_type\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mNone_1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtags\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcheckpointing\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40msave_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181120                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_from_ckpt\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_ckpt_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181120/checkpo\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcallbacks\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181120/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mevery_n_train_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m500                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcheckpoint_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmonitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mval/nll                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmode\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mmin                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181120/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mfilename\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbest                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlearning_rate_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.LearningRateMonitor             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mlogging_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mstep                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmodel\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtiny                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mddit                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mhidden_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m256                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcond_dim\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m64                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlength\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m128                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_blocks\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_heads\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mscale_by_sigma\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtie_word_embeddings\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40madaln\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mattn_backend\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msdpa                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mstrategy\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.strategies.DDPStrategy                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfind_unused_parameters\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mnoise\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0001                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m20                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mlr_scheduler\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtransformers.get_constant_schedule_with_warmup                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_warmup_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2500                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m└── \u001b[0m\u001b[2malgo\u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbd3lm                                                             \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbackbone\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mdit                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mparameterization\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msubs                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtime_conditioning\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mT\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                                    \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcausal_attention\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0                                                            \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mignore_bos\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcross_attn\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_delta\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.05                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_widths\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m[]                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfix_clipping\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                     \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampler\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msemi_ar                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmdlm_loss_scale\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "[2026-01-05 18:11:21,346][__main__][INFO] - Starting Eval.\n",
            "Loading checkpoint at 572\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0.001, max=1.0\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-05 18:11:37,151][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 18:11:37,152][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100% 100/100 [00:00<00:00, 2106.27 examples/s]\n",
            "Map: 100% 100/100 [00:00<00:00, 21552.36 examples/s]\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-05 18:12:41.679224: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767636761.709054    5181 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767636761.717819    5181 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767636761.739275    5181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636761.739322    5181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636761.739331    5181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636761.739338    5181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-05 18:12:41.745690: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_max     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_min     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0010000000474974513  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/bpd         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   10.191167831420898    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/nll         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    7.063979148864746    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/ppl         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     1169.087890625      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    valid_var_0.0 - 1    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   15.276239395141602    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune block size 16, no clipping\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=train \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=16 \\\n",
        "  trainer.devices=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  trainer.max_steps=600 \\\n",
        "  data.max_train_samples=500 \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100 \\\n",
        "  training.nll_diagram=False \\\n",
        "  algo.fix_clipping=False \\\n",
        "  training.sampling_eps_min=0 \\\n",
        "  training.sampling_eps_max=1 \\\n",
        "  checkpointing.resume_ckpt_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt 2>&1 | grep -v \"TQDMProgressBar\\|val_progress_bar\""
      ],
      "metadata": {
        "id": "0OsrDqXU6dY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b857fb-56bc-4757-90bd-0166ccb3bc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "CONFIG\n",
            "├── mode\n",
            "│   └── train                                                                   \n",
            "├── diffusion\n",
            "│   └── absorbing_state                                                         \n",
            "├── seed\n",
            "│   └── 1                                                                       \n",
            "├── block_size\n",
            "│   └── 16                                                                      \n",
            "├── data\n",
            "│   └── max_samples: null                                                       \n",
            "│       max_train_samples: 500                                                  \n",
            "│       max_valid_samples: 100                                                  \n",
            "│       max_test_samples: 100                                                   \n",
            "│       train: lm1b                                                             \n",
            "│       valid: lm1b                                                             \n",
            "│       tokenizer_name_or_path: bert-base-uncased                               \n",
            "│       cache_dir: /share/kuleshov/ssahoo/textdiffusion/data                    \n",
            "│       wrap: true                                                              \n",
            "│       streaming: true                                                         \n",
            "│                                                                               \n",
            "├── loader\n",
            "│   └── global_batch_size: 4                                                    \n",
            "│       eval_global_batch_size: 4                                               \n",
            "│       batch_size: 4                                                           \n",
            "│       eval_batch_size: 4                                                      \n",
            "│       num_workers: 1                                                          \n",
            "│       pin_memory: true                                                        \n",
            "│                                                                               \n",
            "├── sampling\n",
            "│   └── noise_removal: false                                                    \n",
            "│       num_sample_batches: 1                                                   \n",
            "│       var_length: false                                                       \n",
            "│       logdir: ./samples_bd3lm_len128_blocksize16                              \n",
            "│       nucleus_p: 1.0                                                          \n",
            "│       first_hitting: true                                                     \n",
            "│       kv_cache: false                                                         \n",
            "│                                                                               \n",
            "├── training\n",
            "│   └── ema: 0.9999                                                             \n",
            "│       antithetic_sampling: true                                               \n",
            "│       sampling_eps: 0.001                                                     \n",
            "│       coeff_clip: -1.0                                                        \n",
            "│       resample: false                                                         \n",
            "│       sampling_eps_min: 0                                                     \n",
            "│       sampling_eps_max: 1                                                     \n",
            "│       nll_diagram: false                                                      \n",
            "│       from_pretrained: null                                                   \n",
            "│       eval_nll: true                                                          \n",
            "│                                                                               \n",
            "├── eval\n",
            "│   └── checkpoint_path: /content/bd3lms/outputs/lm1b/2026.01.05/030413/checkpoi\n",
            "│       disable_ema: false                                                      \n",
            "│       perplexity_batch_size: 8                                                \n",
            "│       compute_perplexity_on_sanity: false                                     \n",
            "│       gen_ppl_eval_model_name_or_path: gpt2-large                             \n",
            "│       generate_samples: false                                                 \n",
            "│                                                                               \n",
            "├── optim\n",
            "│   └── weight_decay: 0                                                         \n",
            "│       lr: 0.0003                                                              \n",
            "│       beta1: 0.9                                                              \n",
            "│       beta2: 0.999                                                            \n",
            "│       eps: 1.0e-08                                                            \n",
            "│                                                                               \n",
            "├── trainer\n",
            "│   └── _target_: lightning.Trainer                                             \n",
            "│       accelerator: cuda                                                       \n",
            "│       num_nodes: 1                                                            \n",
            "│       devices: 1                                                              \n",
            "│       accumulate_grad_batches: 1                                              \n",
            "│       gradient_clip_val: 1.0                                                  \n",
            "│       precision: bf16                                                         \n",
            "│       num_sanity_val_steps: 2                                                 \n",
            "│       max_steps: 600                                                          \n",
            "│       log_every_n_steps: 1000                                                 \n",
            "│       limit_train_batches: 1.0                                                \n",
            "│       limit_val_batches: 1.0                                                  \n",
            "│       val_check_interval: 2                                                   \n",
            "│                                                                               \n",
            "├── wandb\n",
            "│   └── project: BD3-LMs                                                        \n",
            "│       notes: Block Denoising Discrete Diffusion Language Models               \n",
            "│       group: null                                                             \n",
            "│       job_type: null                                                          \n",
            "│       name: null                                                              \n",
            "│       id: None_1                                                              \n",
            "│       tags:                                                                   \n",
            "│       - loglinear                                                             \n",
            "│       - lm1b                                                                  \n",
            "│       - lm1b                                                                  \n",
            "│                                                                               \n",
            "├── checkpointing\n",
            "│   └── save_dir: /content/bd3lms/outputs/lm1b/2026.01.05/030413                \n",
            "│       resume_from_ckpt: true                                                  \n",
            "│       resume_ckpt_path: /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.\n",
            "│                                                                               \n",
            "├── callbacks\n",
            "│   └── checkpoint_every_n_steps:                                               \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         save_top_k: -1                                                        \n",
            "│         save_last: true                                                       \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/030413/checkpoints   \n",
            "│         verbose: true                                                         \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         every_n_train_steps: 500                                              \n",
            "│       checkpoint_monitor:                                                     \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         monitor: val/nll                                                      \n",
            "│         mode: min                                                             \n",
            "│         save_top_k: 1                                                         \n",
            "│         save_last: false                                                      \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/030413/checkpoints   \n",
            "│         filename: best                                                        \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         verbose: true                                                         \n",
            "│       learning_rate_monitor:                                                  \n",
            "│         _target_: lightning.pytorch.callbacks.LearningRateMonitor             \n",
            "│         logging_interval: step                                                \n",
            "│                                                                               \n",
            "├── model\n",
            "│   └── name: tiny                                                              \n",
            "│       type: ddit                                                              \n",
            "│       hidden_size: 256                                                        \n",
            "│       cond_dim: 64                                                            \n",
            "│       length: 128                                                             \n",
            "│       n_blocks: 8                                                             \n",
            "│       n_heads: 8                                                              \n",
            "│       scale_by_sigma: true                                                    \n",
            "│       dropout: 0.1                                                            \n",
            "│       tie_word_embeddings: true                                               \n",
            "│       adaln: false                                                            \n",
            "│       attn_backend: sdpa                                                      \n",
            "│                                                                               \n",
            "├── strategy\n",
            "│   └── _target_: lightning.pytorch.strategies.DDPStrategy                      \n",
            "│       find_unused_parameters: false                                           \n",
            "│                                                                               \n",
            "├── noise\n",
            "│   └── type: loglinear                                                         \n",
            "│       sigma_min: 0.0001                                                       \n",
            "│       sigma_max: 20                                                           \n",
            "│                                                                               \n",
            "├── lr_scheduler\n",
            "│   └── _target_: transformers.get_constant_schedule_with_warmup                \n",
            "│       num_warmup_steps: 2500                                                  \n",
            "│                                                                               \n",
            "└── algo\n",
            "    └── name: bd3lm                                                             \n",
            "        backbone: dit                                                           \n",
            "        parameterization: subs                                                  \n",
            "        time_conditioning: false                                                \n",
            "        T: 0                                                                    \n",
            "        causal_attention: false                                                 \n",
            "        dropout: 0.0                                                            \n",
            "        ignore_bos: true                                                        \n",
            "        cross_attn: true                                                        \n",
            "        var_min: true                                                           \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "                                                                                \n",
            "[2026-01-05 03:04:14,079][__main__][INFO] - Starting Training.\n",
            "[2026-01-05 03:04:14,091][__main__][INFO] - Resuming training at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "[2026-01-05 03:04:14,127][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_train_bs128_wrapped.dat\n",
            "[2026-01-05 03:04:14,128][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 500 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 500 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 2173.17 examples/s]\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 35754.63 examples/s]\n",
            "[2026-01-05 03:04:18,930][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 03:04:18,930][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 2143.64 examples/s]\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 20724.89 examples/s]\n",
            "Printing train dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] while athletes in different professions dealt with doping scandals and other controversies, woods continued to do what he did best : dominate the field of professional golf and rake in endorsements. [CLS] the minutes could shed light on an internal debate, which has been evident in fed officials'recent speeches, over when to consider raising rates.\n",
            "ids: tensor([  101,  2096,  7576,  1999,  2367, 22797,  9411,  2007, 23799, 29609,\n",
            "         1998,  2060, 25962,  1010,  5249,  2506,  2000,  2079,  2054,  2002,\n",
            "         2106,  2190,  1024, 16083,  1996,  2492,  1997,  2658,  5439,  1998,\n",
            "        26008,  1999, 20380,  2015,  1012,   101,  1996,  2781,  2071,  8328,\n",
            "         2422,  2006,  2019,  4722,  5981,  1010,  2029,  2038,  2042, 10358,\n",
            "         1999,  7349,  4584,  1005,  3522, 13867,  1010,  2058,  2043,  2000,\n",
            "         5136,  6274,  6165,  1012])\n",
            "Last 64 tokens: [CLS] but metro's definition of \" urbanite \" is not accurate, says matthew gandy, director of the urban laboratory at university college london. [CLS] goodrich petroleum is an independent oil and gas exploration and production company listed on the new york stock exchange. [CLS] the support from spears is to end on november 15 [CLS]\n",
            "ids: tensor([  101,  2021,  6005,  1005,  1055,  6210,  1997,  1000,  3923,  4221,\n",
            "         1000,  2003,  2025,  8321,  1010,  2758,  5487, 25957,  5149,  1010,\n",
            "         2472,  1997,  1996,  3923,  5911,  2012,  2118,  2267,  2414,  1012,\n",
            "          101,  2204, 13149, 11540,  2003,  2019,  2981,  3514,  1998,  3806,\n",
            "         8993,  1998,  2537,  2194,  3205,  2006,  1996,  2047,  2259,  4518,\n",
            "         3863,  1012,   101,  1996,  2490,  2013, 13957,  2003,  2000,  2203,\n",
            "         2006,  2281,  2321,   101])\n",
            "Printing valid dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] in medieval times, the townspeople from norcia were so practised at butchering pigs that they gained an in - depth knowledge of anatomy and were allowed to practise as surgeons along with members of the clergy. [CLS] the satellite weighs some 660 pounds, the israeli haaretz newspaper reported, citing unnamed company officials.\n",
            "ids: tensor([  101,  1999,  5781,  2335,  1010,  1996, 27938,  2013,  4496,  7405,\n",
            "         2020,  2061, 20439,  2012, 14998,  2075, 14695,  2008,  2027,  4227,\n",
            "         2019,  1999,  1011,  5995,  3716,  1997, 13336,  1998,  2020,  3039,\n",
            "         2000, 10975, 18908,  5562,  2004, 16804,  2247,  2007,  2372,  1997,\n",
            "         1996, 11646,  1012,   101,  1996,  5871, 21094,  2070, 20982,  7038,\n",
            "         1010,  1996,  5611,  5292, 12069,  5753,  3780,  2988,  1010,  8951,\n",
            "        13294,  2194,  4584,  1012])\n",
            "Last 64 tokens: [CLS] the situation has been further complicated by growing indications that the us treasury is preparing to make funds available for recapitalsing us banks. [CLS] as north korea's close neighbor, traditional ally and main provider of economic aid, china is widely believed to hold the key to solving the north korea conundrum. [CLS]\n",
            "ids: tensor([  101,  1996,  3663,  2038,  2042,  2582,  8552,  2011,  3652, 24936,\n",
            "         2008,  1996,  2149,  9837,  2003,  8225,  2000,  2191,  5029,  2800,\n",
            "         2005, 28667,  9331, 18400,  7741,  2149,  5085,  1012,   101,  2004,\n",
            "         2167,  4420,  1005,  1055,  2485, 11429,  1010,  3151,  9698,  1998,\n",
            "         2364, 10802,  1997,  3171,  4681,  1010,  2859,  2003,  4235,  3373,\n",
            "         2000,  2907,  1996,  3145,  2000, 13729,  1996,  2167,  4420,  9530,\n",
            "         8630,  6824,  1012,   101])\n",
            "[2026-01-05 03:06:08,128][__main__][INFO] - Initializing new model\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "wandb: WARNING The anonymous setting has no effect and will be removed in a future version.\n",
            "Restoring states from the checkpoint path at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:362: The dirpath has changed from '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints' to '/content/bd3lms/outputs/lm1b/2026.01.05/030413/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type           | Params | Mode \n",
            "----------------------------------------------------\n",
            "0 | backbone | DIT            | 22.8 M | train\n",
            "1 | noise    | LogLinearNoise | 0      | train\n",
            "----------------------------------------------------\n",
            "22.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "22.8 M    Total params\n",
            "91.266    Total estimated model params size (MB)\n",
            "110       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Restored all states from the checkpoint at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "Loading checkpoint at 500\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0, max=1\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py:221: You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.\n",
            "Epoch 16, global step 504: 'val/nll' reached 8.15934 (best 8.15934), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/030413/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 506: 'val/nll' reached 7.08132 (best 7.08132), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/030413/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 508: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 510: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 512: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 514: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 516: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 518: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 520: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 522: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 524: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 526: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 528: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 530: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 532: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 534: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 536: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 538: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 540: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 542: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 544: 'val/nll' reached 7.05578 (best 7.05578), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/030413/checkpoints/best.ckpt' as top 1\n",
            "Epoch 18, global step 546: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 548: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 550: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 552: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 554: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 556: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 558: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 560: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 562: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 564: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 566: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 568: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 570: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 572: 'val/nll' reached 6.87670 (best 6.87670), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/030413/checkpoints/best.ckpt' as top 1\n",
            "Epoch 19, global step 574: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 576: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 578: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 580: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 582: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 584: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 586: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 588: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 590: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 592: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 594: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 596: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 598: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 600: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=600` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eval_bd3lm_best block size 16, no clipping\n",
        "\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=ppl_eval \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=16 \\\n",
        "  trainer.devices=1 \\\n",
        "  trainer.num_nodes=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  eval.checkpoint_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/030413/checkpoints/best.ckpt \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100"
      ],
      "metadata": {
        "id": "txZREkvQ6f0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c13c46-9c87-4146-bd58-4d0a8464f6df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "\u001b[2mCONFIG\u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmode\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mppl_eval                                                                \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdiffusion\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mabsorbing_state                                                         \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mseed\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m1                                                                       \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mblock_size\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m16                                                                      \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdata\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mmax_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_train_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_valid_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_test_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtrain\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvalid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtokenizer_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbert-base-uncased                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcache_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/share/kuleshov/ssahoo/textdiffusion/data                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mwrap\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mstreaming\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mloader\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mglobal_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_global_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbatch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_workers\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mpin_memory\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2msampling\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mnoise_removal\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sample_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_length\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlogdir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m./samples_bd3lm_len128_blocksize16                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnucleus_p\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfirst_hitting\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mkv_cache\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtraining\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9999                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mantithetic_sampling\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcoeff_clip\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1.0                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresample\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnll_diagram\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfrom_pretrained\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_nll\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2meval\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.0\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdisable_ema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mperplexity_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcompute_perplexity_on_sanity\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgen_ppl_eval_model_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mgpt2-large                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgenerate_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2moptim\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mweight_decay\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlr\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0003                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta1\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta2\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.999                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0e-08                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtrainer\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.Trainer                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccelerator\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mcuda                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_nodes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdevices\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccumulate_grad_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgradient_clip_val\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mprecision\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbf16                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sanity_val_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m300                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlog_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1000                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_train_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_val_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mval_check_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mwandb\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mproject\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBD3-LMs                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnotes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBlock Denoising Discrete Diffusion Language Models               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgroup\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mjob_type\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mNone_1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtags\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcheckpointing\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40msave_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181306                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_from_ckpt\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_ckpt_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181306/checkpo\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcallbacks\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181306/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mevery_n_train_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m500                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcheckpoint_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmonitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mval/nll                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmode\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mmin                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181306/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mfilename\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbest                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlearning_rate_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.LearningRateMonitor             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mlogging_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mstep                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmodel\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtiny                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mddit                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mhidden_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m256                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcond_dim\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m64                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlength\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m128                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_blocks\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_heads\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mscale_by_sigma\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtie_word_embeddings\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40madaln\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mattn_backend\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msdpa                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mstrategy\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.strategies.DDPStrategy                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfind_unused_parameters\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mnoise\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0001                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m20                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mlr_scheduler\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtransformers.get_constant_schedule_with_warmup                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_warmup_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2500                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m└── \u001b[0m\u001b[2malgo\u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbd3lm                                                             \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbackbone\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mdit                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mparameterization\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msubs                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtime_conditioning\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mT\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                                    \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcausal_attention\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0                                                            \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mignore_bos\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcross_attn\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_delta\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.05                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_widths\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m[]                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfix_clipping\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                     \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampler\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msemi_ar                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmdlm_loss_scale\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "[2026-01-05 18:13:06,973][__main__][INFO] - Starting Eval.\n",
            "Loading checkpoint at 572\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0.001, max=1.0\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-05 18:13:17,598][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 18:13:17,598][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100% 100/100 [00:00<00:00, 1350.55 examples/s]\n",
            "Map: 100% 100/100 [00:00<00:00, 20188.22 examples/s]\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-05 18:14:22.215364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767636862.233626    5669 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767636862.238976    5669 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767636862.252968    5669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636862.252991    5669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636862.252997    5669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767636862.253000    5669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-05 18:14:22.257309: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_max     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_min     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0010000000474974513  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/bpd         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    10.19039249420166    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/nll         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    7.063441753387451    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/ppl         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1168.4598388671875    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    valid_var_0.0 - 1    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   15.259631156921387    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sync to drive\n",
        "!mkdir -p /content/drive/MyDrive/bd3lms_storage_final\n",
        "!rsync -av \\\n",
        "  /content/bd3lms/outputs/lm1b \\\n",
        "  /content/drive/MyDrive/bd3lms_storage_final"
      ],
      "metadata": {
        "id": "7CIK5tfz6fx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2ae202-2676-4bb6-dac1-859e34f29fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending incremental file list\n",
            "lm1b/\n",
            "lm1b/2026.01.05/\n",
            "lm1b/2026.01.05/022135/\n",
            "lm1b/2026.01.05/022135/.hydra/\n",
            "lm1b/2026.01.05/022135/checkpoints/\n",
            "lm1b/2026.01.05/024407/\n",
            "lm1b/2026.01.05/024407/.hydra/\n",
            "lm1b/2026.01.05/024407/checkpoints/\n",
            "lm1b/2026.01.05/025009/\n",
            "lm1b/2026.01.05/025009/.hydra/\n",
            "lm1b/2026.01.05/025009/checkpoints/\n",
            "lm1b/2026.01.05/025827/\n",
            "lm1b/2026.01.05/025827/config_tree.txt\n",
            "lm1b/2026.01.05/025827/main.log\n",
            "lm1b/2026.01.05/025827/.hydra/\n",
            "lm1b/2026.01.05/025827/.hydra/config.yaml\n",
            "lm1b/2026.01.05/025827/.hydra/hydra.yaml\n",
            "lm1b/2026.01.05/025827/.hydra/overrides.yaml\n",
            "lm1b/2026.01.05/025838/\n",
            "lm1b/2026.01.05/025838/config_tree.txt\n",
            "lm1b/2026.01.05/025838/main.log\n",
            "lm1b/2026.01.05/025838/.hydra/\n",
            "lm1b/2026.01.05/025838/.hydra/config.yaml\n",
            "lm1b/2026.01.05/025838/.hydra/hydra.yaml\n",
            "lm1b/2026.01.05/025838/.hydra/overrides.yaml\n",
            "lm1b/2026.01.05/025849/\n",
            "lm1b/2026.01.05/025849/config_tree.txt\n",
            "lm1b/2026.01.05/025849/main.log\n",
            "lm1b/2026.01.05/025849/.hydra/\n",
            "lm1b/2026.01.05/025849/.hydra/config.yaml\n",
            "lm1b/2026.01.05/025849/.hydra/hydra.yaml\n",
            "lm1b/2026.01.05/025849/.hydra/overrides.yaml\n",
            "lm1b/2026.01.05/025849/checkpoints/\n",
            "lm1b/2026.01.05/025849/checkpoints/best.ckpt\n",
            "lm1b/2026.01.05/025849/checkpoints/last.ckpt\n",
            "lm1b/2026.01.05/030413/\n",
            "lm1b/2026.01.05/030413/config_tree.txt\n",
            "lm1b/2026.01.05/030413/main.log\n",
            "lm1b/2026.01.05/030413/.hydra/\n",
            "lm1b/2026.01.05/030413/.hydra/config.yaml\n",
            "lm1b/2026.01.05/030413/.hydra/hydra.yaml\n",
            "lm1b/2026.01.05/030413/.hydra/overrides.yaml\n",
            "lm1b/2026.01.05/030413/checkpoints/\n",
            "lm1b/2026.01.05/030413/checkpoints/best.ckpt\n",
            "lm1b/2026.01.05/030413/checkpoints/last.ckpt\n",
            "\n",
            "sent 1,464,742,855 bytes  received 625 bytes  154,183,524.21 bytes/sec\n",
            "total size is 4,026,967,980  speedup is 2.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune block size 4, clipping\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=train \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=4 \\\n",
        "  trainer.devices=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  trainer.max_steps=600 \\\n",
        "  data.max_train_samples=500 \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100 \\\n",
        "  training.nll_diagram=False \\\n",
        "  algo.fix_clipping=False \\\n",
        "  training.sampling_eps_min=0.5 \\\n",
        "  training.sampling_eps_max=1 \\\n",
        "  checkpointing.resume_ckpt_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt 2>&1 | grep -v \"TQDMProgressBar\\|val_progress_bar\""
      ],
      "metadata": {
        "id": "Zs_rWbiP6fvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9db968-cb91-4b15-f9dd-e6c0c60721db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "CONFIG\n",
            "├── mode\n",
            "│   └── train                                                                   \n",
            "├── diffusion\n",
            "│   └── absorbing_state                                                         \n",
            "├── seed\n",
            "│   └── 1                                                                       \n",
            "├── block_size\n",
            "│   └── 4                                                                       \n",
            "├── data\n",
            "│   └── max_samples: null                                                       \n",
            "│       max_train_samples: 500                                                  \n",
            "│       max_valid_samples: 100                                                  \n",
            "│       max_test_samples: 100                                                   \n",
            "│       train: lm1b                                                             \n",
            "│       valid: lm1b                                                             \n",
            "│       tokenizer_name_or_path: bert-base-uncased                               \n",
            "│       cache_dir: /share/kuleshov/ssahoo/textdiffusion/data                    \n",
            "│       wrap: true                                                              \n",
            "│       streaming: true                                                         \n",
            "│                                                                               \n",
            "├── loader\n",
            "│   └── global_batch_size: 4                                                    \n",
            "│       eval_global_batch_size: 4                                               \n",
            "│       batch_size: 4                                                           \n",
            "│       eval_batch_size: 4                                                      \n",
            "│       num_workers: 1                                                          \n",
            "│       pin_memory: true                                                        \n",
            "│                                                                               \n",
            "├── sampling\n",
            "│   └── noise_removal: false                                                    \n",
            "│       num_sample_batches: 1                                                   \n",
            "│       var_length: false                                                       \n",
            "│       logdir: ./samples_bd3lm_len128_blocksize4                               \n",
            "│       nucleus_p: 1.0                                                          \n",
            "│       first_hitting: true                                                     \n",
            "│       kv_cache: false                                                         \n",
            "│                                                                               \n",
            "├── training\n",
            "│   └── ema: 0.9999                                                             \n",
            "│       antithetic_sampling: true                                               \n",
            "│       sampling_eps: 0.001                                                     \n",
            "│       coeff_clip: -1.0                                                        \n",
            "│       resample: false                                                         \n",
            "│       sampling_eps_min: 0.5                                                   \n",
            "│       sampling_eps_max: 1                                                     \n",
            "│       nll_diagram: false                                                      \n",
            "│       from_pretrained: null                                                   \n",
            "│       eval_nll: true                                                          \n",
            "│                                                                               \n",
            "├── eval\n",
            "│   └── checkpoint_path: /content/bd3lms/outputs/lm1b/2026.01.05/031018/checkpoi\n",
            "│       disable_ema: false                                                      \n",
            "│       perplexity_batch_size: 8                                                \n",
            "│       compute_perplexity_on_sanity: false                                     \n",
            "│       gen_ppl_eval_model_name_or_path: gpt2-large                             \n",
            "│       generate_samples: false                                                 \n",
            "│                                                                               \n",
            "├── optim\n",
            "│   └── weight_decay: 0                                                         \n",
            "│       lr: 0.0003                                                              \n",
            "│       beta1: 0.9                                                              \n",
            "│       beta2: 0.999                                                            \n",
            "│       eps: 1.0e-08                                                            \n",
            "│                                                                               \n",
            "├── trainer\n",
            "│   └── _target_: lightning.Trainer                                             \n",
            "│       accelerator: cuda                                                       \n",
            "│       num_nodes: 1                                                            \n",
            "│       devices: 1                                                              \n",
            "│       accumulate_grad_batches: 1                                              \n",
            "│       gradient_clip_val: 1.0                                                  \n",
            "│       precision: bf16                                                         \n",
            "│       num_sanity_val_steps: 2                                                 \n",
            "│       max_steps: 600                                                          \n",
            "│       log_every_n_steps: 1000                                                 \n",
            "│       limit_train_batches: 1.0                                                \n",
            "│       limit_val_batches: 1.0                                                  \n",
            "│       val_check_interval: 2                                                   \n",
            "│                                                                               \n",
            "├── wandb\n",
            "│   └── project: BD3-LMs                                                        \n",
            "│       notes: Block Denoising Discrete Diffusion Language Models               \n",
            "│       group: null                                                             \n",
            "│       job_type: null                                                          \n",
            "│       name: null                                                              \n",
            "│       id: None_1                                                              \n",
            "│       tags:                                                                   \n",
            "│       - loglinear                                                             \n",
            "│       - lm1b                                                                  \n",
            "│       - lm1b                                                                  \n",
            "│                                                                               \n",
            "├── checkpointing\n",
            "│   └── save_dir: /content/bd3lms/outputs/lm1b/2026.01.05/031018                \n",
            "│       resume_from_ckpt: true                                                  \n",
            "│       resume_ckpt_path: /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.\n",
            "│                                                                               \n",
            "├── callbacks\n",
            "│   └── checkpoint_every_n_steps:                                               \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         save_top_k: -1                                                        \n",
            "│         save_last: true                                                       \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/031018/checkpoints   \n",
            "│         verbose: true                                                         \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         every_n_train_steps: 500                                              \n",
            "│       checkpoint_monitor:                                                     \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         monitor: val/nll                                                      \n",
            "│         mode: min                                                             \n",
            "│         save_top_k: 1                                                         \n",
            "│         save_last: false                                                      \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/031018/checkpoints   \n",
            "│         filename: best                                                        \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         verbose: true                                                         \n",
            "│       learning_rate_monitor:                                                  \n",
            "│         _target_: lightning.pytorch.callbacks.LearningRateMonitor             \n",
            "│         logging_interval: step                                                \n",
            "│                                                                               \n",
            "├── model\n",
            "│   └── name: tiny                                                              \n",
            "│       type: ddit                                                              \n",
            "│       hidden_size: 256                                                        \n",
            "│       cond_dim: 64                                                            \n",
            "│       length: 128                                                             \n",
            "│       n_blocks: 8                                                             \n",
            "│       n_heads: 8                                                              \n",
            "│       scale_by_sigma: true                                                    \n",
            "│       dropout: 0.1                                                            \n",
            "│       tie_word_embeddings: true                                               \n",
            "│       adaln: false                                                            \n",
            "│       attn_backend: sdpa                                                      \n",
            "│                                                                               \n",
            "├── strategy\n",
            "│   └── _target_: lightning.pytorch.strategies.DDPStrategy                      \n",
            "│       find_unused_parameters: false                                           \n",
            "│                                                                               \n",
            "├── noise\n",
            "│   └── type: loglinear                                                         \n",
            "│       sigma_min: 0.0001                                                       \n",
            "│       sigma_max: 20                                                           \n",
            "│                                                                               \n",
            "├── lr_scheduler\n",
            "│   └── _target_: transformers.get_constant_schedule_with_warmup                \n",
            "│       num_warmup_steps: 2500                                                  \n",
            "│                                                                               \n",
            "└── algo\n",
            "    └── name: bd3lm                                                             \n",
            "        backbone: dit                                                           \n",
            "        parameterization: subs                                                  \n",
            "        time_conditioning: false                                                \n",
            "        T: 0                                                                    \n",
            "        causal_attention: false                                                 \n",
            "        dropout: 0.0                                                            \n",
            "        ignore_bos: true                                                        \n",
            "        cross_attn: true                                                        \n",
            "        var_min: true                                                           \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "                                                                                \n",
            "[2026-01-05 03:10:18,779][__main__][INFO] - Starting Training.\n",
            "[2026-01-05 03:10:18,787][__main__][INFO] - Resuming training at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "[2026-01-05 03:10:18,812][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_train_bs128_wrapped.dat\n",
            "[2026-01-05 03:10:18,812][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 500 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 500 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 2335.33 examples/s]\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 36142.21 examples/s]\n",
            "[2026-01-05 03:10:24,745][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 03:10:24,745][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 2325.96 examples/s]\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 21985.03 examples/s]\n",
            "Printing train dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] while athletes in different professions dealt with doping scandals and other controversies, woods continued to do what he did best : dominate the field of professional golf and rake in endorsements. [CLS] the minutes could shed light on an internal debate, which has been evident in fed officials'recent speeches, over when to consider raising rates.\n",
            "ids: tensor([  101,  2096,  7576,  1999,  2367, 22797,  9411,  2007, 23799, 29609,\n",
            "         1998,  2060, 25962,  1010,  5249,  2506,  2000,  2079,  2054,  2002,\n",
            "         2106,  2190,  1024, 16083,  1996,  2492,  1997,  2658,  5439,  1998,\n",
            "        26008,  1999, 20380,  2015,  1012,   101,  1996,  2781,  2071,  8328,\n",
            "         2422,  2006,  2019,  4722,  5981,  1010,  2029,  2038,  2042, 10358,\n",
            "         1999,  7349,  4584,  1005,  3522, 13867,  1010,  2058,  2043,  2000,\n",
            "         5136,  6274,  6165,  1012])\n",
            "Last 64 tokens: [CLS] but metro's definition of \" urbanite \" is not accurate, says matthew gandy, director of the urban laboratory at university college london. [CLS] goodrich petroleum is an independent oil and gas exploration and production company listed on the new york stock exchange. [CLS] the support from spears is to end on november 15 [CLS]\n",
            "ids: tensor([  101,  2021,  6005,  1005,  1055,  6210,  1997,  1000,  3923,  4221,\n",
            "         1000,  2003,  2025,  8321,  1010,  2758,  5487, 25957,  5149,  1010,\n",
            "         2472,  1997,  1996,  3923,  5911,  2012,  2118,  2267,  2414,  1012,\n",
            "          101,  2204, 13149, 11540,  2003,  2019,  2981,  3514,  1998,  3806,\n",
            "         8993,  1998,  2537,  2194,  3205,  2006,  1996,  2047,  2259,  4518,\n",
            "         3863,  1012,   101,  1996,  2490,  2013, 13957,  2003,  2000,  2203,\n",
            "         2006,  2281,  2321,   101])\n",
            "Printing valid dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] in medieval times, the townspeople from norcia were so practised at butchering pigs that they gained an in - depth knowledge of anatomy and were allowed to practise as surgeons along with members of the clergy. [CLS] the satellite weighs some 660 pounds, the israeli haaretz newspaper reported, citing unnamed company officials.\n",
            "ids: tensor([  101,  1999,  5781,  2335,  1010,  1996, 27938,  2013,  4496,  7405,\n",
            "         2020,  2061, 20439,  2012, 14998,  2075, 14695,  2008,  2027,  4227,\n",
            "         2019,  1999,  1011,  5995,  3716,  1997, 13336,  1998,  2020,  3039,\n",
            "         2000, 10975, 18908,  5562,  2004, 16804,  2247,  2007,  2372,  1997,\n",
            "         1996, 11646,  1012,   101,  1996,  5871, 21094,  2070, 20982,  7038,\n",
            "         1010,  1996,  5611,  5292, 12069,  5753,  3780,  2988,  1010,  8951,\n",
            "        13294,  2194,  4584,  1012])\n",
            "Last 64 tokens: [CLS] the situation has been further complicated by growing indications that the us treasury is preparing to make funds available for recapitalsing us banks. [CLS] as north korea's close neighbor, traditional ally and main provider of economic aid, china is widely believed to hold the key to solving the north korea conundrum. [CLS]\n",
            "ids: tensor([  101,  1996,  3663,  2038,  2042,  2582,  8552,  2011,  3652, 24936,\n",
            "         2008,  1996,  2149,  9837,  2003,  8225,  2000,  2191,  5029,  2800,\n",
            "         2005, 28667,  9331, 18400,  7741,  2149,  5085,  1012,   101,  2004,\n",
            "         2167,  4420,  1005,  1055,  2485, 11429,  1010,  3151,  9698,  1998,\n",
            "         2364, 10802,  1997,  3171,  4681,  1010,  2859,  2003,  4235,  3373,\n",
            "         2000,  2907,  1996,  3145,  2000, 13729,  1996,  2167,  4420,  9530,\n",
            "         8630,  6824,  1012,   101])\n",
            "[2026-01-05 03:12:08,051][__main__][INFO] - Initializing new model\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "wandb: WARNING The anonymous setting has no effect and will be removed in a future version.\n",
            "Restoring states from the checkpoint path at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:362: The dirpath has changed from '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints' to '/content/bd3lms/outputs/lm1b/2026.01.05/031018/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type           | Params | Mode \n",
            "----------------------------------------------------\n",
            "0 | backbone | DIT            | 22.8 M | train\n",
            "1 | noise    | LogLinearNoise | 0      | train\n",
            "----------------------------------------------------\n",
            "22.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "22.8 M    Total params\n",
            "91.266    Total estimated model params size (MB)\n",
            "110       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Restored all states from the checkpoint at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "Loading checkpoint at 500\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0.5, max=1\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py:221: You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.\n",
            "Epoch 16, global step 504: 'val/nll' reached 8.36114 (best 8.36114), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/031018/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 506: 'val/nll' reached 7.18001 (best 7.18001), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/031018/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 508: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 510: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 512: 'val/nll' reached 6.96437 (best 6.96437), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/031018/checkpoints/best.ckpt' as top 1\n",
            "Epoch 17, global step 514: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 516: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 518: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 520: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 522: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 524: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 526: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 528: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 530: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 532: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 534: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 536: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 538: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 540: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 542: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 544: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 546: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 548: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 550: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 552: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 554: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 556: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 558: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 560: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 562: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 564: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 566: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 568: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 570: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 572: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 574: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 576: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 578: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 580: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 582: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 584: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 586: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 588: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 590: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 592: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 594: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 596: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 598: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 600: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=600` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eval_bd3lm_best block size 4, clipping\n",
        "\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=ppl_eval \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=4 \\\n",
        "  trainer.devices=1 \\\n",
        "  trainer.num_nodes=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  eval.checkpoint_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/031018/checkpoints/best.ckpt \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100"
      ],
      "metadata": {
        "id": "JYz4jE7r6fsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cfcee3-a0d3-45e6-8f21-55f9b00f6508"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "\u001b[2mCONFIG\u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmode\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mppl_eval                                                                \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdiffusion\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mabsorbing_state                                                         \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mseed\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m1                                                                       \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mblock_size\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m4                                                                       \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdata\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mmax_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_train_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_valid_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_test_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtrain\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvalid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtokenizer_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbert-base-uncased                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcache_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/share/kuleshov/ssahoo/textdiffusion/data                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mwrap\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mstreaming\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mloader\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mglobal_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_global_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbatch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_workers\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mpin_memory\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2msampling\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mnoise_removal\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sample_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_length\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlogdir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m./samples_bd3lm_len128_blocksize4                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnucleus_p\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfirst_hitting\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mkv_cache\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtraining\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9999                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mantithetic_sampling\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcoeff_clip\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1.0                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresample\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnll_diagram\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfrom_pretrained\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_nll\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2meval\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.0\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdisable_ema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mperplexity_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcompute_perplexity_on_sanity\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgen_ppl_eval_model_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mgpt2-large                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgenerate_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2moptim\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mweight_decay\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlr\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0003                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta1\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta2\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.999                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0e-08                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtrainer\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.Trainer                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccelerator\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mcuda                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_nodes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdevices\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccumulate_grad_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgradient_clip_val\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mprecision\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbf16                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sanity_val_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m300                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlog_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1000                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_train_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_val_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mval_check_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mwandb\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mproject\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBD3-LMs                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnotes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBlock Denoising Discrete Diffusion Language Models               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgroup\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mjob_type\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mNone_1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtags\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcheckpointing\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40msave_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181543                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_from_ckpt\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_ckpt_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181543/checkpo\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcallbacks\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181543/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mevery_n_train_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m500                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcheckpoint_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmonitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mval/nll                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmode\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mmin                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181543/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mfilename\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbest                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlearning_rate_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.LearningRateMonitor             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mlogging_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mstep                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmodel\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtiny                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mddit                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mhidden_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m256                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcond_dim\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m64                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlength\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m128                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_blocks\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_heads\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mscale_by_sigma\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtie_word_embeddings\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40madaln\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mattn_backend\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msdpa                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mstrategy\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.strategies.DDPStrategy                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfind_unused_parameters\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mnoise\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0001                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m20                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mlr_scheduler\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtransformers.get_constant_schedule_with_warmup                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_warmup_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2500                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m└── \u001b[0m\u001b[2malgo\u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbd3lm                                                             \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbackbone\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mdit                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mparameterization\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msubs                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtime_conditioning\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mT\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                                    \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcausal_attention\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0                                                            \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mignore_bos\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcross_attn\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_delta\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.05                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_widths\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m[]                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfix_clipping\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                     \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampler\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msemi_ar                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmdlm_loss_scale\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "[2026-01-05 18:15:44,582][__main__][INFO] - Starting Eval.\n",
            "Loading checkpoint at 512\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0.001, max=1.0\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-05 18:15:55,706][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 18:15:55,706][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100% 100/100 [00:00<00:00, 1935.16 examples/s]\n",
            "Map: 100% 100/100 [00:00<00:00, 19410.88 examples/s]\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-05 18:18:33.102149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767637113.121092    6373 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767637113.126577    6373 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767637113.141808    6373 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767637113.141833    6373 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767637113.141837    6373 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767637113.141841    6373 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-05 18:18:33.148352: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_max     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_min     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0010000000474974513  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/bpd         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   10.151830673217773    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/nll         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    7.036713123321533    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/ppl         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1137.64208984375     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    valid_var_0.0 - 1    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    44.85820007324219    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune block size 4, no clipping\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=train \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=4 \\\n",
        "  trainer.devices=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  trainer.max_steps=600 \\\n",
        "  data.max_train_samples=500 \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100 \\\n",
        "  training.nll_diagram=False \\\n",
        "  algo.fix_clipping=False \\\n",
        "  training.sampling_eps_min=0 \\\n",
        "  training.sampling_eps_max=1 \\\n",
        "  checkpointing.resume_ckpt_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt 2>&1 | grep -v \"TQDMProgressBar\\|val_progress_bar\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI6KVwOeEoIl",
        "outputId": "0ca9877e-997a-4f20-8de3-5e0c48f8bd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "CONFIG\n",
            "├── mode\n",
            "│   └── train                                                                   \n",
            "├── diffusion\n",
            "│   └── absorbing_state                                                         \n",
            "├── seed\n",
            "│   └── 1                                                                       \n",
            "├── block_size\n",
            "│   └── 4                                                                       \n",
            "├── data\n",
            "│   └── max_samples: null                                                       \n",
            "│       max_train_samples: 500                                                  \n",
            "│       max_valid_samples: 100                                                  \n",
            "│       max_test_samples: 100                                                   \n",
            "│       train: lm1b                                                             \n",
            "│       valid: lm1b                                                             \n",
            "│       tokenizer_name_or_path: bert-base-uncased                               \n",
            "│       cache_dir: /share/kuleshov/ssahoo/textdiffusion/data                    \n",
            "│       wrap: true                                                              \n",
            "│       streaming: true                                                         \n",
            "│                                                                               \n",
            "├── loader\n",
            "│   └── global_batch_size: 4                                                    \n",
            "│       eval_global_batch_size: 4                                               \n",
            "│       batch_size: 4                                                           \n",
            "│       eval_batch_size: 4                                                      \n",
            "│       num_workers: 1                                                          \n",
            "│       pin_memory: true                                                        \n",
            "│                                                                               \n",
            "├── sampling\n",
            "│   └── noise_removal: false                                                    \n",
            "│       num_sample_batches: 1                                                   \n",
            "│       var_length: false                                                       \n",
            "│       logdir: ./samples_bd3lm_len128_blocksize4                               \n",
            "│       nucleus_p: 1.0                                                          \n",
            "│       first_hitting: true                                                     \n",
            "│       kv_cache: false                                                         \n",
            "│                                                                               \n",
            "├── training\n",
            "│   └── ema: 0.9999                                                             \n",
            "│       antithetic_sampling: true                                               \n",
            "│       sampling_eps: 0.001                                                     \n",
            "│       coeff_clip: -1.0                                                        \n",
            "│       resample: false                                                         \n",
            "│       sampling_eps_min: 0                                                     \n",
            "│       sampling_eps_max: 1                                                     \n",
            "│       nll_diagram: false                                                      \n",
            "│       from_pretrained: null                                                   \n",
            "│       eval_nll: true                                                          \n",
            "│                                                                               \n",
            "├── eval\n",
            "│   └── checkpoint_path: /content/bd3lms/outputs/lm1b/2026.01.05/031558/checkpoi\n",
            "│       disable_ema: false                                                      \n",
            "│       perplexity_batch_size: 8                                                \n",
            "│       compute_perplexity_on_sanity: false                                     \n",
            "│       gen_ppl_eval_model_name_or_path: gpt2-large                             \n",
            "│       generate_samples: false                                                 \n",
            "│                                                                               \n",
            "├── optim\n",
            "│   └── weight_decay: 0                                                         \n",
            "│       lr: 0.0003                                                              \n",
            "│       beta1: 0.9                                                              \n",
            "│       beta2: 0.999                                                            \n",
            "│       eps: 1.0e-08                                                            \n",
            "│                                                                               \n",
            "├── trainer\n",
            "│   └── _target_: lightning.Trainer                                             \n",
            "│       accelerator: cuda                                                       \n",
            "│       num_nodes: 1                                                            \n",
            "│       devices: 1                                                              \n",
            "│       accumulate_grad_batches: 1                                              \n",
            "│       gradient_clip_val: 1.0                                                  \n",
            "│       precision: bf16                                                         \n",
            "│       num_sanity_val_steps: 2                                                 \n",
            "│       max_steps: 600                                                          \n",
            "│       log_every_n_steps: 1000                                                 \n",
            "│       limit_train_batches: 1.0                                                \n",
            "│       limit_val_batches: 1.0                                                  \n",
            "│       val_check_interval: 2                                                   \n",
            "│                                                                               \n",
            "├── wandb\n",
            "│   └── project: BD3-LMs                                                        \n",
            "│       notes: Block Denoising Discrete Diffusion Language Models               \n",
            "│       group: null                                                             \n",
            "│       job_type: null                                                          \n",
            "│       name: null                                                              \n",
            "│       id: None_1                                                              \n",
            "│       tags:                                                                   \n",
            "│       - loglinear                                                             \n",
            "│       - lm1b                                                                  \n",
            "│       - lm1b                                                                  \n",
            "│                                                                               \n",
            "├── checkpointing\n",
            "│   └── save_dir: /content/bd3lms/outputs/lm1b/2026.01.05/031558                \n",
            "│       resume_from_ckpt: true                                                  \n",
            "│       resume_ckpt_path: /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.\n",
            "│                                                                               \n",
            "├── callbacks\n",
            "│   └── checkpoint_every_n_steps:                                               \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         save_top_k: -1                                                        \n",
            "│         save_last: true                                                       \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/031558/checkpoints   \n",
            "│         verbose: true                                                         \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         every_n_train_steps: 500                                              \n",
            "│       checkpoint_monitor:                                                     \n",
            "│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 \n",
            "│         monitor: val/nll                                                      \n",
            "│         mode: min                                                             \n",
            "│         save_top_k: 1                                                         \n",
            "│         save_last: false                                                      \n",
            "│         dirpath: /content/bd3lms/outputs/lm1b/2026.01.05/031558/checkpoints   \n",
            "│         filename: best                                                        \n",
            "│         auto_insert_metric_name: false                                        \n",
            "│         verbose: true                                                         \n",
            "│       learning_rate_monitor:                                                  \n",
            "│         _target_: lightning.pytorch.callbacks.LearningRateMonitor             \n",
            "│         logging_interval: step                                                \n",
            "│                                                                               \n",
            "├── model\n",
            "│   └── name: tiny                                                              \n",
            "│       type: ddit                                                              \n",
            "│       hidden_size: 256                                                        \n",
            "│       cond_dim: 64                                                            \n",
            "│       length: 128                                                             \n",
            "│       n_blocks: 8                                                             \n",
            "│       n_heads: 8                                                              \n",
            "│       scale_by_sigma: true                                                    \n",
            "│       dropout: 0.1                                                            \n",
            "│       tie_word_embeddings: true                                               \n",
            "│       adaln: false                                                            \n",
            "│       attn_backend: sdpa                                                      \n",
            "│                                                                               \n",
            "├── strategy\n",
            "│   └── _target_: lightning.pytorch.strategies.DDPStrategy                      \n",
            "│       find_unused_parameters: false                                           \n",
            "│                                                                               \n",
            "├── noise\n",
            "│   └── type: loglinear                                                         \n",
            "│       sigma_min: 0.0001                                                       \n",
            "│       sigma_max: 20                                                           \n",
            "│                                                                               \n",
            "├── lr_scheduler\n",
            "│   └── _target_: transformers.get_constant_schedule_with_warmup                \n",
            "│       num_warmup_steps: 2500                                                  \n",
            "│                                                                               \n",
            "└── algo\n",
            "    └── name: bd3lm                                                             \n",
            "        backbone: dit                                                           \n",
            "        parameterization: subs                                                  \n",
            "        time_conditioning: false                                                \n",
            "        T: 0                                                                    \n",
            "        causal_attention: false                                                 \n",
            "        dropout: 0.0                                                            \n",
            "        ignore_bos: true                                                        \n",
            "        cross_attn: true                                                        \n",
            "        var_min: true                                                           \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "                                                                                \n",
            "[2026-01-05 03:15:59,563][__main__][INFO] - Starting Training.\n",
            "[2026-01-05 03:15:59,576][__main__][INFO] - Resuming training at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "[2026-01-05 03:15:59,607][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_train_bs128_wrapped.dat\n",
            "[2026-01-05 03:15:59,607][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 500 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 500 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 2257.39 examples/s]\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 35923.05 examples/s]\n",
            "[2026-01-05 03:16:04,433][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 03:16:04,433][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 2260.14 examples/s]\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 21673.75 examples/s]\n",
            "Printing train dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] while athletes in different professions dealt with doping scandals and other controversies, woods continued to do what he did best : dominate the field of professional golf and rake in endorsements. [CLS] the minutes could shed light on an internal debate, which has been evident in fed officials'recent speeches, over when to consider raising rates.\n",
            "ids: tensor([  101,  2096,  7576,  1999,  2367, 22797,  9411,  2007, 23799, 29609,\n",
            "         1998,  2060, 25962,  1010,  5249,  2506,  2000,  2079,  2054,  2002,\n",
            "         2106,  2190,  1024, 16083,  1996,  2492,  1997,  2658,  5439,  1998,\n",
            "        26008,  1999, 20380,  2015,  1012,   101,  1996,  2781,  2071,  8328,\n",
            "         2422,  2006,  2019,  4722,  5981,  1010,  2029,  2038,  2042, 10358,\n",
            "         1999,  7349,  4584,  1005,  3522, 13867,  1010,  2058,  2043,  2000,\n",
            "         5136,  6274,  6165,  1012])\n",
            "Last 64 tokens: [CLS] but metro's definition of \" urbanite \" is not accurate, says matthew gandy, director of the urban laboratory at university college london. [CLS] goodrich petroleum is an independent oil and gas exploration and production company listed on the new york stock exchange. [CLS] the support from spears is to end on november 15 [CLS]\n",
            "ids: tensor([  101,  2021,  6005,  1005,  1055,  6210,  1997,  1000,  3923,  4221,\n",
            "         1000,  2003,  2025,  8321,  1010,  2758,  5487, 25957,  5149,  1010,\n",
            "         2472,  1997,  1996,  3923,  5911,  2012,  2118,  2267,  2414,  1012,\n",
            "          101,  2204, 13149, 11540,  2003,  2019,  2981,  3514,  1998,  3806,\n",
            "         8993,  1998,  2537,  2194,  3205,  2006,  1996,  2047,  2259,  4518,\n",
            "         3863,  1012,   101,  1996,  2490,  2013, 13957,  2003,  2000,  2203,\n",
            "         2006,  2281,  2321,   101])\n",
            "Printing valid dataloader batch.\n",
            "Batch input_ids.shape torch.Size([4, 128])\n",
            "First 64 tokens: [CLS] in medieval times, the townspeople from norcia were so practised at butchering pigs that they gained an in - depth knowledge of anatomy and were allowed to practise as surgeons along with members of the clergy. [CLS] the satellite weighs some 660 pounds, the israeli haaretz newspaper reported, citing unnamed company officials.\n",
            "ids: tensor([  101,  1999,  5781,  2335,  1010,  1996, 27938,  2013,  4496,  7405,\n",
            "         2020,  2061, 20439,  2012, 14998,  2075, 14695,  2008,  2027,  4227,\n",
            "         2019,  1999,  1011,  5995,  3716,  1997, 13336,  1998,  2020,  3039,\n",
            "         2000, 10975, 18908,  5562,  2004, 16804,  2247,  2007,  2372,  1997,\n",
            "         1996, 11646,  1012,   101,  1996,  5871, 21094,  2070, 20982,  7038,\n",
            "         1010,  1996,  5611,  5292, 12069,  5753,  3780,  2988,  1010,  8951,\n",
            "        13294,  2194,  4584,  1012])\n",
            "Last 64 tokens: [CLS] the situation has been further complicated by growing indications that the us treasury is preparing to make funds available for recapitalsing us banks. [CLS] as north korea's close neighbor, traditional ally and main provider of economic aid, china is widely believed to hold the key to solving the north korea conundrum. [CLS]\n",
            "ids: tensor([  101,  1996,  3663,  2038,  2042,  2582,  8552,  2011,  3652, 24936,\n",
            "         2008,  1996,  2149,  9837,  2003,  8225,  2000,  2191,  5029,  2800,\n",
            "         2005, 28667,  9331, 18400,  7741,  2149,  5085,  1012,   101,  2004,\n",
            "         2167,  4420,  1005,  1055,  2485, 11429,  1010,  3151,  9698,  1998,\n",
            "         2364, 10802,  1997,  3171,  4681,  1010,  2859,  2003,  4235,  3373,\n",
            "         2000,  2907,  1996,  3145,  2000, 13729,  1996,  2167,  4420,  9530,\n",
            "         8630,  6824,  1012,   101])\n",
            "[2026-01-05 03:17:48,341][__main__][INFO] - Initializing new model\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "wandb: WARNING The anonymous setting has no effect and will be removed in a future version.\n",
            "Restoring states from the checkpoint path at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:362: The dirpath has changed from '/content/bd3lms/outputs/lm1b/2026.01.05/022135/checkpoints' to '/content/bd3lms/outputs/lm1b/2026.01.05/031558/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type           | Params | Mode \n",
            "----------------------------------------------------\n",
            "0 | backbone | DIT            | 22.8 M | train\n",
            "1 | noise    | LogLinearNoise | 0      | train\n",
            "----------------------------------------------------\n",
            "22.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "22.8 M    Total params\n",
            "91.266    Total estimated model params size (MB)\n",
            "110       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Restored all states from the checkpoint at /content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/022135/checkpoints/last.ckpt\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "Loading checkpoint at 500\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0, max=1\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py:221: You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.\n",
            "Epoch 16, global step 504: 'val/nll' reached 8.36116 (best 8.36116), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/031558/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 506: 'val/nll' reached 7.18012 (best 7.18012), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/031558/checkpoints/best.ckpt' as top 1\n",
            "Epoch 16, global step 508: 'val/nll' was not in top 1\n",
            "Epoch 16, global step 510: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 512: 'val/nll' reached 6.96433 (best 6.96433), saving model to '/content/bd3lms/outputs/lm1b/2026.01.05/031558/checkpoints/best.ckpt' as top 1\n",
            "Epoch 17, global step 514: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 516: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 518: 'val/nll' was not in top 1\n",
            "Epoch 17, global step 520: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 522: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 524: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 526: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 528: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 530: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 532: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 534: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 536: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 538: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 540: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 542: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 544: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 546: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 548: 'val/nll' was not in top 1\n",
            "Epoch 18, global step 550: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 552: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 554: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 556: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 558: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 560: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 562: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 564: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 566: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 568: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 570: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 572: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 574: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 576: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 578: 'val/nll' was not in top 1\n",
            "Epoch 19, global step 580: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 582: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 584: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 586: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 588: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 590: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 592: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 594: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 596: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 598: 'val/nll' was not in top 1\n",
            "Epoch 20, global step 600: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=600` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eval_bd3lm_best block size 4, no clipping\n",
        "\n",
        "!cd /content/bd3lms && python main.py \\\n",
        "  mode=ppl_eval \\\n",
        "  model=tiny \\\n",
        "  algo=bd3lm \\\n",
        "  data=lm1b_wrap \\\n",
        "  model.length=128 \\\n",
        "  model.attn_backend=sdpa \\\n",
        "  block_size=4 \\\n",
        "  trainer.devices=1 \\\n",
        "  trainer.num_nodes=1 \\\n",
        "  loader.global_batch_size=4 \\\n",
        "  loader.batch_size=4 \\\n",
        "  loader.eval_batch_size=4 \\\n",
        "  eval.checkpoint_path=/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.01.05/031558/checkpoints/best.ckpt \\\n",
        "  data.max_valid_samples=100 \\\n",
        "  data.max_test_samples=100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StKzLLkqXN2C",
        "outputId": "51601ae0-a6bf-4322-b903-83878bdd2c01"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "\u001b[2mCONFIG\u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmode\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mppl_eval                                                                \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdiffusion\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40mabsorbing_state                                                         \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mseed\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m1                                                                       \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mblock_size\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;40m4                                                                       \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mdata\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mmax_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_train_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_valid_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_test_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m100                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtrain\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvalid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtokenizer_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbert-base-uncased                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcache_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/share/kuleshov/ssahoo/textdiffusion/data                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mwrap\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mstreaming\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mloader\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mglobal_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_global_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbatch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m4                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_workers\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mpin_memory\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2msampling\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mnoise_removal\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sample_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_length\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlogdir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m./samples_bd3lm_len128_blocksize4                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnucleus_p\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfirst_hitting\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mkv_cache\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtraining\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9999                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mantithetic_sampling\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcoeff_clip\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1.0                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresample\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.001                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampling_eps_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnll_diagram\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfrom_pretrained\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meval_nll\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2meval\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/drive/MyDrive/bd3lms_storage_final/lm1b/2026.0\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdisable_ema\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mperplexity_batch_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcompute_perplexity_on_sanity\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgen_ppl_eval_model_name_or_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mgpt2-large                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgenerate_samples\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2moptim\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mweight_decay\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlr\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0003                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta1\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.9                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbeta2\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.999                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40meps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0e-08                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mtrainer\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.Trainer                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccelerator\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mcuda                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_nodes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdevices\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40maccumulate_grad_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgradient_clip_val\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mprecision\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbf16                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_sanity_val_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmax_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m300                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlog_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1000                                                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_train_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlimit_val_batches\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1.0                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mval_check_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mwandb\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mproject\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBD3-LMs                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnotes\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mBlock Denoising Discrete Diffusion Language Models               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mgroup\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mjob_type\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                          \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mnull                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mid\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mNone_1                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtags\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                                   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m-\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlm1b                                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcheckpointing\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40msave_dir\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181858                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_from_ckpt\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mresume_ckpt_path\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181858/checkpo\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mcallbacks\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mcheckpoint_every_n_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m-1                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181858/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mevery_n_train_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m500                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcheckpoint_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                     \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.ModelCheckpoint                 \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmonitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mval/nll                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mmode\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mmin                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_top_k\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m1                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40msave_last\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mdirpath\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m/content/bd3lms/outputs/lm1b/2026.01.05/181858/checkpoints   \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mfilename\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbest                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mauto_insert_metric_name\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mverbose\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlearning_rate_monitor\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;40m                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.callbacks.LearningRateMonitor             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;97;40m  \u001b[0m\u001b[2;91;40mlogging_interval\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mstep                                                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mmodel\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtiny                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mddit                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mhidden_size\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m256                                                        \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcond_dim\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m64                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mlength\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m128                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_blocks\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                             \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mn_heads\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m8                                                              \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mscale_by_sigma\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                    \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.1                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtie_word_embeddings\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                               \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40madaln\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                            \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mattn_backend\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msdpa                                                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mstrategy\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mlightning.pytorch.strategies.DDPStrategy                      \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfind_unused_parameters\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mnoise\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mtype\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mloglinear                                                         \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0001                                                       \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msigma_max\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m20                                                           \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m├── \u001b[0m\u001b[2mlr_scheduler\u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40m_target_\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtransformers.get_constant_schedule_with_warmup                \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mnum_warmup_steps\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m2500                                                  \u001b[0m\n",
            "\u001b[2m│   \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "\u001b[2m└── \u001b[0m\u001b[2malgo\u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m└── \u001b[0m\u001b[2;91;40mname\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mbd3lm                                                             \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mbackbone\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mdit                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mparameterization\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msubs                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mtime_conditioning\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mT\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0                                                                    \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcausal_attention\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mdropout\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.0                                                            \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mignore_bos\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mcross_attn\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mvar_min\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mtrue                                                           \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_delta\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m0.05                                                 \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mclip_search_widths\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40m[]                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mfix_clipping\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                     \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40msampler\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40msemi_ar                                                        \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;91;40mmdlm_loss_scale\u001b[0m\u001b[2;97;40m:\u001b[0m\u001b[2;97;40m \u001b[0m\u001b[2;40mfalse                                                  \u001b[0m\n",
            "\u001b[2m    \u001b[0m\u001b[2m    \u001b[0m\u001b[2;40m                                                                        \u001b[0m\n",
            "[2026-01-05 18:18:59,158][__main__][INFO] - Starting Eval.\n",
            "Loading checkpoint at 512\n",
            "✓ Overriding sampling_eps in checkpoint before load: min=0.001, max=1.0\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:572: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "Seed set to 1\n",
            "[2026-01-05 18:19:13,737][dataloader][INFO] - Generating new data at: /share/kuleshov/ssahoo/textdiffusion/data/lm1b_test_bs128_wrapped.dat\n",
            "[2026-01-05 18:19:13,737][dataloader][INFO] - streaming=True\n",
            "\n",
            "============================================================\n",
            "GET_STREAMING_SAMPLES DEBUG: lm1b\n",
            "  Requested: 100 samples\n",
            "  Input type: <class 'datasets.iterable_dataset.IterableDataset'>\n",
            "  Returning dataset with 100 samples\n",
            "============================================================\n",
            "Map: 100% 100/100 [00:00<00:00, 1082.04 examples/s]\n",
            "Map: 100% 100/100 [00:00<00:00, 11532.63 examples/s]\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2026-01-05 18:20:17.549695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767637217.578242    7240 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767637217.586726    7240 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767637217.608172    7240 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767637217.608199    7240 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767637217.608205    7240 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767637217.608212    7240 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-05 18:20:17.614547: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
            "  warnings.warn(  # warn only once\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_max     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    sampling_eps_min     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0010000000474974513  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/bpd         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    10.1521577835083     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/nll         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    7.03693962097168     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/ppl         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1137.8997802734375    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    valid_var_0.0 - 1    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    44.89165496826172    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sync to drive\n",
        "!mkdir -p /content/drive/MyDrive/bd3lms_storage_final\n",
        "!rsync -av \\\n",
        "  /content/bd3lms/outputs/lm1b \\\n",
        "  /content/drive/MyDrive/bd3lms_storage_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU-UIjWZEoFq",
        "outputId": "31dcf2aa-6c85-4bb6-9664-20a25c56ee78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending incremental file list\n",
            "lm1b/\n",
            "lm1b/2026.01.05/\n",
            "lm1b/2026.01.05/022135/\n",
            "lm1b/2026.01.05/022135/.hydra/\n",
            "lm1b/2026.01.05/022135/checkpoints/\n",
            "lm1b/2026.01.05/024407/\n",
            "lm1b/2026.01.05/024407/.hydra/\n",
            "lm1b/2026.01.05/024407/checkpoints/\n",
            "lm1b/2026.01.05/025009/\n",
            "lm1b/2026.01.05/025009/.hydra/\n",
            "lm1b/2026.01.05/025009/checkpoints/\n",
            "lm1b/2026.01.05/025827/\n",
            "lm1b/2026.01.05/025827/.hydra/\n",
            "lm1b/2026.01.05/025838/\n",
            "lm1b/2026.01.05/025838/.hydra/\n",
            "lm1b/2026.01.05/025849/\n",
            "lm1b/2026.01.05/025849/.hydra/\n",
            "lm1b/2026.01.05/025849/checkpoints/\n",
            "lm1b/2026.01.05/030413/\n",
            "lm1b/2026.01.05/030413/.hydra/\n",
            "lm1b/2026.01.05/030413/checkpoints/\n",
            "lm1b/2026.01.05/031018/\n",
            "lm1b/2026.01.05/031018/config_tree.txt\n",
            "lm1b/2026.01.05/031018/main.log\n",
            "lm1b/2026.01.05/031018/.hydra/\n",
            "lm1b/2026.01.05/031018/.hydra/config.yaml\n",
            "lm1b/2026.01.05/031018/.hydra/hydra.yaml\n",
            "lm1b/2026.01.05/031018/.hydra/overrides.yaml\n",
            "lm1b/2026.01.05/031018/checkpoints/\n",
            "lm1b/2026.01.05/031018/checkpoints/best.ckpt\n",
            "lm1b/2026.01.05/031018/checkpoints/last.ckpt\n",
            "lm1b/2026.01.05/031558/\n",
            "lm1b/2026.01.05/031558/config_tree.txt\n",
            "lm1b/2026.01.05/031558/main.log\n",
            "lm1b/2026.01.05/031558/.hydra/\n",
            "lm1b/2026.01.05/031558/.hydra/config.yaml\n",
            "lm1b/2026.01.05/031558/.hydra/hydra.yaml\n",
            "lm1b/2026.01.05/031558/.hydra/overrides.yaml\n",
            "lm1b/2026.01.05/031558/checkpoints/\n",
            "lm1b/2026.01.05/031558/checkpoints/best.ckpt\n",
            "lm1b/2026.01.05/031558/checkpoints/last.ckpt\n",
            "\n",
            "sent 1,464,702,239 bytes  received 511 bytes  195,293,700.00 bytes/sec\n",
            "total size is 5,491,309,326  speedup is 3.75\n"
          ]
        }
      ]
    }
  ]
}