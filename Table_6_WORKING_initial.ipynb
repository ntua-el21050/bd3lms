{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "25018dc3436a46299cf084a5846b402d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76a5423b66af49239d288a6cc672d301",
              "IPY_MODEL_a0d491c829144beb8f026b8f99edab50",
              "IPY_MODEL_2cc3dcf669d24a6f844c8af86c5d863f"
            ],
            "layout": "IPY_MODEL_7dea60399c534921ba0d53c37071e631"
          }
        },
        "76a5423b66af49239d288a6cc672d301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_633cb2f4e9ae43edb5876f1f74e7cfe6",
            "placeholder": "​",
            "style": "IPY_MODEL_db99940ea80a4c4c9587028e1234a906",
            "value": "config.json: 100%"
          }
        },
        "a0d491c829144beb8f026b8f99edab50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7ee89f9518142dc9699d507257e54d3",
            "max": 690,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afc25485fa6642dba61c6aef4945596c",
            "value": 690
          }
        },
        "2cc3dcf669d24a6f844c8af86c5d863f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c5f1c4797c4653b8a97cd934a8b0dd",
            "placeholder": "​",
            "style": "IPY_MODEL_e547b731ab5943f39c71d8fcc04f446a",
            "value": " 690/690 [00:00&lt;00:00, 39.8kB/s]"
          }
        },
        "7dea60399c534921ba0d53c37071e631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "633cb2f4e9ae43edb5876f1f74e7cfe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db99940ea80a4c4c9587028e1234a906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7ee89f9518142dc9699d507257e54d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc25485fa6642dba61c6aef4945596c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6c5f1c4797c4653b8a97cd934a8b0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e547b731ab5943f39c71d8fcc04f446a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "303a6798e71249a3b72a995a417a6009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79dae8b994cf4424978d32cb521d83ab",
              "IPY_MODEL_fc6465e1c93d4c7bbe8e4a4de85c975f",
              "IPY_MODEL_e1dfa0a0163f425db4d8e749ca040c6e"
            ],
            "layout": "IPY_MODEL_256b07696ba948209d0212b6c3f07435"
          }
        },
        "79dae8b994cf4424978d32cb521d83ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2737d8e595d14b8ca769140dbababc7a",
            "placeholder": "​",
            "style": "IPY_MODEL_e9f2319bd2194ad6a549eb89ac8f40f5",
            "value": "configuration_bd3lm.py: "
          }
        },
        "fc6465e1c93d4c7bbe8e4a4de85c975f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1326a784b766425f98234f27240f9e7e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6d92af0b9ba431e88c50deb3db06007",
            "value": 1
          }
        },
        "e1dfa0a0163f425db4d8e749ca040c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d5bc419af444812b0e1820dbcee0ef0",
            "placeholder": "​",
            "style": "IPY_MODEL_54f22ff0f1cf4e2199e0e7b4d4742e7d",
            "value": " 1.25k/? [00:00&lt;00:00, 103kB/s]"
          }
        },
        "256b07696ba948209d0212b6c3f07435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2737d8e595d14b8ca769140dbababc7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f2319bd2194ad6a549eb89ac8f40f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1326a784b766425f98234f27240f9e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e6d92af0b9ba431e88c50deb3db06007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d5bc419af444812b0e1820dbcee0ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f22ff0f1cf4e2199e0e7b4d4742e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db47387e93e44e85a180744f4fd4e47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d743a31e22948cca906a867f3b567a2",
              "IPY_MODEL_fc05ee3ee59746ab92dd251aa4b8d91f",
              "IPY_MODEL_b3804d4f1da7472a988eacab323f92a2"
            ],
            "layout": "IPY_MODEL_89630db72baa47b7b095a4644b49c4f2"
          }
        },
        "1d743a31e22948cca906a867f3b567a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b068cce355884479b8bbd6a512a52beb",
            "placeholder": "​",
            "style": "IPY_MODEL_8fda66f742b643ffa6e63f50cec1a183",
            "value": "modeling_bd3lm.py: "
          }
        },
        "fc05ee3ee59746ab92dd251aa4b8d91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3682c913700640809fc70355507cb2a6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50ffd1d01b8b41c4af47ded2de46d265",
            "value": 1
          }
        },
        "b3804d4f1da7472a988eacab323f92a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c22533ac5ba42e19ea3ea3ff31d0e3e",
            "placeholder": "​",
            "style": "IPY_MODEL_b835ab0958be4484ad8db230c29eb445",
            "value": " 21.8k/? [00:00&lt;00:00, 1.75MB/s]"
          }
        },
        "89630db72baa47b7b095a4644b49c4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b068cce355884479b8bbd6a512a52beb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fda66f742b643ffa6e63f50cec1a183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3682c913700640809fc70355507cb2a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "50ffd1d01b8b41c4af47ded2de46d265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c22533ac5ba42e19ea3ea3ff31d0e3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b835ab0958be4484ad8db230c29eb445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4038c527a6f549f2b504adfca13eca67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69d4157325904c5cae367b345016666a",
              "IPY_MODEL_f31cf7f5468f4376ac301f79a57686b3",
              "IPY_MODEL_9179815b40684f42aeb4e69b21d85b27"
            ],
            "layout": "IPY_MODEL_117ef028b6e24345b31177d1a029d008"
          }
        },
        "69d4157325904c5cae367b345016666a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d369c705ccc6421985f2035221155469",
            "placeholder": "​",
            "style": "IPY_MODEL_14ef8430af164c71839cf2f890229f1b",
            "value": "model.safetensors: 100%"
          }
        },
        "f31cf7f5468f4376ac301f79a57686b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f85e259b3a54dfbab102527e32b7f27",
            "max": 678522896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a6cd55679b046bc8698c0f8790f252d",
            "value": 678522896
          }
        },
        "9179815b40684f42aeb4e69b21d85b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9a3b11439fc4f9b8be711b25abc22f1",
            "placeholder": "​",
            "style": "IPY_MODEL_513775c762424c70a7608a92415f2b8d",
            "value": " 679M/679M [00:06&lt;00:00, 202MB/s]"
          }
        },
        "117ef028b6e24345b31177d1a029d008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d369c705ccc6421985f2035221155469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ef8430af164c71839cf2f890229f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f85e259b3a54dfbab102527e32b7f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a6cd55679b046bc8698c0f8790f252d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9a3b11439fc4f9b8be711b25abc22f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "513775c762424c70a7608a92415f2b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Table 6 Reproduction - WORKING VERSION\n",
        "\n",
        "## Fixes Applied:\n",
        "1. **Config keys**: Added `+` prefix for non-existing keys\n",
        "2. **Checkpoint conversion**: Convert `.ckpt` to HuggingFace format before `sample_eval`\n",
        "3. **Length extraction**: Parse actual token counts, not `len(log_text)`\n",
        "\n",
        "## Table 6 from paper:\n",
        "| Model | Median # tokens | Max # tokens |\n",
        "|-------|-----------------|-------------|\n",
        "| SEDD | 1021 | **1024** (limited!) |\n",
        "| BD3-LM L'=16 | 798 | **9982** |"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44ee912-2811-4fc4-cd34-7d97705ccb23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bd3lms'...\n",
            "remote: Enumerating objects: 896, done.\u001b[K\n",
            "remote: Counting objects: 100% (353/353), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 896 (delta 269), reused 265 (delta 214), pack-reused 543 (from 1)\u001b[K\n",
            "Receiving objects: 100% (896/896), 3.40 MiB | 12.66 MiB/s, done.\n",
            "Resolving deltas: 100% (563/563), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone YOUR fork\n",
        "!cd /content && rm -rf bd3lms\n",
        "!cd /content && git clone https://github.com/ntua-el21050/bd3lms.git\n",
        "\n",
        "!mkdir -p /content/bd3lms/data\n",
        "!mkdir -p /content/repro_runs\n",
        "!mkdir -p /content/hf_checkpoints\n",
        "!mkdir -p /content/sample_logs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics==1.6.2 datasets==3.3.2 einops==0.8.1 \\\n",
        "    hydra-core==1.3.2 lightning==2.5.0.post0 transformers==4.49.0 \\\n",
        "    huggingface_hub fsspec==2024.2.0 omegaconf==2.3.0"
      ],
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4549aee3-9434-4b03-faf3-66e58012e828"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m931.6/931.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.3/857.3 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import re\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.insert(0, '/content/bd3lms')\n",
        "\n",
        "def run_main(overrides, timeout=None):\n",
        "    \"\"\"Run main.py with overrides.\"\"\"\n",
        "    env = dict(os.environ)\n",
        "    env.setdefault(\"HYDRA_FULL_ERROR\", \"1\")\n",
        "    cmd = [sys.executable, \"-u\", \"bd3lms/main.py\", *overrides]\n",
        "    print(\"\\n$\", \" \".join(cmd[:8]), \"...\")\n",
        "    proc = subprocess.run(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        timeout=timeout,\n",
        "        check=False,\n",
        "        env=env,\n",
        "    )\n",
        "    print(proc.stdout[-3000:])\n",
        "    if proc.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed with return code {proc.returncode}\")\n",
        "    return proc.stdout\n",
        "\n",
        "\n",
        "def _small_loader_overrides(batch_size=4, num_workers=2):\n",
        "    return [\n",
        "        f\"loader.global_batch_size={batch_size}\",\n",
        "        f\"loader.eval_global_batch_size={batch_size}\",\n",
        "        f\"loader.batch_size={batch_size}\",\n",
        "        f\"loader.eval_batch_size={batch_size}\",\n",
        "        f\"loader.num_workers={num_workers}\",\n",
        "        \"trainer.accumulate_grad_batches=1\",\n",
        "    ]"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_run(run_name, algo, block_size=None, from_pretrained=None, max_steps=800, extra_overrides=None, model_length=1024):\n",
        "    \"\"\"Train a model.\"\"\"\n",
        "    save_dir = Path(\"/content/repro_runs\") / run_name\n",
        "    if save_dir.exists():\n",
        "        shutil.rmtree(save_dir)\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    overrides = [\n",
        "        \"mode=train\",\n",
        "        \"data=openwebtext-split\",\n",
        "        \"++data.cache_dir=/content/bd3lms/data\",       # ++ prefix!\n",
        "        \"++data.streaming=true\",                        # ++ prefix!\n",
        "        \"++data.max_train_samples=1500\",                # ++ prefix!\n",
        "        \"++data.max_valid_samples=100\",                 # ++ prefix!\n",
        "        \"++data.max_test_samples=100\",                  # ++ prefix!\n",
        "        \"model=tiny\",\n",
        "        f\"model.length={model_length}\",\n",
        "        \"model.attn_backend=sdpa\",\n",
        "        f\"algo={algo}\",\n",
        "        \"trainer.accelerator=gpu\",\n",
        "        \"trainer.devices=1\",\n",
        "        \"trainer.num_nodes=1\",\n",
        "        \"trainer.precision=16-mixed\",\n",
        "        \"trainer.num_sanity_val_steps=0\",\n",
        "        \"trainer.log_every_n_steps=20\",\n",
        "        \"trainer.val_check_interval=50\",\n",
        "        f\"trainer.max_steps={max_steps}\",\n",
        "        f\"checkpointing.save_dir={save_dir}\",\n",
        "        \"checkpointing.resume_from_ckpt=false\",\n",
        "        \"wandb=null\",\n",
        "    ]\n",
        "    overrides.extend(_small_loader_overrides(batch_size=4, num_workers=2))\n",
        "\n",
        "    if block_size is not None:\n",
        "        overrides.append(f\"block_size={block_size}\")\n",
        "    if from_pretrained is not None:\n",
        "        overrides.append(f\"training.from_pretrained={from_pretrained}\")\n",
        "        overrides.append(\"training.resample=true\")\n",
        "    if extra_overrides:\n",
        "        overrides.extend(extra_overrides)\n",
        "\n",
        "    _ = run_main(overrides)\n",
        "\n",
        "    # Find checkpoint\n",
        "    ckpt_dir = save_dir / \"checkpoints\"\n",
        "    for name in [\"best.ckpt\", \"last.ckpt\"]:\n",
        "        ckpt = ckpt_dir / name\n",
        "        if ckpt.exists():\n",
        "            print(f\"✓ Checkpoint: {ckpt}\")\n",
        "            return str(ckpt)\n",
        "\n",
        "    # List what we have\n",
        "    if ckpt_dir.exists():\n",
        "        print(f\"Available checkpoints: {list(ckpt_dir.glob('*.ckpt'))}\")\n",
        "    raise FileNotFoundError(f\"No checkpoint in {ckpt_dir}\")"
      ],
      "metadata": {
        "id": "train_run"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_ckpt_to_hf(ckpt_path, output_dir, block_size):\n",
        "    \"\"\"\n",
        "    Convert Lightning .ckpt to HuggingFace format.\n",
        "    \"\"\"\n",
        "    import transformers\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Converting {ckpt_path}\")\n",
        "    print(f\"To: {output_dir}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # Clean output dir\n",
        "    if os.path.exists(output_dir):\n",
        "        shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Step 1: Load reference model FROM HUGGINGFACE (with weights)\n",
        "    print(\"\\n[1/4] Loading reference model from HuggingFace...\")\n",
        "    ref_model_id = f\"kuleshov-group/bd3lm-owt-block_size{block_size}\"\n",
        "\n",
        "    try:\n",
        "        model = transformers.AutoModelForMaskedLM.from_pretrained(\n",
        "            ref_model_id,\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.float32\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: {e}\")\n",
        "        print(\"Trying block_size 16 as fallback...\")\n",
        "        model = transformers.AutoModelForMaskedLM.from_pretrained(\n",
        "            \"kuleshov-group/bd3lm-owt-block_size16\",\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.float32\n",
        "        )\n",
        "\n",
        "    # Step 2: Load Lightning checkpoint\n",
        "    print(\"\\n[2/4] Loading Lightning checkpoint...\")\n",
        "    checkpoint = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
        "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
        "    print(f\"   Found {len(state_dict)} parameters\")\n",
        "\n",
        "    # Step 3: Clean key names\n",
        "    print(\"\\n[3/4] Cleaning state dict keys...\")\n",
        "    cleaned = {}\n",
        "    for k, v in state_dict.items():\n",
        "        new_k = k\n",
        "        for prefix in ['backbone.', 'diffusion.backbone.', 'model.', 'module.']:\n",
        "            if new_k.startswith(prefix):\n",
        "                new_k = new_k[len(prefix):]\n",
        "        cleaned[new_k] = v\n",
        "    print(f\"   Cleaned keys: {list(cleaned.keys())[:3]}\")\n",
        "\n",
        "    # Step 4: Apply our weights to the model\n",
        "    print(\"\\n[4/4] Applying our weights to model...\")\n",
        "    missing, unexpected = model.load_state_dict(cleaned, strict=False)\n",
        "    print(f\"   Missing: {len(missing)}, Unexpected: {len(unexpected)}\")\n",
        "\n",
        "    # Save with our weights\n",
        "    model.save_pretrained(output_dir)\n",
        "\n",
        "    # Tokenizer\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2')\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    print(f\"\\n✓ Saved to {output_dir}\")\n",
        "    return output_dir"
      ],
      "metadata": {
        "id": "convert"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_length_stats(log_text, logdir=None):\n",
        "    \"\"\"\n",
        "    Extract actual token length statistics from CSV.\n",
        "    \"\"\"\n",
        "    lengths = []\n",
        "\n",
        "    # Read CSV file (BD3-LM saves as CSV without header)\n",
        "    if logdir and os.path.exists(logdir) and os.path.isfile(logdir):\n",
        "        try:\n",
        "            import pandas as pd\n",
        "            df = pd.read_csv(logdir, header=None)\n",
        "            # Column 1 is length\n",
        "            lengths.extend(df[1].dropna().astype(int).tolist())\n",
        "            print(f\"Found {len(lengths)} samples in CSV\")\n",
        "        except Exception as e:\n",
        "            print(f\"CSV error: {e}\")\n",
        "\n",
        "    if lengths:\n",
        "        return {\n",
        "            'count': len(lengths),\n",
        "            'median': int(np.median(lengths)),\n",
        "            'max': int(np.max(lengths)),\n",
        "            'mean': round(np.mean(lengths), 1),\n",
        "        }\n",
        "    return {'count': 0, 'median': None, 'max': None, 'mean': None}\n",
        "\n",
        "def eval_run(algo, hf_checkpoint_path, block_size=None, num_samples=50, extra_overrides=None, model_length=1024):\n",
        "    \"\"\"\n",
        "    Run sample_eval with HuggingFace checkpoint.\n",
        "    Run multiple times to collect samples (workaround for variable-length bug).\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    logfile = f\"/content/sample_logs/varlen_{algo}_bs{block_size}\"\n",
        "\n",
        "    # Clean up\n",
        "    if os.path.exists(logfile):\n",
        "        os.remove(logfile)\n",
        "\n",
        "    all_lengths = []\n",
        "\n",
        "    # Run multiple times with 1 sample each (workaround)\n",
        "    for i in range(num_samples):\n",
        "        print(f\"\\rGenerating sample {i+1}/{num_samples}...\", end=\"\")\n",
        "\n",
        "        overrides = [\n",
        "            \"mode=sample_eval\",\n",
        "            \"data=openwebtext-split\",\n",
        "            \"sampling.num_sample_batches=1\",  # 1 at a time!\n",
        "            \"++data.cache_dir=/content/bd3lms/data\",\n",
        "            \"++data.streaming=true\",\n",
        "            \"++data.max_test_samples=1\",\n",
        "            \"model=tiny\",\n",
        "            f\"model.length={model_length}\",\n",
        "            \"model.attn_backend=sdpa\",\n",
        "            f\"algo={algo}\",\n",
        "            \"algo.backbone=hf_dit\",\n",
        "            \"algo.T=5000\",\n",
        "            f\"eval.checkpoint_path={hf_checkpoint_path}\",\n",
        "            \"sampling.var_length=true\",\n",
        "            \"sampling.nucleus_p=0.9\",\n",
        "            \"sampling.kv_cache=true\",\n",
        "            f\"sampling.logdir={logfile}\",\n",
        "            f\"seed={42+i}\",  # Different seed each time\n",
        "            \"trainer.accelerator=gpu\",\n",
        "            \"trainer.devices=1\",\n",
        "            \"trainer.precision=16-mixed\",\n",
        "            \"wandb=null\",\n",
        "            f\"block_size={block_size}\",\n",
        "            \"loader.eval_batch_size=1\",\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            run_main(overrides)\n",
        "        except:\n",
        "            pass  # Continue on error\n",
        "\n",
        "    print(\"\\nDone!\")\n",
        "\n",
        "    # Read results from CSV\n",
        "    if os.path.exists(logfile) and os.path.isfile(logfile):\n",
        "        try:\n",
        "            df = pd.read_csv(logfile, header=None)\n",
        "            all_lengths = df[1].dropna().astype(int).tolist()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if all_lengths:\n",
        "        stats = {\n",
        "            'count': len(all_lengths),\n",
        "            'median': int(np.median(all_lengths)),\n",
        "            'max': int(np.max(all_lengths)),\n",
        "            'mean': round(np.mean(all_lengths), 1),\n",
        "        }\n",
        "    else:\n",
        "        stats = {'count': 0, 'median': None, 'max': None, 'mean': None}\n",
        "\n",
        "    print(f\"\\n=== Length Statistics ===\")\n",
        "    print(f\"Samples: {stats['count']}\")\n",
        "    print(f\"Median: {stats['median']} tokens\")\n",
        "    print(f\"Max: {stats['max']} tokens\")\n",
        "\n",
        "    return stats"
      ],
      "metadata": {
        "id": "eval_run"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## RUN EXPERIMENTS\n",
        "---"
      ],
      "metadata": {
        "id": "run_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_model_length = 131000 # as in OWT"
      ],
      "metadata": {
        "id": "uKb1AZpNzB1Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "# ========================================\n",
        "# STEP 1: Train BD3-LM Base (L'=1024)\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 1: Training BD3-LM Base (block_size=1024)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "bd3lm_base_ckpt = train_run(\n",
        "    run_name=\"bd3lm_base_L1024\",\n",
        "    algo=\"bd3lm\",\n",
        "    block_size=1024,\n",
        "    max_steps=800,\n",
        "    extra_overrides=[\n",
        "        \"training.resample=false\",\n",
        "        \"algo.var_min=false\",\n",
        "    ]\n",
        ")\n",
        "print(f\"✓ Base: {bd3lm_base_ckpt}\")"
      ],
      "metadata": {
        "id": "step1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573d2528-4f5f-4e2a-911e-7618d08c31bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 1: Training BD3-LM Base (block_size=1024)\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ++data.max_train_samples=1500 ...\n",
            "k if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 568: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 618: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 668: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 718: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 768: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=800` reached.\n",
            "\n",
            "✓ Checkpoint: /content/repro_runs/bd3lm_base_L1024/checkpoints/best.ckpt\n",
            "✓ Base: /content/repro_runs/bd3lm_base_L1024/checkpoints/best.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 2: Fine-tune with L'=16\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: Fine-tuning BD3-LM (block_size=16)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "bd3lm_ft_ckpt = train_run(\n",
        "    run_name=\"bd3lm_finetune_L16\",\n",
        "    algo=\"bd3lm\",\n",
        "    block_size=16,\n",
        "    from_pretrained=bd3lm_base_ckpt,\n",
        "    max_steps=500,\n",
        "    extra_overrides=[\n",
        "        \"algo.var_min=false\",\n",
        "    ]\n",
        ")\n",
        "print(f\"✓ Fine-tuned: {bd3lm_ft_ckpt}\")"
      ],
      "metadata": {
        "id": "step2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7408f02c-cdfc-4283-ba0b-1de0c433aee8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 2: Fine-tuning BD3-LM (block_size=16)\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ++data.max_train_samples=1500 ...\n",
            "an either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 0, global step 300: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 0, global step 350: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 0, global step 400: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 468: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=500` reached.\n",
            "\n",
            "✓ Checkpoint: /content/repro_runs/bd3lm_finetune_L16/checkpoints/best.ckpt\n",
            "✓ Fine-tuned: /content/repro_runs/bd3lm_finetune_L16/checkpoints/best.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 3: Convert to HuggingFace format\n",
        "# THIS IS THE KEY FIX!\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: Converting to HuggingFace format\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "hf_checkpoint = convert_ckpt_to_hf(\n",
        "    ckpt_path=bd3lm_ft_ckpt,\n",
        "    output_dir=\"/content/hf_checkpoints/bd3lm_L16\",\n",
        "    block_size=16\n",
        ")\n",
        "print(f\"✓ HF checkpoint: {hf_checkpoint}\")"
      ],
      "metadata": {
        "id": "step3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770,
          "referenced_widgets": [
            "25018dc3436a46299cf084a5846b402d",
            "76a5423b66af49239d288a6cc672d301",
            "a0d491c829144beb8f026b8f99edab50",
            "2cc3dcf669d24a6f844c8af86c5d863f",
            "7dea60399c534921ba0d53c37071e631",
            "633cb2f4e9ae43edb5876f1f74e7cfe6",
            "db99940ea80a4c4c9587028e1234a906",
            "a7ee89f9518142dc9699d507257e54d3",
            "afc25485fa6642dba61c6aef4945596c",
            "a6c5f1c4797c4653b8a97cd934a8b0dd",
            "e547b731ab5943f39c71d8fcc04f446a",
            "303a6798e71249a3b72a995a417a6009",
            "79dae8b994cf4424978d32cb521d83ab",
            "fc6465e1c93d4c7bbe8e4a4de85c975f",
            "e1dfa0a0163f425db4d8e749ca040c6e",
            "256b07696ba948209d0212b6c3f07435",
            "2737d8e595d14b8ca769140dbababc7a",
            "e9f2319bd2194ad6a549eb89ac8f40f5",
            "1326a784b766425f98234f27240f9e7e",
            "e6d92af0b9ba431e88c50deb3db06007",
            "6d5bc419af444812b0e1820dbcee0ef0",
            "54f22ff0f1cf4e2199e0e7b4d4742e7d",
            "db47387e93e44e85a180744f4fd4e47b",
            "1d743a31e22948cca906a867f3b567a2",
            "fc05ee3ee59746ab92dd251aa4b8d91f",
            "b3804d4f1da7472a988eacab323f92a2",
            "89630db72baa47b7b095a4644b49c4f2",
            "b068cce355884479b8bbd6a512a52beb",
            "8fda66f742b643ffa6e63f50cec1a183",
            "3682c913700640809fc70355507cb2a6",
            "50ffd1d01b8b41c4af47ded2de46d265",
            "1c22533ac5ba42e19ea3ea3ff31d0e3e",
            "b835ab0958be4484ad8db230c29eb445",
            "4038c527a6f549f2b504adfca13eca67",
            "69d4157325904c5cae367b345016666a",
            "f31cf7f5468f4376ac301f79a57686b3",
            "9179815b40684f42aeb4e69b21d85b27",
            "117ef028b6e24345b31177d1a029d008",
            "d369c705ccc6421985f2035221155469",
            "14ef8430af164c71839cf2f890229f1b",
            "4f85e259b3a54dfbab102527e32b7f27",
            "2a6cd55679b046bc8698c0f8790f252d",
            "e9a3b11439fc4f9b8be711b25abc22f1",
            "513775c762424c70a7608a92415f2b8d"
          ]
        },
        "outputId": "d9d9e40d-9fdf-4f01-dd2f-bf8cde0fd350"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 3: Converting to HuggingFace format\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "Converting /content/repro_runs/bd3lm_finetune_L16/checkpoints/best.ckpt\n",
            "To: /content/hf_checkpoints/bd3lm_L16\n",
            "==================================================\n",
            "\n",
            "[1/4] Loading reference model from HuggingFace...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25018dc3436a46299cf084a5846b402d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "configuration_bd3lm.py: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "303a6798e71249a3b72a995a417a6009"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/kuleshov-group/bd3lm-owt-block_size16:\n",
            "- configuration_bd3lm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_bd3lm.py: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db47387e93e44e85a180744f4fd4e47b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/kuleshov-group/bd3lm-owt-block_size16:\n",
            "- modeling_bd3lm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/679M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4038c527a6f549f2b504adfca13eca67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2/4] Loading Lightning checkpoint...\n",
            "   Found 93 parameters\n",
            "\n",
            "[3/4] Cleaning state dict keys...\n",
            "   Cleaned keys: ['sampling_eps_min', 'sampling_eps_max', 'vocab_embed.embedding']\n",
            "\n",
            "[4/4] Applying our weights to model...\n",
            "   Missing: 131, Unexpected: 91\n",
            "\n",
            "✓ Saved to /content/hf_checkpoints/bd3lm_L16\n",
            "✓ HF checkpoint: /content/hf_checkpoints/bd3lm_L16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 4: Variable-Length Generation\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: Variable-Length Generation (Table 6)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "bd3lm_stats = eval_run(\n",
        "    algo=\"bd3lm\",\n",
        "    hf_checkpoint_path=hf_checkpoint,  # HF dir, NOT .ckpt!\n",
        "    block_size=16,\n",
        "    num_samples=50,\n",
        "    model_length=max_model_length\n",
        ")\n",
        "\n",
        "results.append({\n",
        "    \"model\": \"BD3-LM L'=16 (ours)\",\n",
        "    \"median_tokens\": bd3lm_stats['median'],\n",
        "    \"max_tokens\": bd3lm_stats['max'],\n",
        "})"
      ],
      "metadata": {
        "id": "step4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8ad45a-be86-4b99-fd82-02a62d15e6e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 4: Variable-Length Generation (Table 6)\n",
            "============================================================\n",
            "\rGenerating sample 1/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "                                     \n",
            "│                                                                               \n",
            "└── algo\n",
            "    └── name: bd3lm                                                             \n",
            "        backbone: hf_dit                                                        \n",
            "        parameterization: subs                                                  \n",
            "        time_conditioning: false                                                \n",
            "        T: 5000                                                                 \n",
            "        causal_attention: false                                                 \n",
            "        dropout: 0.0                                                            \n",
            "        ignore_bos: true                                                        \n",
            "        cross_attn: true                                                        \n",
            "        var_min: true                                                           \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "        reweight_loss: false                                                    \n",
            "        w_type: simple                                                          \n",
            "                                                                                \n",
            "[2026-01-30 22:47:24,029][__main__][INFO] - Generating samples.\n",
            "2026-01-30 22:47:25.108513: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769813245.126233   15295 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769813245.131324   15295 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769813245.144307   15295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769813245.144333   15295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769813245.144336   15295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769813245.144338   15295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\n",
            "Generating sample 2/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "                                     \n",
            "│                                                                               \n",
            "└── algo\n",
            "    └── name: bd3lm                                                             \n",
            "        backbone: hf_dit                                                        \n",
            "        parameterization: subs                                                  \n",
            "        time_conditioning: false                                                \n",
            "        T: 5000                                                                 \n",
            "        causal_attention: false                                                 \n",
            "        dropout: 0.0                                                            \n",
            "        ignore_bos: true                                                        \n",
            "        cross_attn: true                                                        \n",
            "        var_min: true                                                           \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "        reweight_loss: false                                                    \n",
            "        w_type: simple                                                          \n",
            "                                                                                \n",
            "[2026-01-30 22:48:03,463][__main__][INFO] - Generating samples.\n",
            "2026-01-30 22:48:06.679066: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769813286.935330   15435 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769813287.002564   15435 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769813287.559273   15435 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769813287.559306   15435 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769813287.559310   15435 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769813287.559312   15435 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\n",
            "Generating sample 3/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "                                     \n",
            "│                                                                               \n",
            "└── algo\n",
            "    └── name: bd3lm                                                             \n",
            "        backbone: hf_dit                                                        \n",
            "        parameterization: subs                                                  \n",
            "        time_conditioning: false                                                \n",
            "        T: 5000                                                                 \n",
            "        causal_attention: false                                                 \n",
            "        dropout: 0.0                                                            \n",
            "        ignore_bos: true                                                        \n",
            "        cross_attn: true                                                        \n",
            "        var_min: true                                                           \n",
            "        clip_search_delta: 0.05                                                 \n",
            "        clip_search_widths: []                                                  \n",
            "        fix_clipping: false                                                     \n",
            "        sampler: semi_ar                                                        \n",
            "        mdlm_loss_scale: false                                                  \n",
            "        reweight_loss: false                                                    \n",
            "        w_type: simple                                                          \n",
            "                                                                                \n",
            "[2026-01-30 22:48:50,302][__main__][INFO] - Generating samples.\n",
            "2026-01-30 22:48:53.549200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769813333.811167   15647 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769813333.882623   15647 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769813334.405310   15647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769813334.405342   15647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769813334.405345   15647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769813334.405348   15647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\n",
            "Generating sample 4/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Autoregressive LM for comparison\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training Autoregressive LM (block_size=16)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "ar_lm_ckpt = train_run(\n",
        "\trun_name=\"ar_lm_L16\",\n",
        "\talgo=\"ar\",\n",
        "\tblock_size=16,\n",
        "\tmax_steps=800,\n",
        ")\n",
        "print(f\"✓ AR LM: {ar_lm_ckpt}\")\n",
        "ar_lm_hf_checkpoint = convert_ckpt_to_hf(\n",
        "\tckpt_path=ar_lm_ckpt,\n",
        "\toutput_dir=\"/content/hf_checkpoints/ar_lm_L16\",\n",
        "\tblock_size=16\n",
        ")\n",
        "\n",
        "ar_lm_stats = eval_run(\n",
        "\talgo=\"ar_lm\",\n",
        "\thf_checkpoint_path=ar_lm_hf_checkpoint,\n",
        "\tblock_size=16,\n",
        "\tnum_samples=50,\n",
        "  model_length=max_model_length\n",
        ")\n",
        "\n",
        "results.append({\n",
        "\t\"model\": \"Autoregressive LM L'=16 (baseline)\",\n",
        "\t\"median_tokens\": ar_lm_stats['median'],\n",
        "\t\"max_tokens\": ar_lm_stats['max'],\n",
        "})"
      ],
      "metadata": {
        "id": "cypg8FWT8EzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SEDD for comparison\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training SEDD (block_size=16)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "sedd_ckpt = train_run(\n",
        "\trun_name=\"sedd_L16\",\n",
        "\talgo=\"sedd\",\n",
        "\tblock_size=16,\n",
        "\tmax_steps=800,\n",
        "\textra_overrides=[\n",
        "\t\t\"training.resample=false\",\n",
        "\t\t\"algo.var_min=false\",\n",
        "\t],\n",
        ")\n",
        "print(f\"✓ SEDD: {sedd_ckpt}\")\n",
        "sedd_hf_checkpoint = convert_ckpt_to_hf(\n",
        "\tckpt_path=sedd_ckpt,\n",
        "\toutput_dir=\"/content/hf_checkpoints/sedd_L16\",\n",
        "\tblock_size=16\n",
        ")\n",
        "\n",
        "sedd_stats = eval_run(\n",
        "\talgo=\"sedd\",\n",
        "\thf_checkpoint_path=sedd_hf_checkpoint,\n",
        "\tblock_size=16,\n",
        "\tnum_samples=50\n",
        ")\n",
        "\n",
        "results.append({\n",
        "\t\"model\": \"SEDD L'=16 (baseline)\",\n",
        "\t\"median_tokens\": sedd_stats['median'],\n",
        "\t\"max_tokens\": sedd_stats['max'],\n",
        "})"
      ],
      "metadata": {
        "id": "68EMLtUB82OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# RESULTS\n",
        "# ========================================\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TABLE 6 RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comparison = [\n",
        "    {\"model\": \"SEDD (paper)\", \"median_tokens\": 1021, \"max_tokens\": 1024},\n",
        "    {\"model\": \"BD3-LM L'=16 (paper)\", \"median_tokens\": 798, \"max_tokens\": 9982},\n",
        "] + results\n",
        "\n",
        "df = pd.DataFrame(comparison)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"KEY INSIGHT: SEDD limited to 1024, BD3-LM generates ~10x longer!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDbPBDAF3fXT"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}