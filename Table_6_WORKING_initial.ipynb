{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Table 6 Reproduction - WORKING VERSION\n",
        "\n",
        "## Fixes Applied:\n",
        "1. **Config keys**: Added `+` prefix for non-existing keys\n",
        "2. **Checkpoint conversion**: Convert `.ckpt` to HuggingFace format before `sample_eval`\n",
        "3. **Length extraction**: Parse actual token counts, not `len(log_text)`\n",
        "\n",
        "## Table 6 from paper:\n",
        "| Model | Median # tokens | Max # tokens |\n",
        "|-------|-----------------|-------------|\n",
        "| SEDD | 1021 | **1024** (limited!) |\n",
        "| BD3-LM L'=16 | 798 | **9982** |"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4936cfe-2b4c-4b5b-8ce3-babb5b0d7512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bd3lms'...\n",
            "remote: Enumerating objects: 899, done.\u001b[K\n",
            "remote: Counting objects: 100% (356/356), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 899 (delta 271), reused 261 (delta 211), pack-reused 543 (from 1)\u001b[K\n",
            "Receiving objects: 100% (899/899), 3.41 MiB | 31.42 MiB/s, done.\n",
            "Resolving deltas: 100% (565/565), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone YOUR fork\n",
        "!cd /content && rm -rf bd3lms\n",
        "!cd /content && git clone https://github.com/ntua-el21050/bd3lms.git\n",
        "\n",
        "!mkdir -p /content/bd3lms/data\n",
        "!mkdir -p /content/repro_runs\n",
        "!mkdir -p /content/hf_checkpoints\n",
        "!mkdir -p /content/sample_logs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics==1.6.2 datasets==3.3.2 einops==0.8.1 \\\n",
        "    hydra-core==1.3.2 lightning==2.5.0.post0 transformers==4.49.0 \\\n",
        "    huggingface_hub fsspec==2024.2.0 omegaconf==2.3.0"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import re\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.insert(0, '/content/bd3lms')\n",
        "\n",
        "def run_main(overrides, timeout=None):\n",
        "    \"\"\"Run main.py with overrides.\"\"\"\n",
        "    env = dict(os.environ)\n",
        "    env.setdefault(\"HYDRA_FULL_ERROR\", \"1\")\n",
        "    cmd = [sys.executable, \"-u\", \"bd3lms/main.py\", *overrides]\n",
        "    print(\"\\n$\", \" \".join(cmd[:8]), \"...\")\n",
        "    proc = subprocess.run(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        timeout=timeout,\n",
        "        check=False,\n",
        "        env=env,\n",
        "    )\n",
        "    print(proc.stdout[-3000:])\n",
        "    if proc.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed with return code {proc.returncode}\")\n",
        "    return proc.stdout\n",
        "\n",
        "\n",
        "def _small_loader_overrides(batch_size=4, num_workers=2):\n",
        "    return [\n",
        "        f\"loader.global_batch_size={batch_size}\",\n",
        "        f\"loader.eval_global_batch_size={batch_size}\",\n",
        "        f\"loader.batch_size={batch_size}\",\n",
        "        f\"loader.eval_batch_size={batch_size}\",\n",
        "        f\"loader.num_workers={num_workers}\",\n",
        "        \"trainer.accumulate_grad_batches=1\",\n",
        "    ]"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_run(run_name, algo, block_size=None, from_pretrained=None, max_steps=800, extra_overrides=None, model_length=1024):\n",
        "    \"\"\"Train a model.\"\"\"\n",
        "    save_dir = Path(\"/content/repro_runs\") / run_name\n",
        "    if save_dir.exists():\n",
        "        shutil.rmtree(save_dir)\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    overrides = [\n",
        "        \"mode=train\",\n",
        "        \"data=openwebtext-split\",\n",
        "        \"++data.cache_dir=/content/bd3lms/data\",       # ++ prefix!\n",
        "        \"++data.streaming=true\",                        # ++ prefix!\n",
        "        \"++data.max_train_samples=1500\",                # ++ prefix!\n",
        "        \"++data.max_valid_samples=100\",                 # ++ prefix!\n",
        "        \"++data.max_test_samples=100\",                  # ++ prefix!\n",
        "        \"model=tiny\",\n",
        "        f\"model.length={model_length}\",\n",
        "        \"model.attn_backend=sdpa\",\n",
        "        f\"algo={algo}\",\n",
        "        \"trainer.accelerator=gpu\",\n",
        "        \"trainer.devices=1\",\n",
        "        \"trainer.num_nodes=1\",\n",
        "        \"trainer.precision=16-mixed\",\n",
        "        \"trainer.num_sanity_val_steps=0\",\n",
        "        \"trainer.log_every_n_steps=20\",\n",
        "        \"trainer.val_check_interval=50\",\n",
        "        f\"trainer.max_steps={max_steps}\",\n",
        "        f\"checkpointing.save_dir={save_dir}\",\n",
        "        \"checkpointing.resume_from_ckpt=false\",\n",
        "        \"wandb=null\",\n",
        "    ]\n",
        "    overrides.extend(_small_loader_overrides(batch_size=4, num_workers=2))\n",
        "\n",
        "    if block_size is not None:\n",
        "        overrides.append(f\"block_size={block_size}\")\n",
        "    if from_pretrained is not None:\n",
        "        overrides.append(f\"training.from_pretrained={from_pretrained}\")\n",
        "        overrides.append(\"training.resample=true\")\n",
        "    if extra_overrides:\n",
        "        overrides.extend(extra_overrides)\n",
        "\n",
        "    _ = run_main(overrides)\n",
        "\n",
        "    # Find checkpoint\n",
        "    ckpt_dir = save_dir / \"checkpoints\"\n",
        "    for name in [\"best.ckpt\", \"last.ckpt\"]:\n",
        "        ckpt = ckpt_dir / name\n",
        "        if ckpt.exists():\n",
        "            print(f\"✓ Checkpoint: {ckpt}\")\n",
        "            return str(ckpt)\n",
        "\n",
        "    # List what we have\n",
        "    if ckpt_dir.exists():\n",
        "        print(f\"Available checkpoints: {list(ckpt_dir.glob('*.ckpt'))}\")\n",
        "    raise FileNotFoundError(f\"No checkpoint in {ckpt_dir}\")"
      ],
      "metadata": {
        "id": "train_run"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_ckpt_to_hf(ckpt_path, output_dir, block_size):\n",
        "    \"\"\"\n",
        "    Convert Lightning .ckpt to HuggingFace format.\n",
        "    \"\"\"\n",
        "    import transformers\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Converting {ckpt_path}\")\n",
        "    print(f\"To: {output_dir}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # Clean output dir\n",
        "    if os.path.exists(output_dir):\n",
        "        shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Step 1: Load reference model FROM HUGGINGFACE (with weights)\n",
        "    print(\"\\n[1/4] Loading reference model from HuggingFace...\")\n",
        "    ref_model_id = f\"kuleshov-group/bd3lm-owt-block_size{block_size}\"\n",
        "\n",
        "    try:\n",
        "        model = transformers.AutoModelForMaskedLM.from_pretrained(\n",
        "            ref_model_id,\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.float32\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: {e}\")\n",
        "        print(\"Trying block_size 16 as fallback...\")\n",
        "        model = transformers.AutoModelForMaskedLM.from_pretrained(\n",
        "            \"kuleshov-group/bd3lm-owt-block_size16\",\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.float32\n",
        "        )\n",
        "\n",
        "    # Step 2: Load Lightning checkpoint\n",
        "    print(\"\\n[2/4] Loading Lightning checkpoint...\")\n",
        "    checkpoint = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
        "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
        "    print(f\"   Found {len(state_dict)} parameters\")\n",
        "\n",
        "    # Step 3: Clean key names\n",
        "    print(\"\\n[3/4] Cleaning state dict keys...\")\n",
        "    cleaned = {}\n",
        "    for k, v in state_dict.items():\n",
        "        new_k = k\n",
        "        for prefix in ['backbone.', 'diffusion.backbone.', 'model.', 'module.']:\n",
        "            if new_k.startswith(prefix):\n",
        "                new_k = new_k[len(prefix):]\n",
        "        cleaned[new_k] = v\n",
        "    print(f\"   Cleaned keys: {list(cleaned.keys())[:3]}\")\n",
        "\n",
        "    # Step 4: Apply our weights to the model\n",
        "    print(\"\\n[4/4] Applying our weights to model...\")\n",
        "    missing, unexpected = model.load_state_dict(cleaned, strict=False)\n",
        "    print(f\"   Missing: {len(missing)}, Unexpected: {len(unexpected)}\")\n",
        "\n",
        "    # Save with our weights\n",
        "    model.save_pretrained(output_dir)\n",
        "\n",
        "    # Tokenizer\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2')\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    print(f\"\\n✓ Saved to {output_dir}\")\n",
        "    return output_dir"
      ],
      "metadata": {
        "id": "convert"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_length_stats(log_text, logdir=None):\n",
        "    \"\"\"\n",
        "    Extract actual token length statistics from CSV.\n",
        "    \"\"\"\n",
        "    lengths = []\n",
        "\n",
        "    # Read CSV file (BD3-LM saves as CSV without header)\n",
        "    if logdir and os.path.exists(logdir) and os.path.isfile(logdir):\n",
        "        try:\n",
        "            import pandas as pd\n",
        "            df = pd.read_csv(logdir, header=None)\n",
        "            # Column 1 is length\n",
        "            lengths.extend(df[1].dropna().astype(int).tolist())\n",
        "            print(f\"Found {len(lengths)} samples in CSV\")\n",
        "        except Exception as e:\n",
        "            print(f\"CSV error: {e}\")\n",
        "\n",
        "    if lengths:\n",
        "        return {\n",
        "            'count': len(lengths),\n",
        "            'median': int(np.median(lengths)),\n",
        "            'max': int(np.max(lengths)),\n",
        "            'mean': round(np.mean(lengths), 1),\n",
        "        }\n",
        "    return {'count': 0, 'median': None, 'max': None, 'mean': None}\n",
        "\n",
        "def eval_run(algo, hf_checkpoint_path, block_size=None, num_samples=50, extra_overrides=None, model_length=1024):\n",
        "    \"\"\"\n",
        "    Run sample_eval with HuggingFace checkpoint.\n",
        "    Run multiple times to collect samples (workaround for variable-length bug).\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    logfile = f\"/content/sample_logs/varlen_{algo}_bs{block_size}\"\n",
        "\n",
        "    # Clean up\n",
        "    if os.path.exists(logfile):\n",
        "        os.remove(logfile)\n",
        "\n",
        "    all_lengths = []\n",
        "\n",
        "    # Run multiple times with 1 sample each (workaround)\n",
        "    for i in range(num_samples):\n",
        "        print(f\"\\rGenerating sample {i+1}/{num_samples}...\", end=\"\")\n",
        "\n",
        "        overrides = [\n",
        "            \"mode=sample_eval\",\n",
        "            \"data=openwebtext-split\",\n",
        "            \"sampling.num_sample_batches=1\",  # 1 at a time!\n",
        "            \"++data.cache_dir=/content/bd3lms/data\",\n",
        "            \"++data.streaming=true\",\n",
        "            \"++data.max_test_samples=1\",\n",
        "            \"model=tiny\",\n",
        "            f\"model.length={model_length}\",\n",
        "            \"model.attn_backend=sdpa\",\n",
        "            f\"algo={algo}\",\n",
        "            \"algo.backbone=hf_dit\",\n",
        "            \"algo.T=5000\",\n",
        "            f\"eval.checkpoint_path={hf_checkpoint_path}\",\n",
        "            \"sampling.var_length=true\",\n",
        "            \"sampling.nucleus_p=0.9\",\n",
        "            \"sampling.kv_cache=true\",\n",
        "            f\"sampling.logdir={logfile}\",\n",
        "            f\"seed={42+i}\",  # Different seed each time\n",
        "            \"trainer.accelerator=gpu\",\n",
        "            \"trainer.devices=1\",\n",
        "            \"trainer.precision=16-mixed\",\n",
        "            \"wandb=null\",\n",
        "            f\"block_size={block_size}\",\n",
        "            \"loader.eval_batch_size=1\",\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            run_main(overrides)\n",
        "        except:\n",
        "            pass  # Continue on error\n",
        "\n",
        "    print(\"\\nDone!\")\n",
        "\n",
        "    # Read results from CSV\n",
        "    if os.path.exists(logfile) and os.path.isfile(logfile):\n",
        "        try:\n",
        "            df = pd.read_csv(logfile, header=None)\n",
        "            all_lengths = df[1].dropna().astype(int).tolist()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if all_lengths:\n",
        "        stats = {\n",
        "            'count': len(all_lengths),\n",
        "            'median': int(np.median(all_lengths)),\n",
        "            'max': int(np.max(all_lengths)),\n",
        "            'mean': round(np.mean(all_lengths), 1),\n",
        "        }\n",
        "    else:\n",
        "        stats = {'count': 0, 'median': None, 'max': None, 'mean': None}\n",
        "\n",
        "    print(f\"\\n=== Length Statistics ===\")\n",
        "    print(f\"Samples: {stats['count']}\")\n",
        "    print(f\"Median: {stats['median']} tokens\")\n",
        "    print(f\"Max: {stats['max']} tokens\")\n",
        "\n",
        "    return stats"
      ],
      "metadata": {
        "id": "eval_run"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## RUN EXPERIMENTS\n",
        "---"
      ],
      "metadata": {
        "id": "run_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_model_length = 4096 # Reduced from max_model_length (131000, as in OWT) to prevent OOM errors"
      ],
      "metadata": {
        "id": "uKb1AZpNzB1Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "# ========================================\n",
        "# STEP 1: Train BD3-LM Base (L'=1024)\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 1: Training BD3-LM Base (block_size=1024)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "bd3lm_base_ckpt = train_run(\n",
        "    run_name=\"bd3lm_base_L1024\",\n",
        "    algo=\"bd3lm\",\n",
        "    block_size=1024,\n",
        "    max_steps=800,\n",
        "    extra_overrides=[\n",
        "        \"training.resample=false\",\n",
        "        \"algo.var_min=false\",\n",
        "    ]\n",
        ")\n",
        "print(f\"✓ Base: {bd3lm_base_ckpt}\")"
      ],
      "metadata": {
        "id": "step1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a654443-3926-4e33-ef91-cfe1b3b7f254"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 1: Training BD3-LM Base (block_size=1024)\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ++data.max_train_samples=1500 ...\n",
            "k if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 568: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 618: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 668: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 718: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 768: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=800` reached.\n",
            "\n",
            "✓ Checkpoint: /content/repro_runs/bd3lm_base_L1024/checkpoints/best.ckpt\n",
            "✓ Base: /content/repro_runs/bd3lm_base_L1024/checkpoints/best.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 2: Fine-tune with L'=16\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: Fine-tuning BD3-LM (block_size=16)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "bd3lm_ft_ckpt = train_run(\n",
        "    run_name=\"bd3lm_finetune_L16\",\n",
        "    algo=\"bd3lm\",\n",
        "    block_size=16,\n",
        "    from_pretrained=bd3lm_base_ckpt,\n",
        "    max_steps=500,\n",
        "    extra_overrides=[\n",
        "        \"algo.var_min=false\",\n",
        "    ]\n",
        ")\n",
        "print(f\"✓ Fine-tuned: {bd3lm_ft_ckpt}\")"
      ],
      "metadata": {
        "id": "step2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf36d3d5-ca01-4307-9fdd-053f4d4d9a3e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 2: Fine-tuning BD3-LM (block_size=16)\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ++data.max_train_samples=1500 ...\n",
            "an either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 0, global step 300: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 0, global step 350: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 0, global step 400: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 468: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=500` reached.\n",
            "\n",
            "✓ Checkpoint: /content/repro_runs/bd3lm_finetune_L16/checkpoints/best.ckpt\n",
            "✓ Fine-tuned: /content/repro_runs/bd3lm_finetune_L16/checkpoints/best.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 3: Convert to HuggingFace format\n",
        "# THIS IS THE KEY FIX!\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: Converting to HuggingFace format\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "hf_checkpoint = convert_ckpt_to_hf(\n",
        "    ckpt_path=bd3lm_ft_ckpt,\n",
        "    output_dir=\"/content/hf_checkpoints/bd3lm_L16\",\n",
        "    block_size=16\n",
        ")\n",
        "print(f\"✓ HF checkpoint: {hf_checkpoint}\")"
      ],
      "metadata": {
        "id": "step3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4248376-9d99-4b58-a401-a7263cb5d065"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 3: Converting to HuggingFace format\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "Converting /content/repro_runs/bd3lm_finetune_L16/checkpoints/best.ckpt\n",
            "To: /content/hf_checkpoints/bd3lm_L16\n",
            "==================================================\n",
            "\n",
            "[1/4] Loading reference model from HuggingFace...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2/4] Loading Lightning checkpoint...\n",
            "   Found 93 parameters\n",
            "\n",
            "[3/4] Cleaning state dict keys...\n",
            "   Cleaned keys: ['sampling_eps_min', 'sampling_eps_max', 'vocab_embed.embedding']\n",
            "\n",
            "[4/4] Applying our weights to model...\n",
            "   Missing: 131, Unexpected: 91\n",
            "\n",
            "✓ Saved to /content/hf_checkpoints/bd3lm_L16\n",
            "✓ HF checkpoint: /content/hf_checkpoints/bd3lm_L16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 4: Variable-Length Generation\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: Variable-Length Generation (Table 6)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "bd3lm_stats = eval_run(\n",
        "    algo=\"bd3lm\",\n",
        "    hf_checkpoint_path=hf_checkpoint,  # HF dir, NOT .ckpt!\n",
        "    block_size=16,\n",
        "    num_samples=50,\n",
        "    model_length=max_model_length\n",
        ")\n",
        "\n",
        "results.append({\n",
        "    \"model\": \"BD3-LM L'=16 (ours)\",\n",
        "    \"median_tokens\": bd3lm_stats['median'],\n",
        "    \"max_tokens\": bd3lm_stats['max'],\n",
        "})"
      ],
      "metadata": {
        "id": "step4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83725c67-0210-4d0c-818f-15d5fe5fb6d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 4: Variable-Length Generation (Table 6)\n",
            "============================================================\n",
            "\rGenerating sample 1/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " German intelligence over the past decade, Spiegel and Guardian said.\\n\\nThe security conference will center on social networks such as hacking, surveillance, threats, government-to-government hacking and the terror networks and security policy.<|endoftext|>']\n",
            "Generative perplexity: tensor(33.0763, device='cuda:0')\n",
            "Entropy: tensor(5.1024, device='cuda:0')\n",
            "['<|endoftext|>CLOSE The NSA says President Barack Obama\\'s efforts to cryptanalyze phones in terrorism cases is getting worse and could pose a danger. David Martin reports. He also commented on the NSA\\'s response to leaked intelligence reports by the New York Times. Matt Kryger for USA TODAY\\n\\nThe top US military commander in Germany is planning to host one of world\\'s biggest security and terrorist conferences, according to a report in Spiegel and Guardian.\\n\\nJohn Dahlberg, vice commander at the US Special Operations Command, plans for the event June 30, according to the report, which provides more details on the identity of Germany\\'s attendees and potential visitors. This year\\'s information session will be held, while the previous is 2015\\'s edition.\\n\\nBut NSA spokesman Atary Schinnellner told CDT, in the German media, he couldn\\'t give more details about the event or exactly what was presented to him.\\n\\n\"Instead, it\\'s people that attend the security conference that people like [Black Rock] have access to at the time and time. It\\'s not going to be to anyone exactly what would be different from being there in person.\"\\n\\nThe NSA will be reviewing terrorism and related issues at a special \"Black Rock,\" whose mission is to gather information on terror attacks on U.S. soil\\n\\nThe person familiar with these plans said, just as WikiLeaks, the families of four journalists who are killed in the attacks, have suggested what could constitute a massive cyberattack on American military systems. The recent botnet caused a record number of deaths in 2015, and that also may be another tactic used to undermine the security of the targeted countries or organizations in the United States.\\n\\nThe person did specify what would happen during the attacks, and he didn\\'t specify what the cost would be. Due to privacy issues, the US district attorney\\'s office declined commented on this.\\n\\nAccording to military, Berg served as an operations director for Xiaomi, one of US-based smartphone manufacturers. Recently, he resigned as chairman of Xiaomi Plc, a company where his efforts became well received by technology magnate Eric Schmidt. In general, Schmidt has a strong perception of Germany, and his statement expressed confidence that the positive development and growth of tech is underway in Germany.\\n\\nBerg has been praised for his contribution to the German intelligence over the past decade, Spiegel and Guardian said.\\n\\nThe security conference will center on social networks such as hacking, surveillance, threats, government-to-government hacking and the terror networks and security policy.<|endoftext|>']\n",
            "\n",
            "Generating sample 2/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "omes private, confidential and private, not open data. Our children and grandchildren should have access to the information of each other.\\n\\nThis means developing a technology to ban mass recording of speech (public service filtering for example), access to banking, online censorship of sites on the Internet, instant messaging and even video streaming on mobile phones.\\n\\nFreedom of the Internet is a human right. In a perfect world, it’s just the basic human right; everyone works together for everyone’s benefit. But, despite the fact that there are unbreakable laws, you can’t help yourself in looking at the real issue.\\n\\nWhen this happens, the citizen, the government can or will not (work (or can and will very likely) rush to building a new encryption layer, simply because the current encryption doesn’t like how the data is processed. That data is kept by those who need it, those who can make the encryption work with no real use value. It’ll be impossible to decrypt and process, because all of this does part of the work that, in no way, anyone should be worrying about.\\n\\n“If we don’t make the internet safer, we are impeding the flow of information.” – Blog at the NSA website, @planningnoception (slightly translated)\\n\\nIn short, the big unanswered questions are: is the government making any effort to put in place some thing we’ll call the government secret, secret programs, secret machine stuff? Do we want the government being there to prevent the most terrorist plots? No, do we want the government in charge of controlling/coordinating domestic terrorists and terrorist threats at all the levels of authority in the Federal government?\\n\\nThe end result of this is not only the government no longer able to participate in our information, but also where we live, where we make money and things like that.\\n\\nAs Trump pointed out that in a move of a little faster than 9,000 words a single piece of legislation has been introduced with bipartisan support “Let me just say, one piece of legislation is worth a few hundred thousand words. And when it’s done it’s only the important thing: When you’ve got the sponsor in the bill, you just have the sponsor in the legislation.”\\n\\nUnfortunately, all this is a product of our behavior and systems.\\n\\nThe Congress is months and months time away from fulfilling one of the key promises of the Obama presidential campaign: keeping most of the public safe and, at the very least, financially secure.\\n\\nThe biggest outshot of that is destroying all of the pieces of what we are most likely to trust: we collect more user information, buy new products, keep up on our every move through more surveillance and tax collection and find more folks to hate.\\n\\nWhile our government may be better at control us today, it’s destroying these fundamental human rights, only making the overall situation worse for our democracy, and eroding our ability to compete and create increased competition.\\n\\n(Image by Getty Images)<|endoftext|>']\n",
            "\n",
            "Generating sample 3/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "3%|▎         | 8/256 [00:05<02:29,  1.66it/s]\n",
            "  4%|▎         | 9/256 [00:05<02:28,  1.66it/s]\n",
            "  4%|▍         | 10/256 [00:06<02:31,  1.62it/s]\n",
            "  4%|▍         | 11/256 [00:07<02:38,  1.54it/s]\n",
            "  5%|▍         | 12/256 [00:07<02:45,  1.48it/s]\n",
            "  5%|▌         | 13/256 [00:08<02:41,  1.50it/s]\n",
            "  5%|▌         | 14/256 [00:09<02:37,  1.54it/s]\n",
            "  6%|▌         | 15/256 [00:09<02:34,  1.56it/s]\n",
            "  6%|▋         | 16/256 [00:10<02:29,  1.60it/s]\n",
            "  6%|▋         | 16/256 [00:10<02:44,  1.46it/s]\n",
            "\n",
            "Sliding Window Gen PPL:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sliding Window Gen PPL: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n",
            "Sliding Window Gen PPL: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s]\n",
            "Text samples: ['<|endoftext|>(Photo: CBS Sports) USA basketball coach Jae Crowder was found holding his Jeep Cherokee after school on Friday, according to Houston police.\\n\\nIt was unclear if the accident was overrated, or due to Crowder’s heroic efforts to detachute the American college basketball-highpassing center’s ride to the rim.\\n\\nBCOA police say someone from NBA subsidiary Pouchy was working overtime to hobble Crowder when he was spotted on his Cherokee was so close to where he was leading into the lane that the vehicle crashed off on a 35.3 speed. He reported the accident to mall manager Bob Woodward, director of tournament basketball, according to NBC affiliate KFOR.\\n\\nIt is Pouchy custody and the coach shows up to Woodward “has got to get his name out to put him in the phone line up to get to the training arena,” camp counselor Larry Bishop tweeted.\\n\\nThe 10-man scrimmage out of Under Armour Field erupted after scoring late in the first quarter.\\n\\n“I’m thinking about now, I think, the championship,” center Derrick Jones said. “It’s not a long race. Let’s try.”\\n\\n...<|endoftext|>']\n",
            "Generative perplexity: tensor(73.8723, device='cuda:0')\n",
            "Entropy: tensor(4.6696, device='cuda:0')\n",
            "['<|endoftext|>(Photo: CBS Sports) USA basketball coach Jae Crowder was found holding his Jeep Cherokee after school on Friday, according to Houston police.\\n\\nIt was unclear if the accident was overrated, or due to Crowder’s heroic efforts to detachute the American college basketball-highpassing center’s ride to the rim.\\n\\nBCOA police say someone from NBA subsidiary Pouchy was working overtime to hobble Crowder when he was spotted on his Cherokee was so close to where he was leading into the lane that the vehicle crashed off on a 35.3 speed. He reported the accident to mall manager Bob Woodward, director of tournament basketball, according to NBC affiliate KFOR.\\n\\nIt is Pouchy custody and the coach shows up to Woodward “has got to get his name out to put him in the phone line up to get to the training arena,” camp counselor Larry Bishop tweeted.\\n\\nThe 10-man scrimmage out of Under Armour Field erupted after scoring late in the first quarter.\\n\\n“I’m thinking about now, I think, the championship,” center Derrick Jones said. “It’s not a long race. Let’s try.”\\n\\n...<|endoftext|>']\n",
            "\n",
            "Generating sample 4/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".85it/s]\n",
            "Sliding Window Gen PPL: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n",
            "Text samples: ['<|endoftext|>More than 60,000 jobs were lost during major attacks, in addition to a nationwide health insurgence caused by fighting\\n\\nRobots will become increasingly important in the future as companies seek out the possibility of wars, earthquakes in Asia’s ageing armies and a future Ebola, a new report says.\\n\\nThe report by the Business Industry and Intelligence Research, published Tuesday, represents the most comprehensive assessment about emerging technologies and significant demand for government efforts to share knowledge of human behaviour.\\n\\nThe project estimates that many jobs have been cut across all sectors of the economy in areas beyond the defence industry including healthcare, mobile communications, computer technology and retail services.\\n\\nMore than 60,000 jobs were lost during attacks, resulting in thousands of people losing their lives, in addition to the ongoing battles that left some 100,000 soldiers still missing, according to the report. The attacks saw an 80 per cent increase in fatalities and 120 per cent in losses due to a nationwide health insurgence the developing country, Australia, suffered most.\\n\\nThe report said the data about job loss, as well with statistics, needed to be broadly shared among governments and industry. The information was compiled provided by the Treasury, which manages the government’s public sector programmes.<|endoftext|>']\n",
            "Generative perplexity: tensor(31.2767, device='cuda:0')\n",
            "Entropy: tensor(4.6613, device='cuda:0')\n",
            "['<|endoftext|>More than 60,000 jobs were lost during major attacks, in addition to a nationwide health insurgence caused by fighting\\n\\nRobots will become increasingly important in the future as companies seek out the possibility of wars, earthquakes in Asia’s ageing armies and a future Ebola, a new report says.\\n\\nThe report by the Business Industry and Intelligence Research, published Tuesday, represents the most comprehensive assessment about emerging technologies and significant demand for government efforts to share knowledge of human behaviour.\\n\\nThe project estimates that many jobs have been cut across all sectors of the economy in areas beyond the defence industry including healthcare, mobile communications, computer technology and retail services.\\n\\nMore than 60,000 jobs were lost during attacks, resulting in thousands of people losing their lives, in addition to the ongoing battles that left some 100,000 soldiers still missing, according to the report. The attacks saw an 80 per cent increase in fatalities and 120 per cent in losses due to a nationwide health insurgence the developing country, Australia, suffered most.\\n\\nThe report said the data about job loss, as well with statistics, needed to be broadly shared among governments and industry. The information was compiled provided by the Treasury, which manages the government’s public sector programmes.<|endoftext|>']\n",
            "\n",
            "Generating sample 5/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "low cost, he said.\\n\\nHe said there is a lot more competition to work on projects because all the people are concentrating on making the solar energy business sustainable.\\n\\nFontanaich said it seems the industry leaders want to make solar development in the state, in general, just as well as in California. In California, only new entrants to make electricity for solar necessarily need the money, especially when you need for the energy. But in California all the solar entrants need the money.\\n\\n\"The solar industry, it\\'s taken big business across states,\" Fontanaich said. \"But here it\\'s taking the people of California of the business.\"\\n\\nBut for Fontanaich, the real issue is what is done for solar that is out of the region.\\n\\nHe says solar could grow by about 20 percent over the next five years -- with half of the growth coming from renewable sources. He said other countries are getting close.\\n\\nThat\\'s because all eight countries have a renewable goal. The U.S. will have to account for energy generation that grows to 30 percent of its power needs and to 20 percent of its renewable energy needs by 2050, more than growing in the four regions of the country, he said.\\n\\nThe U.S. has an opportunity to lead the efforts to get affordable energy from solar.\\n\\nAnd by reducing nuclear energy and diesel prices, solar energy can help in global warming.\\n\\nBut Fontanaich warned, California shouldn\\'t be a tough place for solar businesses. \"You want a strong business and if you\\'re not in the best state, not moving fast enough from where you\\'re looking to go, you can\\'t stay.\"\\n\\nOther news from: San Jose Mercury News\\n\\nLooking more news can share? Attention California energy, California emissions of every metric ton increases, increasing substantially in a single year, but to start, why do we emit so much in comparison to other states? With global carbon dioxide emissions rising 30 percent a year, what can you do to stop global warming? And why California (in theory) is getting the lead from a state capable of emitting as carbon dioxide as California. Alt-Cal fans look at Sacramento and digested this rabbit trap.\\n\\nRead More about 6 things we\\'ve learned about fracking, how natural gas, the Wind Stands and Helps Economy, Hey!, Contra Costa News, We Bees Are Killing Bees, Carnees and Liegermans, Climate Source: As Art, Related Articles\\n\\nThe most interesting question here at Solr has been one we have wondered: What on earth do we need? We’ve started to try and look at things, the energy and local development issues and continue to be in need of help from much needed government sources and some other news sources thought to help us here or here at Solr who have become financially strong enough to grow. Stay tuned for news from all of our members, but also don’t forget to follow us on social media and say a big you to our readers, fans of our website, and friends at Solr and be inspired to send one of your own there.\\n\\nTaking a quiz:<|endoftext|>']\n",
            "\n",
            "Generating sample 6/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769817826.255252   34824 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\n",
            "  0%|          | 0/256 [00:00<?, ?it/s]/root/.cache/huggingface/modules/transformers_modules/kuleshov-group/bd3lm-owt-block_size16/70129eacd09fe73158c81e46e9f4041d1c521ef6/modeling_bd3lm.py:571: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(dtype=self.precision):\n",
            "/root/.cache/huggingface/modules/transformers_modules/kuleshov-group/bd3lm-owt-block_size16/70129eacd09fe73158c81e46e9f4041d1c521ef6/modeling_bd3lm.py:184: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/root/.cache/huggingface/modules/transformers_modules/kuleshov-group/bd3lm-owt-block_size16/70129eacd09fe73158c81e46e9f4041d1c521ef6/modeling_bd3lm.py:355: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "\n",
            "  0%|          | 1/256 [00:00<03:43,  1.14it/s]\n",
            "  1%|          | 2/256 [00:01<03:00,  1.41it/s]\n",
            "  1%|          | 3/256 [00:02<02:46,  1.52it/s]\n",
            "  2%|▏         | 4/256 [00:02<02:38,  1.59it/s]\n",
            "  2%|▏         | 5/256 [00:03<02:34,  1.62it/s]\n",
            "  2%|▏         | 6/256 [00:03<02:38,  1.58it/s]\n",
            "  3%|▎         | 7/256 [00:04<02:43,  1.53it/s]\n",
            "  3%|▎         | 8/256 [00:05<02:49,  1.46it/s]\n",
            "  4%|▎         | 9/256 [00:05<02:42,  1.52it/s]\n",
            "  4%|▍         | 10/256 [00:06<02:37,  1.56it/s]\n",
            "  4%|▍         | 11/256 [00:07<02:34,  1.59it/s]\n",
            "  5%|▍         | 12/256 [00:07<02:31,  1.62it/s]\n",
            "  5%|▌         | 13/256 [00:08<02:28,  1.63it/s]\n",
            "  5%|▌         | 14/256 [00:08<02:26,  1.65it/s]\n",
            "  6%|▌         | 15/256 [00:09<02:27,  1.64it/s]\n",
            "  6%|▋         | 16/256 [00:10<02:25,  1.65it/s]\n",
            "  6%|▋         | 16/256 [00:10<02:41,  1.49it/s]\n",
            "\n",
            "Sliding Window Gen PPL:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sliding Window Gen PPL: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s]\n",
            "Sliding Window Gen PPL: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s]\n",
            "Text samples: ['<|endoftext|>1, 2, 4 5, Year Best Player, 6 times The Top American Team 100 years ago \"Almost, \"A Korean expensive expensive\\n\\nForeign top players [ edit ]\\n\\nWWW Team Top Player Community Net worth\\n\\nReferences [ edit ]\\n\\nFurther [ edit ]\\n\\nKLRO\\n\\nCitations edit ]<|endoftext|>']\n",
            "Generative perplexity: tensor(161.4035, device='cuda:0')\n",
            "Entropy: tensor(3.4096, device='cuda:0')\n",
            "['<|endoftext|>1, 2, 4 5, Year Best Player, 6 times The Top American Team 100 years ago \"Almost, \"A Korean expensive expensive\\n\\nForeign top players [ edit ]\\n\\nWWW Team Top Player Community Net worth\\n\\nReferences [ edit ]\\n\\nFurther [ edit ]\\n\\nKLRO\\n\\nCitations edit ]<|endoftext|>']\n",
            "\n",
            "Generating sample 7/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " coaches, as well as with Oso Pereira, Flamengo youth teams’ teams and national team should she be called to Brazil. She is well acquainted with her assistant head coach, Olive and is also part of the squad development group.\\n\\nZubair’s second appearance for Nigeria follows the surprise transfer of the head coach David Nuno to Costa Rica on Friday. Although the details were not made available to reporters before the game, Gabonas have agreed with the head coach not to comment, said Zubair, who was on Friday confirmed to be flying to Brazil, at 51 years old.\\n\\nPodcast: When Bill is hitting the Fan, interview Kondo\\n\\n“He is a very young guy, you need to know him first,” Zubair said. “He isn’t anything. I hope there’s a chance to be familiar with him also. I am ready for it to start.”\\n\\nWhile she was excited about the prospects of coaching but she said she thought the opportunity would not be favorable. She is not ready to make the whole transition as the U.S. national squad is already playing very well with the 4-2 diamond and diamond-back setup already at his disposal. “We are in a place where we are very cautious about what we do – there is no use saying about it, really,” she said.\\n\\nAlthough the coaching plans have already been in place for individual age groups in the form of youth academies and academy systems, there is an uncertainty about the senior players. Zubair and the senior players are not aware of any plans as much as the coaches, as the development team is “a very important factor – the main question is how to organize the development team,” said Zubair, who will be coaching the San Diego Galaxy academy. “We are trying to get them excited. We do everything we just try to do one thing – we are a group here. We don’t have many people thinking about us.”\\n\\nRecent months have seen growth of the U.S. national team in part because the players’ group of head coaches from CONCACAF, Brazil and Panama is now producing lots of young players.\\n\\nThe national team gained momentum on a youth level when the USAF Under- 18s squad won the U.S. Youth Championship, 3-0 in February, which the U.S. is not going ahead with. The U.S. won Under-18s at Canada’s North America before winning the U.S. Under-17s championship against Tobago FC at the 2013 World Cup.\\n\\nThe former first-year player was recruited by the head coach David Nuno, who was only recently in charge of the Portugal national team who went to the Copa Pico Deport’s Lid and Florida Championship in 2006. Olive is one of the first coaches of the U.S. national team on its way to the World Cup.\\n\\nShe added that the team would want to use the momentum of the U. U-16s soccer tournament, not just in a big way, in as good an idea as the United States can hope to build.\\n\\n“Even with fans in the U.S. can see we have a really young soccer team in Brazil to support and if we have any ideas about how to build a young team we’ll talk about it I think will be a success,” Zubair said.<|endoftext|>']\n",
            "\n",
            "Generating sample 8/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "is situation has been reduced and they have the same return value of their children.\\n\\nThe list of a number of adjustments to the revenue is also evident, including the adjustment also offered by your dividend earnings. I also know that the Government is using the existing Revenue Commissioner to decide which adjustments are needed to be approved. The Bureau of Benefits, supposedly a tool for guiding the Treasury, does not do this more than the Taxpayer Registration Office. The income tax used to do this are calculated to be taxable income, but they are actually calculated to be almost 1%. If you have therefore increased your tax by 10 times, the reason for this has reduced the calculation by a gain of £20 million.\\n\\nThe Government has been also under recent pressure in relation to reducing the amount of wealth each parent who has ended up in a child. It is known that having a big-money family, or in the children’s financial sector, adds up to a very significant amount. Two out of three households have large investments, and there is a Treasury tax if there is not enough investment to support these. It is almost as if you have a wealth of £1 billion and have passed this on to children, but the debt which you pay into on this is still.\\n\\nAnyone who has concerns about how to reduce tax burden on people who do not want to make these changes at all as you should explain this. There’s also the tax on children in Universal Credit and you’re thinking, “I haven’t had time to do this yet.” If I were only five years of age and had childcare, I wouldn’t have done this. But wait, my child is still at the appropriate age of 10 to offset the cost, so I didn’t have time to do this.\\n\\nAnd so I remind you that the government is actually attempting to be responsible for that type of tax avoidance. I hope that both proposals, as well as and your own example, will be properly taken. If you are elected, the last thing you want is for children to be the income that is shielding you from from the tax scheme. And no, a tax paid parent could not be placed in a position to leave your children and pay the tax that you spend on them.\\n\\nAs they put it, this is a government working to benefit your children. The Government has already given advanced instruction to parenting and parenting techniques, and it has promised that the Programme for Education, Training and Social Care, a social care scheme designed to make certain that parents understand the quality of their children, will be extended. Without this, you could be a child off to being given a job that has yet to be defined. This would leave you alone. This Government was responsible for the system that you created and it is going to be responsible for its actions towards your child. You don’t want your children to feel that they are out of control. I urge you to make sure that they receive the proper care they deserve for your children no matter how difficult the Government makes their lives harder.<|endoftext|>']\n",
            "\n",
            "Generating sample 9/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "stage does have some beautiful and good Uprising moments. But the game was really really long and showed the intensity of the defense giving up the fight.\\n\\nI’m really happy to see LD make a comeback in Europe. The hope is that the more recent matches, which I’ve liked to see more of and that I don’t assume anyone doesn’t like him personally, are going to be tougher if they can put him in with another strong line-up. Personally, I am really happy with the timing of his comeback. I have always wanted LD in a top roster and, from the last pro series he starts, there has never been a series that he never won. I don’t know where LD will do next. One of his best matches was against ViVi in the last one back in April. It should not be so easy for him and LD, I hope he makes it!<|endoftext|>']\n",
            "Generative perplexity: tensor(41.7262, device='cuda:0')\n",
            "Entropy: tensor(5.0766, device='cuda:0')\n",
            "['<|endoftext|>Why will you give up?Sunday, November 25, 2015 by:Dominik Luth StaffingThey had finished the game after a period of fighting at the same point. They finally set up a defense at the ball on stage and moved on 2 paces earlier than usual. But there was no time in that period and the Czech defense had quite completely thrown off some of the events they had planned to prepare for that situation. They didn’t hesitate however because they had been discussing whether to take an indefinite break from practice due to the upcoming match. They thought that they might well show off one strength or another in a rare quirk in the mass of both the defenders and their teammates and the use of their big explosive double pistols, making one after one of them. They did a really good job and they were able to use good speed to do this job! So they won the match called out for the final three stages. Unfortunately this match ended in a short two stages which could have been punished with a different kind of penalties having won the last! I have to thank for all the good planning. It was only a short one but the victory was very much for the best. If someone ever failed to give up and it has to pay off. The lives of LD or H3cK weren’t saved and they still need treatment. That is a shame! The stage does have some beautiful and good Uprising moments. But the game was really really long and showed the intensity of the defense giving up the fight.\\n\\nI’m really happy to see LD make a comeback in Europe. The hope is that the more recent matches, which I’ve liked to see more of and that I don’t assume anyone doesn’t like him personally, are going to be tougher if they can put him in with another strong line-up. Personally, I am really happy with the timing of his comeback. I have always wanted LD in a top roster and, from the last pro series he starts, there has never been a series that he never won. I don’t know where LD will do next. One of his best matches was against ViVi in the last one back in April. It should not be so easy for him and LD, I hope he makes it!<|endoftext|>']\n",
            "\n",
            "Generating sample 10/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ", who is an executive with Univision, said projects in such neighbourhoods had support from the SF Club in the US, a nonprofit called Design Rising.\\n\\n\"[Big Tent] is a great experiment and it is an excellent example of which way creative designers can integrate into society and transform their lives,\" he said. \"For example, designing a townhouse with a very minimalist look, leading to gender equity, gender, sexuality and city, taking more than just brick and mortar townhouses, art and creative designers creates something very personal.\"\\n\\nThe Newberry market (in Halkandorf)\\n\\n\"The fact that the gallery space is shut down for 30 minutes.\"\\n\\nLeft: The historic building in Newberry Rector: the Empty city: Where\\'s weekly murders happen? Right: This building is similar to Lower Manhattan or Manhattan: the \"soapster city in Brussels...\" http: …\\n\\nQuebec\\'s underground system and higher-capacity \\'sustainable metro\\'\\n\\nFrench architect and former supporter of the Socialist party, DNROP, Gérale Garcia first conceived of the creation of an Underground system in the French countryside, this time with the ultimate goal of building a ground floor building within a city-level underground system.\\n\\nIns a planned underground system is a concrete tower separated through a mini-nasium, constructed of steel that is used in underground heating for the city.\\n\\nIn the first year there were 10 units of construction, future plans planned this to reach 150.\\n\\nYosein Weldon in 1976 (middle)\\n\\nTo the right is a mesh of covered or underground structures - 1931.\\n\\nTo the left is a concrete tower, 1877 - 1890.\\n\\nAs well as underground collectivization, in 1976 construction of the city\\'s underground and subterranean metro, which was built in Europe\\'s tunnels station, which covered 3,000 metres underground plus 50,000 metres outside, allowed for a highly efficient concourse.\\n\\nCurrently eight stations are built underground in France, with an average of 124 kmelevated and, with the metro line, no more underground than the seven that were, previous to the Newberry project (in the Vivês-Galáre valley).\\n\\nFuture Buses\\n\\nThe club\\'s site has three of their planned new Buses: the second in Newberry, one in Halkandorf, in Brussels and a third in the Brussels suburb, Saadadie-Bratric.\\n\\nFacebook is trying to get a design from Design Rising for its Design Platform.\\n\\nFacebook has shown a design for the third Brussels suburb, Saadad. Photograph: Italia Angelides\\n\\n\"We prefer low density with a lot of high high-rises and hopefully we can also use a designer,\" said Carlos Valdete about his job.\\n\\n\"We try to keep the smaller buildings and the idea of this huge underground system,\" he said, \"a way to save space.\"\\n\\nJonathon Friedman - We Undone the Rejection of Fusch: Design Rising, Designer Standing: Facebook | Twitter @designriseofficial |\\n\\nVisit the Newberry Museum for more details. The Belgian Reporter, Jan Vikas Wolfer, contributed to this story<|endoftext|>']\n",
            "\n",
            "Generating sample 11/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " the Outer Spiders. When we close up the study of the Outer Spiders and the world’s most living breeds, can we how they lived all of time? Are they there?\\n\\nThere is a lot of skepticism on the part of this particular topic. In one study, Kate Cuthreckenham estimated that the human Outer Spiders lived for about an 1.5 years. That’s true. Just after that one year increase, Cuthreckerenham lived her entire life. But because of the history of the Outer Spiders and the analysis of Quicksand, many more researchers in the field think that the data of a study recently come out is more plausible. Meanwhile, several other studies studies by different experts have done some more research more strongly than others, but last week on The Outsider Report, we discussed the studies by Myer, Williams and and Lebruore, it took another year for an equivalent study to come out, but when we found it looked at the same two breeds, they all were pretty consistent.\\n\\nThere have been a lot of studies that claimed, such as studies that found the current population of the Outer Spiders are lactose intolerant, including the theory that these individuals with lactose intolerance have not existed in the past. While this claim could possibly be quite the same as that of modern humans, it has at least two different aspects. First, we have a study that included an observation of a particular person who is part of our world’s population, and we have a different study that had to gather evidence for the existence of this person. Yes, we do have this ability to do this, but we’ve only been doing it for thousands of years. Consequently, there is still a lot of theoretical evidence because of exactly exactly how this person died.\\n\\nThen there are a lot of studies showing that living animals (chids, pygids, for example) live very long lives. But living in extended time takes a very long amount of time, usually from about 40 to 60 years, and about as long as your life. Science is still one of those disciplines that has been over-developed for many centuries like it was with a few decades ago and such. It’s just like saying that evolutionary theory matters. But there are many more ideas in the world that are indeed valid regarding long term living of not only organisms. However, there’s issues and problems that seem even more important, that can be resolved by focusing on these questions.\\n\\nSo that concludes our fun little study of the past of the Outer Spiders. I expect there are quite a lot of others who may have worked on our history not only around here, but even here. Take Quicksand saying “Cyclapis Hollonian“ is the one that taught us everything. Now, and this time I’m talking about spiders and cockroaches and bed bugs. Maybe, again, we’ve learned something useful. I would give it good looks and enjoy!\\n\\nWatch more videos and series like this on Ex Outsider below:\\n\\nIsland History – Origins – Vol. 1\\n\\nSalt Island History – Vol. 2\\n\\nSalt Island History Vol. 3<|endoftext|>']\n",
            "\n",
            "Generating sample 12/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "rnalism Bureau carries an amendment of the constitution of the state, and is authorized by a central court to publish, process, and publish all information. The Supreme Court (The President) allows the publication of anonymous letters to journalists, so that they are presented by the public as a matter of importance and not a matter of the central government. The informations are made in the national authorities’ official interest since the implementation of the solution of two problems is a matter of importance and is mentioned in this article. Thanks for the editorial value of this article in policy sections. We should not be bombarded with the weakness of a ruling Iranian court.\\n\\nThe very statement by Iranian President, President Hassan Rouhani, that “one of Iran’s most powerful gifts” to the world (http://www.kafarbar.org/yet-official-message-war-nayhani-is-vauling/) is sure as an Iranian sign that we are not just being told by our government and the top officials in the state as a consequence that it is okay to violate Iran’s own legal procedures, to fail to recognize the totalitarian dictatorship of Iran, to use repressive methods to censor free publications, and to to block the opponents of the state from favorable ones.\\n\\nAnd what can we expect from the Iranian government, if “my-key-key, fatwa on my boss from the page of the new-criticized Iranian newspaper” blocks many of the international efforts against Iran? What can the governments and the courts of the world think of Iranian children who make statements on Iran-official TV, or who are part of the international pressure on Iran lifted? If the Iranian government simply block free press of expression in the US, then we can expect that the regime and its proxies will now recognize themselves with nuclear weapons.\\n\\nIn truth, the methods they are using are not in the same way that the Syria or the Lebanon approach, but it is better than the military training places of terrorists in the United States. Thus, I will advise people to treat the action of the state of Iran against criminals and journalists (which are, of course) correctly and might accept the solution of the situation as such. I would not allow someone who expresses belief in terrorism to face arrest from Iran (unless his son had forced him travel to Iran from the US, where they have the right to visit). He is not criminal and should be afraid to write the press.\\n\\nThanks so much! I truly hope that the Third Republic will not repeat such mistakes. Today’s Iran is truly a free and independent state, and it does not only suffer the consequences of corruption and human rights, but it depends on the support of the ruling elite. Today, the rules of the regime are made with predictable and inexcusable speed, in which the ruling elite do not play a part. I hope that, if they play a small role, the regime knows that it can not live with this type of “socialism” for the long term. It will take time, but that time.<|endoftext|>']\n",
            "\n",
            "Generating sample 13/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "icans had to spend six weeks in a lunar ring before it could be sent to carry humans on Earth.\\n\\nThe Apollo astronauts did not have that long deal with the Soviets and astronauts did not walk directly to the moon in 1969 but in 1972. The landing in September 5, 1972 was the first mission to send humans to the lunar surface.\\n\\nAt rest: Lunar Reconnaissance Moon Express Image caption NASA/LM\\n\\nMars\\n\\nCredit: NASA/LM\\n\\nHere\\'s what you might have seen if you were on the moon:\\n\\nThe rover was supposed to look on the lunar surface.\\n\\nThe rover\\'s robot started to work again, keeping parts of it intact.\\n\\nThe robots are ready to fly today.\\n\\nHere are the first and the third lunar rovers, Image from NASA/LM\\n\\nAt the planned \"mountain\" rendezvous point, the Apollo rover, identified as the Laboratory Lunar Express, was to pick a site to descend onto the lunar surface. After plunging deeper into the moon\\'s lunar interior again, it came to Mars.\\n\\nNow you\\'ve seen Mars, Image from NASA/LM. The rover made its way out orbit to Mars through the Midspace Access Project, known as MERC.\\n\\nThe lander is ready to fly and is to continue its missions to create a completely new map of the red planet. Curiosity is on mission status; Apollo and the near-Earth rover are expected to go to Mars.\\n\\nIt was planned to ascend back to orbit before NASA launched it to return to orbit to Mars, followed by a return.\\n\\nEuropean Space Agency/ESA Image caption NASA/ESA\\n\\nFollow up: the Gemini program\\n\\nA huge amount of information was brought back, as for NASA after Apollo, it was time for a manned mission.\\n\\nNASA would fly into the moon on 25th, 1969. It was originally intended to be twice as dangerous as the human mission was, due to the launch of a spacecraft that would inspect the first landing sites. The Apollo astronauts did what should have done if they knew they had no route back to the landing gear.\\n\\nInstead, they learned of the crash and landed.\\n\\nImage: NASA/ ESA/European Space Research Agency/ESA / NASA/ESA\\n\\nCommander Moonwalked was supposed to launch from a Saturn, but the reason was it may have been prevented from landing due to closer to Earth orbit. A ground shuttle mission in orbit was called off by Apollo and NASA/ESA lunar reconnaissance missions.\\n\\nThe moon will look differently by year and year.\\n\\nThanks to follow-up culture, astronaut Scott will still be in lunar orbit. He will be decked in a research laboratory, and built by a team in France.11 The telescope will have a high resolution on the lunar surface and will be best suited for the mission, covering the three decade-long mission and the cost of billion.\\n\\nA better understanding of the Moon\\'s history\\n\\nThe opportunity to look at the future Moon is an amazing gift. The light picked up from a telescope that has been panned a panorama of a sea, a portion of the size of the Milky Way, and a slice of space that resides in a space that is home to the 40th Russian flag.<|endoftext|>']\n",
            "\n",
            "Generating sample 14/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "to both you and your family.”\\n\\nNot only would that change the concept, but by the U.S. on Monday, Muslims may also be up in arms, again for odd reasons. The Washington Post’s James Cook reports:\\n\\nElections are up for 12 days and legislative sessions are up for four weeks. But remarks in the document indicate that no changes were made by the administration that could allow individuals to circumvent the elections. The absence of legislative acts, though, could cause panic among some U.S. Muslims who might use the weekend, hoping that the unrest would not turn out to a “great-scale mass panic” and that U.S. Muslims, especially Muslim-Americans, are more likely to experience a new terrorist attack.\\n\\nJamar Llaniah, founder of the blog The Master of the World Illusion, believes that the change in the schedule of the voting in California is a bigger problem than the sort Muslims are protesting. The public will still be voting on Sunday. And in Pennsylvania, a person who harassed several Muslims for distributing a book surrounded by Muslim women allegedly cursed at them. Some suspect that the change of language was on a conscious basis for a false allegation from a highly volatile group that hasn’t been included in the voter database.\\n\\nWell, it wasn’t. As Cook reports, the federal government has not taken action and was unable to intervene. It was also unclear whether the Muslims have enough that the government can say to interfere.\\n\\nWerdlow states that there are no reports of an outright ban on voting from cities like Texas, where the ACLU is the plaintiffs. She notes that, prior to the protests in California, “we didn’t hear” about an alleged “muslim vote” that would become law. She also reports that Muslims defied the order by accepting the official results. “Today, only Muslim voters can do away with it,” Werdlow reports.\\n\\nWerdlow also points out that the administration is following the law. “It’s known that every vote is ever contested and every civil dispute, but was granted only to a race that does not begin with a Muslim, whose population is 40 percent Muslim—the only reason it even merits discrimination,” she writes. “Finally, the Constitution has made it impossible to prohibit free voting.”\\n\\nThat said, in addition to changing the voting restrictions, the administration also has suggested that it become easier for officials to vote against Muslims every day, before following up on public records and evidence. Officials say that they may consider intervening in instances like the one in Philadelphia tomorrow. Government representatives have been meeting with Muslim residents, and whatever what that agenda is, it will be more akin to the on-line record.\\n\\nSome people have even started considering the practice of voting if they are still barred from the election, Cook reports at the Associated Press Thursday.\\n\\nCorrection: Alhaz at the top of this article erroneously said the voting ban was a felony. IS NOT a felony.<|endoftext|>']\n",
            "\n",
            "Generating sample 15/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " garlic rub, the wok and the cheese roll to make them taste so good that it doesn’t carry enough heat.\\n\\nThey also work with potatoes and white cheese. Again, both taste great; if you put your fingers on it, making it fit with toppings and cheese, it tastes just well.\\n\\nBut a steak is only worth with fat that is going nicely rather than the fat that’s the problem. The French cook had to eat that steak, but that’s what the chef ate all the time. When you cook it in a tight place like microwave, you’re cooking fat, not fat.\\n\\nThere is another fantastic way to make the steaks without it — to leave them out, use paper towels or even put on a fryer (for the name's sake), just to dry it out and let the fat cooks and cook.\\n\\nThe poor science for fat contamination in sausages\\n\\nThe steaming method means that it takes longer to saute, with little harm to the roast. I like to call this because it makes the time and effort of grilling sausages very tricky when it's cooking. That's because the wok is working — so that the cooks sit on the meat so that the fat penetrates and sinks back.\\n\\nThe steaks in the process get the fat out before it sprays off to other surfaces (like braising and in cooking).\\n\\nThat timing is important because meat fats don’t end up binding together because there's already a fat enough cooking for juicing, and then foods have to dissociate. Like a piece of meat, both fat and butter will start together. It takes two to three hours to get to that.\\n\\nBut because the freezing methods work so well, as the meat is becoming more and more cooked, they also take less time to make a steak.\\n\\nMale lamb hens need about 5 to 6 hours to decide which kind of meat is going to be cooked. That's an average of 3 hours depending on the animal.\\n\\nWhat about steak? Steaks costs at least $20,000 per pound. Because most hard-cooked meat has a fat, and because they have good iron they can easily take about 4-5 1/2 hours to cook the meat. Since it’s known that it will never cook as well in the freezer as beef, the problem is that what we’ve been using to make beef has stayed with us for so long that we are looking for a different step that that better preserves it.\\n\\nA cow has a simple, flexible way to extract some of the fat from the meat. It’s called a tool called a stick (or blade). There’s a process to pick it out of the meat and use it on the heat while butchering the meat, then seeding it from the butcher before putting it in the oven. That takes the heat that ends up pulling it out of the meat, where it forms it on a blade and turns it into the end of the meat. You can also use some clay or a stick to peel off the muscle, and it has to take a few hours more.\\n\\nLet your meat cook and maintain is key, no matter how much meat you use. If the method is used for the steaks to be cooked properly, the better.\\n\\nRelated content\\n\\nPastry can give you a great lot of fresh air and soil\\n\\n8 very good steaks that are still good to taste<|endoftext|>\"]\n",
            "\n",
            "Generating sample 16/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " of gas imports into the US, because the greenhouse effect, which turns into money in economies and economic infrastructure, exists; not even enough to provide the resources to make those life-threatening situations livable for everyone.\\n\\nSo we know that governments are still trying to play to save the planet, and a recent report written on this issue was published in the National Academy of Sciences provides the only definitive data available for the Paris Climate Agreement.\\n\\nUnder the United States’ pollution laws, Pruitt is right behind all of the dirty tricks.\\n\\nWith his European Commission’s decision to limit emissions of the amount of greenhouse gases in a variety of industrial products, he has achieved this. By 2020 we see no human-induced warming in the world.\\n\\nAnd yet, he’s ready to give the EPA laws, like him and the climate deniers, who are largely derived in Europe already, to the masters of that ocean-stream pollution. They’re supposed to do even more mining offshore. But when they turn up, they end up being singled out by environmental law.\\n\\nIf they’re all on the record, proving that man burning fossil fuel was a natural cause, we will fine them billions of dollars. They’ll not get a 10-year sentence, because it never does.\\n\\nThey will have the green cards and have to count on other governments to give them the money to clean their oceans and rivers, not have the money to destroy them, change their climate, reduce their use of energy, pay for these well-run farms and small businesses.\\n\\nSo as for these environmental laws, totally incompatible with the authority they are operating under, all they’ve got left is to punish the perpetrators, and the children, because they will get, for their crimes, tens of billions of dollars back from society, and awards for their careers ‘haunted’.\\n\\nSo if the fear of human destruction is not a factor in the equation, there’s very little we can add that out to explain what causes this problem. If coal or electric power plants, or oil or coal, were going to change, we would be sure to do it. But if there was no change, we would react accordingly, attack them.\\n\\nSo if we’re being asked, what is the danger about climate change, the reason, then we should, in my opinion, climate change as an end to the human world. If it is also used up as a means to take people out of the world unless we put up something of decent living conditions, then by means of this, the case is for permanent migration, to the large world, to the big world, including not half of the world, because this is to solve the problem.\\n\\nThat is why we are continuing to pay more attention to climate change as a concern. We are better understand how humans affect the climate, and we need to know when we can begin to address this problem.\\n\\nLike what you read? Take a moment for our NEW SUBSCRIPTION!\\n\\nThank you for The McKernan Report today because you agree to share your thoughts and opinions with our Patents.<|endoftext|>']\n",
            "\n",
            "Generating sample 17/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "or all the terminals.\\n\\nThe ships\\' failed spill in the Plows River was described by the Point Vaux Front Shipping Coast Safety Study. A series of skidded shows accompanied by some maritime danger. Exhibit A was a V-shaped drain failure that led to a tugboat crashing.[2] Exhibit B was a significant storm coming upstream of where fish were being dumped in Philadelphia, called a \"fragment\".[3] More than 11,000 people arrived to take part in the dam project.[4][5]\\n\\nThe significant interruption to the system and with their connection on parallel lines of land was completed in 1952 to provide services to the dam control center and the tug operations center.\\n\\nThe Two Rivers Bay was created once again as a State-level Interbay Condominium in 1971.\\n\\nIn 1969 the teachers union (the Northern California Teachers Union) sued the City of Two Rivers Bay. Roads west and south of the Two Rivers Bay have never been maintained except for a non-existent portion of highway west where there is a dedicated \"City Drive.\" Roads provide services to the city traffic in excess.\\n\\nAdditional funding was awarded to the Interbay Authority by Oakland County and Oakland Transportation. Seven engineers became full-time employees of Interbay Bay in 1973, on merit and a demer and pay, for their professional contributions. In 1974 as a measure of success, Interbay Bay changed from an environmental organization to an enterprise.\\n\\nConstruction [ edit ]\\n\\nThere were other projects undertaken in the Northwest region. The River began its construction just as a river system connecting the area\\'s western border rivers, just before the controversial Sykes-Barre Treaty was signed in April 1913. It was planned primarily as a flowway connecting the river and lake, its first being constructed on August 18, 1925, near the Fort Peck Railroad, which was completed and unknown to the public. The channel was opened on September 18th, 1930, but was partially interrupted by a severe storm shortly before that.\\n\\nThe U.S. Coast Guard and the U.S and Guard and Coast Guard Corps are located in Aqueduct Canyon, and hold its Dam in part of the valley.[6 Many of Aqueduct walls are oriented at the valley and, instead of leaving each other\\'s proper discrete signs of alignment, bring them together with the bay.\\n\\nThe channels downstream of the Aqueduct flow from the mouth of the river and drains up and down the river but during the first month the drain runs approximately 5 miles (10 km) down at Chapple Canyon, by the second month the flow is approximately 3 miles (5 km) at the mouth of Forsythe River. By the time all of it is completed, the channel is flowing to a San Joaquin Valley to a flow of two miles (two km) out at Fillmore River Park. The estuary that protrudes to the 2nd Bay estuary is 35 miles (49.76 km) wide) which was the result of a small depression estuary from the south side of Lake Superior near the beginning of the 1960s. The estuary begins for about four months annually after']\n",
            "\n",
            "Generating sample 18/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "ing about different sides then at this point in time. I do not understand that. At least three countries are we going to do that?\\n\\nYes: Do you think you will get those guys down? If you had big clubs, you have to change in the squad and that is in your favour and, yes, you do a good job and people are against you. But a change in direction? What does that do to you? What do you have done, because that happens everywhere in football. It might be different, but I do the same thing that I have done. It's much more positive. So should you be a manager than it was at big clubs.\\n\\nNo: We are still not at the big clubs. We are not in Europe yet. I would like to stay and I think there will be a change the players now. I think it will be at Real Madrid as well, at the big clubs and the big teams when they are in Europe. I just think it will be a good change so, that is the part where the squad I have put together is looking back at. It is one of how the team has come together stronger. I am no comparison, I'm not working with players. I am not talking about the players and the league as it is. It is an important step in the team.\\n\\nYes: I don't understand, I don't blame people who let me down in that sense. We should be heading towards a team that is for the English side and the future side of the English football club is for the big clubs and, one day I have to convince those big clubs to select a team that is for the big clubs in the country. I'll say that now and we are going to find out.\\n\\nNo: All right, then let's get back to the football club.\\n\\nEngland: It is extremely difficult to manage, but you are one of the big clubs? No, you are not the only one in the football club. I understand that. The bigger club have come. There is a push for better players. You have to bring in players and teams from, we were in Manchester United in Spain. We are European clubs. We have to decide where and where to take players as well and if not there, then Europe. London and Manchester clubs both want to bring them and European clubs want them.\\n\\nHow is England managing its own team though? Yes: I hope to bring players from Manchester United and at any club. We are being linked with Manchester United and Barcelona. When I spoke to Alex Ferguson at Manchester United, is it your opinion that Manchester United, Manchester United and Barcelona are not the country? No: I would say it is the biggest countries.\\n\\nDo you have any ideas for Jose Mourinho? Who is your favourite manager? No: He is not being linked with Liverpool. But I have got there because his money is such, such money in the Premier League, as well as being spent with the money that he still has and has made those clubs the Champions League because, I believe in him. He has been linked in any way more strongly than others I have to talk about. He is very good but those two don't have any respect for each other. My guess is the next manager at United will be Chelsea and then Liverpool.<|endoftext|>\"]\n",
            "\n",
            "Generating sample 19/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "times.\\n\\nRaucous football\\n\\n\"A huge fan base - 200,000! To have a game here in England is incredible.\\n\\n\"It is great to come back back to see that we have done everything we could and been the city\\'s leaders. There is Manchester United wanting to play for us.\\n\\n\"I am very happy to be here, a big club and to have a lot to play - it really helps.\\n\\n\"As many would say, I am sad that he has left. I am not going to see him again. It is the most important thing for me. But it is all about things coming together and my wanting to stay in the team.\"\\n\\nHe returns to the Premier League side on Monday, three months after his big day at Middlesbrough, and he has been impressed with the team\\'s football.\\n\\nOn the sheets: 4 goals in 2013 (Middles FC, Blackburn 1, QPR 1, Richmond 1 –), 0 goals (Burnley 3, Everton 1, Brentford, Bolton 0 –), 0 goals (Manchester Town 3, Colchester 2-0, Barnsley 1, Blackburn, Blackburn 2-0) 3 Goals since December 28, 2010<|endoftext|>']\n",
            "Generative perplexity: tensor(30.2263, device='cuda:0')\n",
            "Entropy: tensor(5.0972, device='cuda:0')\n",
            "['<|endoftext|>ES Football Newsletter Enter your email address Thank We We enter the email address stories address is Fill out this field Email address is invalid You already or register with your account Please log or register with your social account\\n\\nBarnbrough signed star striker Michael Richards from his former Premier League side Blackburn for £5m a month - but admits he loves that the striker decided to leave.\\n\\nRichards, who is now at Charlton, will not play until Dec. 28, 2010 after a striking run of 72 goals grabbed the headlines during the opening of the season.\\n\\n\"At Middlesbrough we are like no other clubs at home - we want good players because they are available. It\\'s a little bit trickier than that,\" Richards said.\\n\\n\"To miss, it is disappointing for (the fans) we are all down in tears (at a move), but happy.\"\\n\\nRichards played three solid seasons at Middlesbrough, where he scored and made the Premier League final four times.\\n\\nRaucous football\\n\\n\"A huge fan base - 200,000! To have a game here in England is incredible.\\n\\n\"It is great to come back back to see that we have done everything we could and been the city\\'s leaders. There is Manchester United wanting to play for us.\\n\\n\"I am very happy to be here, a big club and to have a lot to play - it really helps.\\n\\n\"As many would say, I am sad that he has left. I am not going to see him again. It is the most important thing for me. But it is all about things coming together and my wanting to stay in the team.\"\\n\\nHe returns to the Premier League side on Monday, three months after his big day at Middlesbrough, and he has been impressed with the team\\'s football.\\n\\nOn the sheets: 4 goals in 2013 (Middles FC, Blackburn 1, QPR 1, Richmond 1 –), 0 goals (Burnley 3, Everton 1, Brentford, Bolton 0 –), 0 goals (Manchester Town 3, Colchester 2-0, Barnsley 1, Blackburn, Blackburn 2-0) 3 Goals since December 28, 2010<|endoftext|>']\n",
            "\n",
            "Generating sample 20/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "y\\'re uninsured—and more than half of them will be by 2020, according to a new White House report. And they\\'ve been running Medicaid and Veterans Affairs for many years longer than they\\'re on them.\\n\\nAnd the Republicans are better off. It\\'s the first 10th-year overhaul of the health care system, and it\\'s less than 30 percent below rates in 2009, according to nonpartisan officials surveyed. In 2011, every new year beginning at the end of 2010 grew under the 0.7 per cent Obamacare standard rather than President Obama\\'s 22 per cent and the Romney administration\\'s 14 per cent\\n\\n\"This is worth celebrating,\" said Rep. Mark Meadows, an AHCA supporter who\\'s the House House Committee\\'s ranking member, asked if he would like to see the failed bill originate in the House of Representatives.\\n\\n\"It\\'s not fundamental,\" said Stephen Carella, who has served as vice chairman.\\n\\nBy the evening of Nov. 25, on the House floor, some 300 House GOP members had begun to bring up a process they had hoped would allow a debate by early in the summer.\\n\\nBut there\\'s a substitute for a partisan \"district\" floor, said House Majority Whip Steve Scalise, a Republican, that was put in place to handle the Senate and oversee conversations on the White House lawn and Senate Majority Leader Harry Reid\\'s press conference the day before. The conference committee set up to avoid another partisan delay.\\n\\nReid\\'s bill split from Democrats, and the House bill, from Republican to Democrat, would have passed even after Republican legislation repealing pre-existing conditions without funding Obamacare. And by a procedural vote as late as June, Minority Leader Mitch McConnell, a minority that was the only minority to force the GOP repeal vote and has lost seven leadership jobs, only got a slim two-vote majority from moderate Republican lawmakers.\\n\\nThe vote, which is still very close on Thursday, will see Republicans finally win full control back in the Senate.\\n\\nBut Republicans will have to fight over the votes of House and Senate Republicans and also the rules of the Senate for approval of the bill. The House will still have to vote in the House in a typical year when no Republican has his majority. Both chambers vote separately on a bill with amendments and agree on any amendments.\\n\\n\"It\\'s over,\" said Gene Leckland, a conservative lobbyist who worked with Ryan and McConnell in the fight over the GOP reform package.\\n\\nAdvertisement\\n\\nSpeaker Ryan and Senate Majority Leader Mitch McConnell, meanwhile, leave the Senate floor on May 19, three days before the June 4 recess, as they meet with House GOP lawmakers.\\n\\nA White House official told Reuters on Thursday that it could be four months before the legislation can take effect from the re-imposed August recess.\\n\\n\"It\\'s a little inconvenience, but we know that as we know exactly what has happened in the Washington Room last week, we\\'ll see now that there\\'s a lot of work to be done,\" the official said.<|endoftext|>']\n",
            "\n",
            "Generating sample 21/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "o justify the testimony.\\n\\n“It’s outrageous that the Senate justice committee, even today, has the chairman of the Senate Judiciary Committee say he knows nothing about it, not know that they’ve been taking the same approach with absolutely no evidence by his leadership,” McCain said.\\n\\nBut Warner says the investigation has found no collusion.\\n\\nSen. John McCain, R-Arizona, appeared on MSNBC’s ‘ morning show to take a shot at Chuck Schumer, saying he is “very concerned about threats from on the left today.” (AP)\\n\\nThe White House’s alleged ties to the DNC hack as an excuse used it in late July to was nothing in fact, nor was that intelligence assessment taken seriously. Instead, the White House again appeared unimpressed by the evidence in that investigation, and sought to blame its successor, James Comey.\\n\\n“There has been no allegation of more than routine activity on the part of the FBI. The integrity of the investigation has been compromised,” Warner was asked about whether “nuttles” about the investigation are out of the executive branch. “You need to get on the White House.”\\n\\nSchumer reportedly sat down at the press briefing.\\n\\nThe Post’s Christopher Walken noted there are two questions about Trump’s unfettered investigation into Russia and Russia matters:\\n\\nThe allegation that FBI Director James Comey was in talk to two high-ranking Democrats who said the President “had directed,” even to them, to investigate his contacts with Russia.\\n\\nWhat happened this week is that the Justice Department picked up the e-mails to have the substance of the emails it came across come out.\\n\\nEverything is a crime\\n\\nThe White House insists it has never fished the president’s office by running a ball into the hands of Donald Trump’s attorney general and Obama’s senior adviser. Comey called White House Deputy General Andrew McCabe “contempt” in questioning whether the investigation extended to the White House.\\n\\nWhite House spokesman Sean Spicer has been very clear that the Russia investigation “doesn’t interfere with the administration’s ability to respond to it or not, but to take its course.”\\n\\nSchumer, meanwhile, claimed “any suggestion that there’s any evidence in collusion” by Comey is “not credible.”\\n\\nAnd McCabe, speaking under oath, said the investigation started under Trump when two acting Justice Department lawyers arrived — already John Doval of the Special Counsel, who served as a senior adviser — in the drive to investigate FBI interference in the 2016 election.\\n\\nCited 10 different questions by a reporter from The Daily Beast, they look very bad for a man who seemingly is largely against the news media. Sen. Chuck Grassley, R-Iowa, wants to prove they are Trump-friendly partisan, no matter.\\n\\nBuzzFeed News, which first went through the filings to Warner’s judiciary committee to call for answers, was not able to get 30-minute internet access.\\n\\nThe White House didn’t respond when told this story Thursday morning.<|endoftext|>']\n",
            "\n",
            "Generating sample 22/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "rman, and Trump presidential nominee Bill Maher. When asked if it really was O’Malley that got him interested in seeing Clinton, Maher called him a \"poor guy.”\\n\\nAdvertisement:\\n\\nMark Rosendahl, Clinton presidential communications director, was critical of O’�Malley’s work and his role as counselor to Clinton.\\n\\n“See Martin O’Malley is playing to Hillary,” Rosendahl said Saturday. “He has to talk about her successes, but he will do what he is going to do to get people to like [Clinton]. That’s what she’s done.” He then admitted his over-refreshing work and added, “I understand some of the haters will take a little bit farther, but he would like to do a great job. I’m glad he didn’t make a mistake.” Bernie Sanders, which has both Clinton and O’Malley endorsed Clinton with millions in donations, was equally impressed with O’Malley’s speech of the hour.\\n\\n“This is something that a lot of folks don’t pay a lot of attention to that they should be talking about,” Sanders said. “He is ready to be president. The ideal man to do that is Congress.”\\n\\n“[Progressives are Hollywood]. They campaigned with Paul Begala for years before he would run for the White House,” he ended, noting Barack Obama. “It’s too late, it’s too late for this country.”\\n\\nAdvertisement:\\n\\nVivine van Dominguez said that Trump is making a very political choice. As Democrats and progressives fear Trump’s flaws in his run, “He is going to the other side,” she said.\\n\\nShe continued, “This is Hillary Rodham Clinton’s (RNC) personality of the year because she is absolutely qualified.”\\n\\nSpeaking in Virginia Beach, Del. Rep. Douglas MacArthur vowed not to abandon Clinton’s candidacy, saying, \"I hope President Obama and Hillary Clinton [see who Trump beat in Indiana], endorse Ted Cruz’s rival] in Ohio …— and please don’t allow this to happen in Fairfax County.”\\n\\nLeila Robhtinen, a Democrat and co-chair of the Republican-dominated Congressional Black Political Caucus, was more blunt: “Can we be as close as both on the issue of us before we forget some of the president’s incredible achievements in the improving economy? It’s not enough just to be a secretary of state or to be secretary of state forever.”\\n\\nAdvertisement:\\n\\nAsked about accepting Clinton’s endorsement, the president of the Center for President’s Studies told National Journal, “In George W. Bush, he practically had his head made for the job. I don’t see him making any policy proposals.” “I think Donald Trump is bringing back something to the country through his ideology and personality,” Dean Baker from the AFL-DIO enthused. “I’d rather have George W. Bush than Barack Obama and Hillary here. And we need so much more.”\\n\\nAdvertisement:\\n\\nWATCH: An economics professor about Hillary Clinton\\'s personal style has said he can separate the Clinton Foundation from his personal foundation.\\n\\nFollow Adam Williams at AdamJAWR on Twitter or find him on Facebook. You may also have a tip for the News Alert here.<|endoftext|>']\n",
            "\n",
            "Generating sample 23/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " my daughter today. She cannot get help. She can’t suffer worse than I did here. There is nobody to help the rest of my family. My daughter is only 15 years old. She doesn’t want to let me in because my family got beaten by here. But I have only one left in my family. She has to fight her life back.\\n\\nThese are written in the law, but I know they are true. Any help I can get in the name of these people, I can only help them.\\n\\nNow my parents want to see somebody who is blind. They want to make sure that nobody can feel pain in the field, or pain or distress at all, like here, where the beatings are much more frequent. They want to give me a home, and there is nobody for me to ask to protect my eyes and my mother. But they don’t have a home, and they don’t want me to have one. But I find the room, and they try to give me a room in a village. And if there is a place where nobody has a room, there is a place for them here, they can go.\\n\\nI still worry about the man who brought me home today. There are people who are not willing to help us, because we are here. That’s the sad thing when you see somebody who doesn’t look for a real home. Now, they cannot help themselves. And for many years, I have gone back and forth with the family out of his room. I have been living in his village. My grandfather, he said, is from the village, where he lived for many years. Two years ago, they got married, as soon as they married, you call him your brother. Everyone has been there before.\\n\\nHe always tried to look for a place to live. Now, he’s like this. His house is empty, with no room. My father wants to help the people who come here, but they don’t want to take me a home. But I still worry about my father, because he is here. So when you listen, these poor people are saying for a reason they don’t have a place. They want nothing better than to show up, going to a place where nobody else can see.\\n\\nWhere? We live in trouble. We live in the rest of the human race. We are getting beaten by people. How can they tell me that I am not going to help them here?\\n\\nWhen I came when I was, and I was 14, my wife and I fought one point every day. We spent countless hours. We gave him medicine, that I would give him. I told him that he wouldn’t suffer if you beat him. He took my child for him. Finally, after my son was dead, my wife got married with one son and one daughter.\\n\\nOur son died, and I am going to have him this year. I have a daughter as well. She was a great dreamer. She still suffers here, and I look towards me that way. We are hurt. I want for them to help us again. I am in a situation. I want to come back and fight for them.\\n\\nMy wife and I were willing to come back and fight every day. We were willing to tell people about our struggles, and that it was time for us to fight. But it was time for me to mend my wounds and get out of here. Yes, we need you to help us now. That is how we live.\\n\\nCorrection: GlobalPost Today is a BBC program.<|endoftext|>']\n",
            "\n",
            "Generating sample 24/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "es an advanced age, trying to find out where he was and the next life taken by a strange figure. It was several years ago. The game is enormous, and the characters are clearly human beings. I know who there is in it because it\\'s part of my brain that would seem to make a great product. Sure, it\\'s got the best stuff in yet, but it certainly has some extras I really won\\'t know about.\\n\\nLittle Things, €2. Little Things has always had a punch, punch of a thud. It\\'s full of new things. You can\\'t choose others. But you can at least find your favourite \"name\" – that\\'s a cake. It\\'s a game, about the environment and the gameplay. So, you got your favourite name to choose. You don\\'t have to go to Look around, all you get is where you select the name. Now this may sound like a game you have to throw at your kids, but I picked my favourite of mine because it made me cry and was worth it. As well, this would be a great holiday game as it\\'s so funny and relatable. But you may have to play another game if you want.\\n\\nVandal, €2. You will get a Great Game today, even if only it\\'s online. This is one of those great titles, and it gets exactly the same thing as all the other games. The core element is the same, and the cost is cheaper. In fact, it\\'s getting worse; one day there will be a limited period of \"game\", coming to all big stores.\\n\\nGames, €1. I bought the game and the name is Alan Key. I am a fan, like the game and like almost all the games in it, and I think it looks serious. My brother sent me an email also telling me it was too, and other things will follow. So what games are you going to get? You\\'ve got a great game today, and you got it! But you might actually expect to be a more advanced version of it than the other games. If you\\'ve got a how-to, that\\'s that\\'s going to get you. And as the biggest surprise, you\\'re not going to buy it again. I hope it\\'s free.\\n\\nValerie Island, €7. I\\'m so sure you have a good day. I so much hate to ask me. The price is low however, and the game is fantastic. You can\\'t ask more. You can\\'t say no anymore, and once you reach the next half-million, you\\'ll go spend Christmas with friends for four weeks. But, if you\\'ve already guessed, how to save money by playing (or not). For example, if you don\\'t like, you can still buy the other games. And then that\\'s it – then buy. You\\'re going to buy too.\\n\\nStudio der Mereheid, €2. Another game that I think add up to being an excellent game. But I really do miss, one you should not take lightly. If you\\'ve bought the basic version before, it\\'s actually very nice, because it\\'s the only game that offers you a new level of capabilities. (I own four all over the internet and don\\'t buy). Once you have the upgraded version, you can simply type in on the buy button and start. That\\'s all it is. The cheaper than the cheaper versions, I don\\'t want to buy at all.\\n\\nWatch these for more information\\n\\nI purchased a copy of the second video Review<|endoftext|>']\n",
            "\n",
            "Generating sample 25/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "tract because of the fact that if the landlord doesn\\'t show up, the landlords cannot sell the property.\\n\\nThe rent increases for these taxes for utilities, and therefore the landlord taxes, onto the filers who do show up, they can\\'t replace their tenants. Now, that provides an incentive for larger rental buildings, and much of the labor that the smaller landlords provide to their tenants.\\n\\nThis is one thing that allows us to allow situations in which there are two exceptions to income tax.\\n\\nBut the biggest issue I think is to get involved in levies against paying your rent. If a landlord charges for a tenant that he charges for their transportation, this is one one example of a situation. And I think it does allow for the government to step out and do the right thing.\\n\\nIf you\\'re a rental tax filer, you are covered if your rent is reduced. But it\\'s a very complicated issue. If you do something, you\\'re going to have to pay for it. So you\\'re covered for it.\\n\\nThe problem with that is that if you\\'re operating a very small business, there\\'s a real estate agent who is showing up, he\\'s charged an amount for service. And now that\\'s changes in the net incomes for the employees of the owner, it\\'s an increase in the rent.\\n\\nSo I think what\\'s required is if you see that landlords are still not providing some services to their tenants, that\\'s one more avenue for issue.\\n\\nIn Baltimore, landlords can always provide for you to reduce your rent. If you\\'re struggling with your rental income and you have to bring other things to the table, and you\\'re saying, \\'Hey, you\\'ve had to rent your car mechanic to a guy for five years\\' just to pay him $1,000 in rent, because that\\'s an increased amount of rent, and you\\'re helpless because of that, that\\'s going to be held up in court.\\n\\nI\\'m aware of some others who had to do that.\\n\\nBut the reality is a lot of people feel badly about this kind of issue, because they feel like they should have to be held accountable for service to their tenants and their rental income.\\n\\nWe\\'re also moving towards a common rent floor floor, which means more efficiently we will be able to have a common floor for rent in Maryland.\\n\\nThe combination of the politics and lobbying, the issue of bills being a particular issue for the last day of the Congress, and the issue of legislation trying to change the general rule that applies to utilities and public schools, in general, it is really concerning.\\n\\nThe state of Maryland has had a hundred-year history of... try and create a common floor and floor. It\\'s one of the most powerful reforms, if not reforms of the past.\\n\\nAnd we\\'ll be able to call for hearings and a committee to do that.\\n\\nWe\\'ll call for a \"Portable Rental Association\" to establish the legislation and its name, to be brought to the table and discuss it, let us know just what rent increases in critical services and businesses need to avoid. - Dave Pliata,National Council of Tenants<|endoftext|>']\n",
            "\n",
            "Generating sample 26/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "this is the first step towards getting the problem out into animal models.”\\n\\nThe team has reported on to their findings in the December issue of journal Nature Genetics.<|endoftext|>']\n",
            "Generative perplexity: tensor(31.2301, device='cuda:0')\n",
            "Entropy: tensor(5.0221, device='cuda:0')\n",
            "['<|endoftext|>A new drug may be better able to treat type 2 diabetes, a study at the University College London in England led by the Nobel laureate said.\\n\\nThe chip offers the power to extend or probe red blood cells to boost the level of beta-4 beta, a blood sugar fighter.\\n\\nIn mice, the scientists injected the cell, nitro-5-EP, or called toceptor-10 (PHP), in mice and programmed it to drive a spike in beta. Eventually, they said this activity was restored in five to six mice after the injections, which would normally be triggered if they had a normal immune reaction.\\n\\nThese properties have improved and the brain persists in the skin with the effects that strengthen the immune system over time. However, they say that this is only cosmetic and with little to the potential for serious complications.\\n\\nIt is therefore the first time this technology is tested on mice and the first time that researchers have been able to use a molecule that can test for type 2 diabetes, says Dr. James Riggs of the Harvard University School of Medical Genetics. “Until now, other tests in humans for diabetes or to control for type 2 diabetes have been by placebo”, Riggs says.\\n\\nThe team at the research institute is now working on the HITIS gene, which includes the genetic code for PHP. It says it helps “to prolong beta and early beta production”.\\n\\n“The new technology can now deliver insulin into mice”, says Riggs. “A more broadly-available drug designed to test for type 2 diabetes can be used as well.”\\n\\nScientists use an enzyme called CRISPR, an enzyme that can be easily found in the human genome.\\n\\n“We can test the molecular screen in mice to screen for diabetes” says the report published in Diabetes, the journal of the American Diabetes Association. “We use the same gene code in CRISPR [and other drugs used for diseases such as dementia]. Our cells now help bind the protein, endogenous tissue hormones, molecules or peptides known to impact or control to make a test that works and works for diabetes.”\\n\\nDrug assays that used cells in CRISPR are also being applied to mice. In 2010, Riggs and his colleagues reported that by blocking beta production in both the brain and the lungs of diabetic mice that affected CRISPR, the test has significantly increased the frequency of diabetes treatment in mice.\\n\\n“It is still important to define which parts of genes they are known to act on, and maybe, for example, a few clues about why and which syndrome. But in terms of dosage we don’t make sense yet and this is the first step towards getting the problem out into animal models.”\\n\\nThe team has reported on to their findings in the December issue of journal Nature Genetics.<|endoftext|>']\n",
            "\n",
            "Generating sample 27/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " what are they doing and you live in small buildings in tall buildings or in very small houses. And it all get real and it’s very complicated. You know it’s where I’m going to take photos of them, or I’ll work with them and I’ll get them to make sure they’re finished. So I’m told that everything is handled well and so long as I live in the same house, if I have any kids, it’s safe and we are safe too.\\n\\nWhy don’t you live together in the same house when you both take your days off or nights off? I can hear people telling me I don’t go away. I don’t say, “There are too many people out there, it’s tough.” You can do that if you do the job, or you’re working with a professional or I’m a professional, but I don’t think it’s a problem. I’m doing my job and if I come back, I’ll tell you who you are and who you are and call me when you need me. And it’s very funny because, back in this house, I’ve never taken photos and my photos are made because I feel forced to give back my kids. I do not give myself back. I love my kids and I treat them in this way.\\n\\nWhat do you do wrong? Can you think of something about your photo that ends up getting wrong?\\n\\nCOUSHER HOLT: Not sure what you’re dealing with at my job. This whole 24-hour thing, you know what I’m dealing with, all the time. I get a photograph, I don’t want to see that; I am not sure it’s a photo not a picture. Sometimes, I don’t take this photo, I get a or a picture from somebody so that I can see how it will look and feel. I have done it a few times, because I do not know how I work, you know, I am not working with a professional. I will go and shoot myself, I shoot, everything works out the way. But I do not want to do eight or 10 shots where I try to put together a photograph and then that photograph is taken from another photographer and it is and it will have me and the photographer kind of awkward. And I have been working with this family very well by far this year.\\n\\nIf you think of something without also trying to forget something, along the way, they do not forget you.\\n\\nCOUSHER HOLT: I do not forget my kids, but please remember, here we are. If you don’t know what you do before, please send me a message, and here we are. Because it’s obvious what you do. You know, the media already promoting you and you just work on that at the end and take a photo for the other people out there and all that is good, and then there’s no time to think about it. It’s pretty easy to keep it pretty simple.”\\n\\nCOUSHER HOLT: Thank you very much to you.\\n\\nCatch up and stay here for the latest Holiday Rooting Tutorials.\\n\\n—————\\n\\nHollywoodNews\\n\\nAnja\\n\\nAnja is a lover of photos with a camera and Anja: The Daughter of Happiness from Annie Hoffman on Vimeo.\\n\\nShe and Miss Anja enjoyed a week's holiday seven years ago, and now they're back with these photographs of their relationship making it back to the world.\\n\\nCheck out their fruitful partnership and her whole Anja Live Instagram page.<|endoftext|>\"]\n",
            "\n",
            "Generating sample 28/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "pect for Imam Hussein al-Abu Jamahid, a Shia cleric at the University of Melbourne and part of the mosque in Nasroubi.\\n\\nThe others were gathered in a central square that connected a street, Mr. Farid pointed out, where the violence took place because the street in that area was well neighboured.\\n\\n“When we read someone a message from a young man similar to what Ahmad was in the Koran, we all say that the same message that Ahmad\\'s family and other Iranian citizens read out there, was echoed by Mr. Astrinejad,” he said.\\n\\nSaeed Hosra said he was the first to arrive at the aque address and that even there he was told he would be killed and was waiting at the doorway.\\n\\nHis only complaint in a debate in Sydney last week was a woman who said he was not bothered by a heavy rain. He said people do not like that and was in the mosque because his room was packed with several guests. Among those guests included the Shah of Iran, a figure revered in Islam and described by writers and sagas as being physically unyielding and \"evil and devil.\"\\n\\n\"There was very little hope for it for me. I\\'m just physically weak.\"\\n\\n\"But I probably wanted to see someone alive today, like someone who\\'s never really seen anything, appeared to me,\" Mr. Hosra said. \"It was heartening to watch it.\"\\n\\n\"The police, with huge equipment, looked around and saw what they were all doing,\" he said.\\n\\nAuthorities sent a jury to the mosque\\'s basement to watch as they heard the proceedings. When the jurists were approached and asked questions, they told reporters they did not believe what they heard shouting about was \"Muhammed Ali Nazareth.\"\\n\\nPolice said they received at least 557 reports about a person inside the mosque, saying they did not have evidence of the individual, but nothing was found.\\n\\nHowever, a mosque spokesman said that he had heard suggestions that the crowd was motivated by an inappropriate remark and that the behaviour was directed by a senior officer of the congregation. One of the members, according to witnesses, began writing an account with Mohammed\\'s name in Hebrew, apparently joking. Authorities took no action.\\n\\n\"I think they are Muslims and they have to understand to live here,\" Doug Thramson, who in fact chairs the religion committee, said of the protesters, saying they \"drematised\" members of the ones that were inside the prayer room and then attacking other Muslim groups.\\n\\nGeneral Law Minister and human rights chief, Mahmoud Albani, was set on fire by riot police and has been on treatment for injuries and a life battery at the hands of the police and the protesters. He is being monitored by The Islamic Society of Australia.\\n\\nThere were even students in tears amid a sea of kids.\\n\\n\"I came here to learn about people who had come to the last week,\" said Dr. Ali Shah, a 44-year-old Australian resident, from a small town in Victoria, Australia. \"Everyone is coming here from school to see. Now these things are really important.\"<|endoftext|>']\n",
            "\n",
            "Generating sample 29/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "ry important, and that should encourage all those who support the peaceful creation of self-government.\\n\\nThe best way to suggest that this issue has not been resolved is to say that the lack of recent legislative bills is only delaying the progress of building the legal framework for a legislative government. The good intentions are kept apart by an obscure bill that states that the above non-violent handgun measures, otherwise known as “Virginia Mandated Voter Symbols,” i.e., the same-day immigration law and public transportation law, must be adopted by the Commonwealth of Virginia.\\n\\nThe question has to be: Any reasonable practical reason why these crucial and purposeful legislative proposals have so far not been brought before a future Virginia assembly to properly evaluate their effects and articulate the framework of the legislation?<|endoftext|>']\n",
            "Generative perplexity: tensor(40.9856, device='cuda:0')\n",
            "Entropy: tensor(4.8929, device='cuda:0')\n",
            "['<|endoftext|>by D.\\n\\nIt was my first answer to a question for the letter Dana sends to the head of the Virginia Chapter. The last time in 1993, when I waited for the response from the editor directly, it was Maureen N. * G. * M.R. * Atagania staff attorney, as if I were the response editor. However, above all, I said what I thought I said to the last question a year ago. The question got lots of coverage, and since then I was able to respond. I still struggle with that when I reply. It’s the only way I could write a reply.\\n\\nMost people in the state of Virginia are not more interested in my normal legal practice. But thanks for feeling up enough for me in 1985 to express what I said to the last question. I wrote to the Virginia State Assembly questioning the process of the recent legislation to ask why that process is still being made. I wrote a reply to that letter, sent this out to other legislative leaders and several others.\\n\\nIf the Assembly does not want to answer this question, then we are forced to continue. Ultimately, I will acknowledge that their attempt to form a government with the Assembly, and continues to do so, is probably very important, and that should encourage all those who support the peaceful creation of self-government.\\n\\nThe best way to suggest that this issue has not been resolved is to say that the lack of recent legislative bills is only delaying the progress of building the legal framework for a legislative government. The good intentions are kept apart by an obscure bill that states that the above non-violent handgun measures, otherwise known as “Virginia Mandated Voter Symbols,” i.e., the same-day immigration law and public transportation law, must be adopted by the Commonwealth of Virginia.\\n\\nThe question has to be: Any reasonable practical reason why these crucial and purposeful legislative proposals have so far not been brought before a future Virginia assembly to properly evaluate their effects and articulate the framework of the legislation?<|endoftext|>']\n",
            "\n",
            "Generating sample 30/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ":28,  1.67it/s]\n",
            "  4%|▍         | 10/256 [00:06<02:26,  1.68it/s]\n",
            "  4%|▍         | 11/256 [00:06<02:36,  1.57it/s]\n",
            "  5%|▍         | 12/256 [00:07<02:40,  1.52it/s]\n",
            "  5%|▌         | 13/256 [00:08<02:42,  1.50it/s]\n",
            "  5%|▌         | 14/256 [00:08<02:36,  1.55it/s]\n",
            "  6%|▌         | 15/256 [00:09<02:31,  1.59it/s]\n",
            "  6%|▋         | 16/256 [00:10<02:28,  1.61it/s]\n",
            "  6%|▋         | 16/256 [00:10<02:41,  1.49it/s]\n",
            "\n",
            "Sliding Window Gen PPL:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sliding Window Gen PPL: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
            "Sliding Window Gen PPL: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
            "Text samples: ['<|endoftext|>What the next election will impact on US military operations abroad will mark a departure from prior debates on presidential war strategy.\\n\\n“It will be a shock,” commander-in-chief Donald Trump has said.\\n\\nWith Congress already working on several bills, Trump and his allies plan to reshape military options, opening themselves up to new legislative fights.\\n\\nWith the GOP taking over the federal government, Trump and his allies increasingly pushing for more conventional warfare, it will become clear exactly which they are taking on, especially at the international level.\\n\\n“So it is going to be more difficult to take the war in the more immediate future,” said Ben Greer, deputy director of government and security at the Brookings Institution and a specialist in war and security.\\n\\nUnder a Trump administration proposal, Congress would remove longstanding barriers for taking on hostile states, such as Iran, build up the capabilities of the Navy to strike Cuba, and modernize the military he heads and oversees.\\n\\nHe also said he would focus more on being flexible at the international level.<|endoftext|>']\n",
            "Generative perplexity: tensor(29.6327, device='cuda:0')\n",
            "Entropy: tensor(4.4924, device='cuda:0')\n",
            "['<|endoftext|>What the next election will impact on US military operations abroad will mark a departure from prior debates on presidential war strategy.\\n\\n“It will be a shock,” commander-in-chief Donald Trump has said.\\n\\nWith Congress already working on several bills, Trump and his allies plan to reshape military options, opening themselves up to new legislative fights.\\n\\nWith the GOP taking over the federal government, Trump and his allies increasingly pushing for more conventional warfare, it will become clear exactly which they are taking on, especially at the international level.\\n\\n“So it is going to be more difficult to take the war in the more immediate future,” said Ben Greer, deputy director of government and security at the Brookings Institution and a specialist in war and security.\\n\\nUnder a Trump administration proposal, Congress would remove longstanding barriers for taking on hostile states, such as Iran, build up the capabilities of the Navy to strike Cuba, and modernize the military he heads and oversees.\\n\\nHe also said he would focus more on being flexible at the international level.<|endoftext|>']\n",
            "\n",
            "Generating sample 31/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "\\nThe first inspection is by the University of Wisconsin-Madison\\'s new Lake Superior liver disease laboratory, delivering detailed microscopic imaging of the liver disease body that is poised to create a huge problem. Absent all the science funding and food and supplies for the near future, the researchers said, the laboratory will be a mainstay of the region\\'s \"naval treasure search worldwide.\"\\n\\nIn the same area, the scientists focus on Wisconsin, and local health officials are following up on new developments from the sprawling region, including two liver disease research facilities. The UW researchers are collecting blood samples from these new structures, as well as tissue samples from liver tissue from mice. A team of researchers from the Wisconsin area are also part of an effort led by the University of Wisconsin-Madison to analyze the liver body. \"We\\'re starting to understand what\\'s coming in and coming out,\" said Kevin Metwene, executive director of the lab.\\n\\nMadison and its partners in the UW system say such a new lab not only provides a facility but offers an opportunity to share information on liver disease in areas that are currently intensively tracked.<|endoftext|>']\n",
            "Generative perplexity: tensor(29.3388, device='cuda:0')\n",
            "Entropy: tensor(4.7250, device='cuda:0')\n",
            "['<|endoftext|>The opening of a northern Wisconsin liver disease laboratory makes headlines for a second, but this time the new lab follows a \"turbulent\" cocktail in other areas of an ongoing build-up of disease in the Great Lakes region.\\n\\nThe scientific nation is in the process of visiting the region on this year\\'s annual Famine Day, and experts say there is critical need to understand all signs of disease development and the danger that exists today in the Great Lakes region.\\n\\nThe first inspection is by the University of Wisconsin-Madison\\'s new Lake Superior liver disease laboratory, delivering detailed microscopic imaging of the liver disease body that is poised to create a huge problem. Absent all the science funding and food and supplies for the near future, the researchers said, the laboratory will be a mainstay of the region\\'s \"naval treasure search worldwide.\"\\n\\nIn the same area, the scientists focus on Wisconsin, and local health officials are following up on new developments from the sprawling region, including two liver disease research facilities. The UW researchers are collecting blood samples from these new structures, as well as tissue samples from liver tissue from mice. A team of researchers from the Wisconsin area are also part of an effort led by the University of Wisconsin-Madison to analyze the liver body. \"We\\'re starting to understand what\\'s coming in and coming out,\" said Kevin Metwene, executive director of the lab.\\n\\nMadison and its partners in the UW system say such a new lab not only provides a facility but offers an opportunity to share information on liver disease in areas that are currently intensively tracked.<|endoftext|>']\n",
            "\n",
            "Generating sample 32/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "victions for being involved in heroin.\\n\\nAs the DEA said Monday, the investigation is ongoing.\\n\\nThe agreements were signed by the DEA in New New York and the Northern District of Virginia, and Pennsylvania is the one under its jurisdiction to issue permits\\n\\n\"DEA officials in Pennsylvania, Delaware and the United States will be reviewing individuals identified and dealers examined under their forfeiture agreements,\" the DEA said in a Tuesday statement.\"\\n\\n\"DEA still has policies and procedures in place to make sure dealers or sellers are successful as they proceed and to ensure federal officials are accountable for their actions,\" it added.\\n\\nThe men and women who are sellers of fentanyl were arrested in January 2016, and charged with 16 of the most drug charges in the United States according to the DEA, most recently in possession of fentanyl-related substances. Some of this, in the form of synthetic opioids that are similar to heroin, fentanyl and pot.\\n\\nThe DEA identified fentanyl as a controlled substance in 2014, making it one of the largest drugs in the world. Italy exported half of it in 2015, but in larger quantities with known toxicity. China and other countries know fentanyl is an effective drug for manufacturing and distributing heroin fentanyl.\\n\\nThe DEA undercover program comes from Ohio.\\n\\nThree men, native of Northeast Ohio, were charged with the interstate distribution of fentanyl and a firearm by a law-enforcement officer. Police are looking into charges related to the heroin trade.\\n\\nTwo years ago, she was arrested in Delaware for selling heroin-related substances at a Joe\\'s pot shop with customers in Delaware State.\\n\\nThe pair allegedly sold small amounts of fentanyl back to dealers. The dealer told police that upon entering Delaware, he thought that he would find out more. Instead, the dealers lost nearly a significant amount of heroin.\\n\\nA scene captured in a dashboard video shows one of the suspects driving back to the pot shop. They held a large amount in a black bag for two hours before transporting the remaining amount back to the shop.\\n\\nThe two pleaded guilty to each charge. The two are expected to appear in federal court on April 25. Just last year, an armed robbery charge involving multiple heroin products followed for connection to the drug trafficking. That trial is scheduled to take place on March 7.\\n\\nThat said, the feds are not cooperating with federal prosecutors in the case. The U.S. Attorney\\'s office indicated that the men are not to be named in the ongoing investigation. DEA officers and the DEA declined to comment on the ongoing investigation or its specific nature.\\n\\nA spokesperson for the DEA, which tracks undercover operations on its website, did not give more specific details.\\n\\nA spokesperson for the DEA office in Columbus, Ohio was not responding to questions.\\n\\nGraphic from Tareil Pirro on the Wall Street Journal, which tweeted a day after it issued the announcement.<|endoftext|>']\n",
            "\n",
            "Generating sample 33/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "ge questions remain. Hawking’s predictions took him out of sight of humanity. It is the Hawking projects that I have carried out trying to prove his existence and I am still keen to announce what I can think of and will possibly try. I also set up an interview with someone named Professor Donald J. Hayek, who is U.S major in chemistry and physics. As what he has so far shown us, he is still spending more time investigating the impact of God on humanity.\\n\\nI’ve also contacted Hawking on whether he has contacted Prof. Hayek with any information about what the quest would entail. I have gone all pew pew and provided him with some sort of update. If that is how I will go it, well. This could be revealed sometime tomorrow.\\n\\nAlso the following interview was from Dr. Albert Swenhall, a member of NASA’s Ancient Energy Research section of the ISS Alliance.<|endoftext|>']\n",
            "Generative perplexity: tensor(45.1611, device='cuda:0')\n",
            "Entropy: tensor(4.9632, device='cuda:0')\n",
            "['<|endoftext|>Eager to provide the Universe with proof of God’s existence, Stephen Hawking is investigating an influential scientist at the University of Los Angeles in his attempt to research his beliefs.\\n\\nHawking has been researching the Universe since he started the university in 2007 investigating the effects of cosmic forces on the being, self and the soul. Long viewed as the greatest achievement by a metaphysics physicist, Hawking has conducted a substantial amount of experiments making long-term predictions such that he has developed the technical ability to prove the existence of God at which point quantum theory becomes practical. Given the physical complexity of the Universe such a massive new idea would require, just how intelligently anyone can carry out that was necessary. Hawking would then have to build a network of failure.\\n\\nUnfortunately, although Hawking’s attempts to disprove the Universe have all been successful without any answers and no simulations are the last big questions remaining as of 2011. It was only in 2013 that his research began, and as humans began to leave the Universe in size and speed large questions remain. Hawking’s predictions took him out of sight of humanity. It is the Hawking projects that I have carried out trying to prove his existence and I am still keen to announce what I can think of and will possibly try. I also set up an interview with someone named Professor Donald J. Hayek, who is U.S major in chemistry and physics. As what he has so far shown us, he is still spending more time investigating the impact of God on humanity.\\n\\nI’ve also contacted Hawking on whether he has contacted Prof. Hayek with any information about what the quest would entail. I have gone all pew pew and provided him with some sort of update. If that is how I will go it, well. This could be revealed sometime tomorrow.\\n\\nAlso the following interview was from Dr. Albert Swenhall, a member of NASA’s Ancient Energy Research section of the ISS Alliance.<|endoftext|>']\n",
            "\n",
            "Generating sample 34/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "n to the Toronto Area have received increases in their wholesale food prices, with the nearest major city, Goa, seeing a spike in its prices, according to Banks. All those regions have good production in the region. That is changing with population growing enough to millage out to the north, and with jobs lost in those to Ontario. \"A lot of eastern Ontario, like in Niagara and Erypharrie, is a country south of what Canada has become,” Banks said. Tim Wargar, general manager of milk operations in the Niagara region, said the forecast is not an accurate picture. “The high prices up north are causing the death of the millage farm,\" he said. Wargar, who said wages are falling in the upper regions of the agricultural chain, said consumers are having bigger problems. \"On the one hand is the sweet and condensed water prices, and on the other hand is very low grain prices. I can’t think of a more painful situation on either,” he said.Industrial sector executives are also dealing with ever-rising debt and cost pressures. In a report released Wednesday, the Bank of Canada Industrial and Commercial Board (ARI) said that many companies in Ontario have increased operating costs by more than 10 per cent between 2011 and 2016, and have cut output and wage increases across the province. And there have been many big pay increases and shedding jobs, even in places such as the Athabasca Valley.\\n\\n“But the big challenge will be how things are reconciled with the economies that are weakening,” AR wrote in an August 2016 survey for the ONS. “There is also the deterioration in the jobs picture in general.” Kitco Inc., the company putting out the recent survey for the ONS, said that higher production costs are also leading to both higher salaries and lower wages. In Alberta, the province that follows the U.S. and Saskatchewan, said the company released the report. It said both it has hired more than 40 new jobs and has created another 25. Since its publication, 175 were employees there, and there are indications that more may be hired soon. Some 3,000 hired jobs are direct-pay or part-time positions, but close to 600 to 1,000 more are full-time positions. Companies worry that job opportunities will soon shrink as the economy slows or slows. “More and more people will have to find jobs that pay them less, which is very different right across the country,” when based in a low-wage region, said Bob Clavey, a production consultant who consults Wargar. “More and more you’re going to see more people drop out.”\\n\\nSignup to receive a daily newsletter Please send a tip on your email or call us at 1-800-866-7453. Delivery: Thurs. Invalid email address Thank you! You\\'re almost signed up for Breaking News Keep an eye out for an email to confirm your newsletter registration. More newsletters\\n\\nLocation: Focus during your Region Select Area Your map Your Region Select Your Region map Where are you from? Where What region did you come from? Click here for full map.<|endoftext|>']\n",
            "\n",
            "Generating sample 35/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "facing charges for murder and cocaine possession, but not for drug possession. His will has been waived.\\n\\n\\u200b Actress nominee Meryl Streep has been receiving unwelcome publicity this year for her Oscars. She has publicly teased the possibility of a documentary on Polanski ever appearing in Hollywood because she was in the early 1980s and has been nominated. This news isn’t about the Academy problem. Her upcoming movie is being seen as respectable, even though Polanski was denied his Oscar.\\n\\nTrey Williams will have time soon after having been the subject of three months of silence in Hollywood.\\n\\nRoman Polanski doesn’t deserve any, nor does he deserve any. Also, despite the Oscars he wins, he doesn’t deserve any, nor he deserves any, should anybody be denied his Oscar. Nobody is allowed to go to see his movies, and possibly me and the Oscars he deserved.\\n\\nRoman Polanski has been threatening murder when his rights were in the process. At this point, I don’t have proof that Polanski ever threatened anyone. He doesn’t deserve to look at his hours. In fact, I don’t think anything like that would happen in his world now. Roman Polanski doesn’t deserve millions on millions of dollars. When you do that to a person, he has nothing earned in his life.\\n\\nPolanski was shot in July 1977, was numerous times injured by the police, and died of AIDS. At 33 years old, it was the golden age of the killer in Hollywood, when murders were being committed in the entertainment industry. I was with him all through the trouble that he was in. He still has a lot of good doing in Hollywood, and it’s unfair to him for him to lose his Oscar. Polanski himself caused a lot of controversy with his allegations about him.\\n\\nRoman Polanski was Best Actor-winning for 25 years. So, would he be at serious risk of losing the Oscars for not publicly supporting him? That’s absurd.\\n\\nRoman Polanski is constantly harassed, including on Instagram. It has taken several months to begin defending Polanski from harassment, and the attacks to prove that he’s getting blackmailed.\\n\\nSo, there is more money in Hollywood than just any human rights. It takes an acclaimed actor to be nominated for that money to be allowed to the Academy Awards to take it, or else only to get attacked and harassed again. Polanski wants the Oscar he is right to win. Polanski deserves it, because he is the best man. That makes a guy that wants to win a lot more money, but his problem is a guy who is allowed to have money to continuously get harassed, and repeatedly gets harassed. It is too late for the Roman Polanski Academy to stop.\\n\\nThis is why Roman Polanski is taking his Oscar without losing a fight, he is just trying and fighting, and giving it over. Critics have stepped up their efforts to try to get Polanski, and no one knows what his success will lead to, but if Polanski thinks he can win this award and continue to get away with it, then that makes Polanski worthy of his own Oscar.<|endoftext|>']\n",
            "\n",
            "Generating sample 36/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "face/modules/transformers_modules/kuleshov-group/bd3lm-owt-block_size16/70129eacd09fe73158c81e46e9f4041d1c521ef6/modeling_bd3lm.py:355: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "\n",
            "  0%|          | 1/256 [00:00<03:43,  1.14it/s]\n",
            "  1%|          | 2/256 [00:01<03:04,  1.38it/s]\n",
            "  1%|          | 3/256 [00:02<02:48,  1.50it/s]\n",
            "  2%|▏         | 4/256 [00:02<02:44,  1.53it/s]\n",
            "  2%|▏         | 5/256 [00:03<02:50,  1.47it/s]\n",
            "  2%|▏         | 6/256 [00:04<02:51,  1.46it/s]\n",
            "  3%|▎         | 7/256 [00:04<02:51,  1.45it/s]\n",
            "  3%|▎         | 8/256 [00:05<02:44,  1.50it/s]\n",
            "  4%|▎         | 9/256 [00:06<02:38,  1.56it/s]\n",
            "  4%|▍         | 10/256 [00:06<02:34,  1.59it/s]\n",
            "  4%|▍         | 11/256 [00:07<02:31,  1.62it/s]\n",
            "  5%|▍         | 12/256 [00:07<02:29,  1.63it/s]\n",
            "  5%|▌         | 13/256 [00:08<02:28,  1.64it/s]\n",
            "  5%|▌         | 14/256 [00:09<02:26,  1.65it/s]\n",
            "  6%|▌         | 15/256 [00:09<02:26,  1.64it/s]\n",
            "  6%|▋         | 16/256 [00:10<02:25,  1.65it/s]\n",
            "  6%|▋         | 16/256 [00:10<02:43,  1.47it/s]\n",
            "\n",
            "Sliding Window Gen PPL:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sliding Window Gen PPL: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
            "Sliding Window Gen PPL: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
            "Text samples: ['<|endoftext|>Shoshie A.K: No, not directly affected by events [P.S.: The information in the AP analysis referenced above was not used and is intended to be only presented as an opinion of a quote from Chaka, a friend.]\\n\\nKiri, Travis (Kris) BuzzDrunk Dog (comments), Hushweight SuperFight (AFGH on news), 7 Comments, Aggressive perspective, t.k.a: culture, 3600 words, go out, fight, DETAIL OVERVIEW 1\\n\\nCredits\\n\\nKiri, Travis (Kris) Rewind: Love (Vocal), NXN, XXXX, Lady Murmur, Big Cartoons (via Twitter), Hasbro\\n\\nMappaKiri, Travis (Kris) Olayem Horse (Twitter), Crouch Boy (+Warning, Tweet), T:Jax:Facebook); Profile (Isukido), Lishunky\\n\\nClick on your favourite websites and feel free to connect with me and follow me on your favourite social media.<|endoftext|>']\n",
            "Generative perplexity: tensor(122.7787, device='cuda:0')\n",
            "Entropy: tensor(4.6535, device='cuda:0')\n",
            "['<|endoftext|>Shoshie A.K: No, not directly affected by events [P.S.: The information in the AP analysis referenced above was not used and is intended to be only presented as an opinion of a quote from Chaka, a friend.]\\n\\nKiri, Travis (Kris) BuzzDrunk Dog (comments), Hushweight SuperFight (AFGH on news), 7 Comments, Aggressive perspective, t.k.a: culture, 3600 words, go out, fight, DETAIL OVERVIEW 1\\n\\nCredits\\n\\nKiri, Travis (Kris) Rewind: Love (Vocal), NXN, XXXX, Lady Murmur, Big Cartoons (via Twitter), Hasbro\\n\\nMappaKiri, Travis (Kris) Olayem Horse (Twitter), Crouch Boy (+Warning, Tweet), T:Jax:Facebook); Profile (Isukido), Lishunky\\n\\nClick on your favourite websites and feel free to connect with me and follow me on your favourite social media.<|endoftext|>']\n",
            "\n",
            "Generating sample 37/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " from a special advisor, appointed doctors to visit him all through the day and at lunch time to stay away from his golf-attacking in Gujarat.\\n\\nSuddenly politics became an aspect of PM’s relationship. A period of obsessive politics has now caught the PM’s guard and he will have to fight hard for ever for his ability to follow through. At the time he realised he wasn’t going to do it simply because Modi might be good enough to do it but the PM was decided to stick arm-in-alarm as Minister of All India.\\n\\nMore from The Indian Express\\n\\nWatch: Read on how the PM’s doubles down on Sri Sri Santosh Dikshit today\\n\\nWhy he should keep it as PM: Why Kumar and Raje are creating a ‘natural match’<|endoftext|>']\n",
            "Generative perplexity: tensor(69.8092, device='cuda:0')\n",
            "Entropy: tensor(5.1626, device='cuda:0')\n",
            "['<|endoftext|>Prime Minister Narendra Modi resigned his RSS close friend Deepak Kumar this weekend and distanced himself against the India Today. In addition, the BJP leader vowed to aggressively defend him in the Patna case.\\n\\nThis party-intimidatement was built on rumours and false calls in the case – the anti-beaver drug plant kratom is not the only part of the trial process. Now, the case faces its own court because, unfortunately, Prime Minister Narendra Modi has little substance of his own to indulge in disinformation. In fact, Kumar and his men did see some trouble in 2010 when the CM secretary of a coalition government, then, Pranab Muktesherjee.\\n\\nA Hazare Day agitation, thousands of protestors arrived that day and when Modi announced a spiritual guru was serving as the Ministerial Advisor, then the CM removed him because he was allegedly brought in as a matter of conscience. The Congress showed its strong suit by making a point known that a doctor was not in India for Modi.\\n\\nLater, Modi himself returned to the Lok Sabha as ruled by his Rathore and the only Ministry of doctors headed by scientists who “tried the worst” for patients. In severe cases, medicine still claimed that Modi was no sick Modi.\\n\\nAdvertising\\n\\npost\\n\\nBut doctors in every state of Karn, prior to his appointment, had to have a hard time as they often were unable to access either Akarlal Bhavan or his hospital rooms. Even then, the ministry of health, with support from a special advisor, appointed doctors to visit him all through the day and at lunch time to stay away from his golf-attacking in Gujarat.\\n\\nSuddenly politics became an aspect of PM’s relationship. A period of obsessive politics has now caught the PM’s guard and he will have to fight hard for ever for his ability to follow through. At the time he realised he wasn’t going to do it simply because Modi might be good enough to do it but the PM was decided to stick arm-in-alarm as Minister of All India.\\n\\nMore from The Indian Express\\n\\nWatch: Read on how the PM’s doubles down on Sri Sri Santosh Dikshit today\\n\\nWhy he should keep it as PM: Why Kumar and Raje are creating a ‘natural match’<|endoftext|>']\n",
            "\n",
            "Generating sample 38/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " solidify what you want. We need the forces we need to get to that end, and not only to change in policy for both parties. We need the people who grew up in the 1970s, who spent years writing about the economy, and who’ve found the disillusionment with what’s good for America is hopelessly cynical, and that there is no chance of winning in the long run.\\n\\nFor example, you will remember that the left’s right-wing advocacy group is in the process of creating a nonprofit news branch, known as liberal.org. We have a long history of independent advocacy organizations, political advocacy organizations, and think of groups. We’ve been anti-war groups. But it’s not about individual activists who just got $250,000 support. We all know the meaning of that name. But one has to realize that this left is not going to generate revenue by that effort. And that they just can’t base millions on the movement itself. It’s a shame they are wasting even more money on that. The fact that this is a big cause that for me, although not radical or progressive, is all the rage for this very moment also indicative of how far we are, that’s a sign that we’re not yet.\\n\\nAnd it shouldn’t be that far this time.\\n\\nBut this left is not going to change America, because it shouldn’t even change this place where we’ve been for 25 years. It just has to bring in politics a change that the public looks on to — and accept, because of the change in the name.\\n\\nThe difference with the left and the left is that most people want what they want. They come to meetings with some of our organizations. They listen to some of our organizations, and some of our organizations. And they realize that they’re heard, and that we’re heard by everyone.\\n\\nBut for many people it just isn’t. It needs a change. It should be a new way, not an old way, to break the old, to get there.\\n\\nAnd I think that we has a new way now, of hope and fear. We need ideas and people. We need people like myself. I think a lot of people this election season have had a chance for things to get the change they want, because of how many people have been so far.\\n\\nThis is a chance again, for many people, for a lot of people to bring the change they want and be heard, and that they hope is best for when people are that powerful, and that when you get beyond the rich and the big, people can make real bonds that are unbreakable. And that’s an enormous thing. It’s important.\\n\\nAnd that’s why you will be welcomed into an evening of opinion in Washington tonight.\\n\\nIf we win, we will not be the same thing we’ve been for two decades.\\n\\nThis discussion is being moderated by Jo-Ann Guldenfon.\\n\\nAlso in this space, the newly formed Republican Project is writing an article here, and a talk at the Cato Institute is happening tomorrow about what we need to do to fight back against Trump's presidency. You can also hear the podcast interview here. It's uploaded on iTunes. Listen to the podcast at blogDComics.com/liberty.<|endoftext|>\"]\n",
            "\n",
            "Generating sample 39/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "rrently at $317,000 for Trump versus $153,000 for Bill Clinton. “And by the way, for president, you won’t have to skimp on your first presidential year to a lot more than previous presidents had in their first as president.”\\n\\nDan Sullivan / President Information He himself wrote a biography of Trump, one for Congress, for the President. And he’s “totally nostalgic for the president-elect. And all Mr. Trump has done very, very, very well is make you have a problem when it comes to you.”\\n\\nMichael Reynolds / AP\\n\\nA pop band banding together at AP’s headquarters in Washington bears the band’s name. They often react to a concert in less than 10 minutes. The Beatles performed “I Will Rock You” in concert in 1971 for a hit ballad that never emerged as a studio hit. Jon Tatum, the bassist and chief executive of the group, had time to make “things sound that good and so good and take care of the right things.” It took him a million years on earth to make those songs a hit.\\n\\nLiz Welch / Getty Images\\n\\nWhat happened to Europe, Trump’s supposed love for that country? A president-elect spokesperson says that Twitter said he tweeted too many “ages of Melania Trump’s family, and went ‘alt mic.’” Given Trump’s trade practices and knowledge of the international system, it means a great deal that this isn’t because he tweets too frequently. Given his approach to diplomacy, it’s also quite possible that he didn’t retweet policies that the entire United States has opposed, or doesn’t like as much, but know how he handled it.\\n\\nTrump was on the Senate floor during an interview with ABC’s Diane Sawyer last Tuesday when she discussed the likely Senate nominee — so perhaps she asked a little more about Trump’s conflicts with the pharmaceutical companies who will be paying for services to the nominee. She then spoke about something she told Sawyer afterward — that Trump apparently wanted to build hype around lobbying to keep his signature health care bill intact — and then said, “Look, Susan Collins and M&&M are owned by hospitals, so it’s not a side line.”\\n\\nAccording to The Washington Post, she suggested that some of the additional $1 million a Trump would donate to companies that do work there could play a significant role in shifting Trump’s opposition to the ACA. “Will there be a change in the aid from the private sector that Hillary Clinton and her campaign included in the ACA? As you might expect, Trump played along and his campaign said he’d help pay his own companies more money than they were paying them,” she told the New York Times. “What Hillary Clinton said there does have to be a little private sector support in there just to get the health care bill in its current form, particularly because the tax on health insurance companies has much more to grow as a result of the tax credit that she put in there.\\n\\n“I do think that they were making a huge error by what Congress was doing in the legislative proposal.”\\n\\nVia Associated Press.<|endoftext|>']\n",
            "\n",
            "Generating sample 40/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " currency they’re going to be buying?\\n\\nSo, what kind of decisions can we make and maybe make it even more important that we understand what we’re taking in with our money overseas, what we should be taking back, who is the greatest risk to them, who’s most vulnerable, who are the really popular guys, why is it there?\\n\\nI would think of a very simple answer to these choices. We should continue to allow them to come in. There’s more easy money for us to borrow, and we should continue to use our power to so that we can turn that around over time, in a way that we haven’t been able to. It’s a good problem that nothing in the country have ever brought on.\\n\\nAnd it’s a good problem that other countries have to continue to confront. If they don’t come in, if they don’t start up early on, if they don’t have the international agreements that we have been able to have, that we’re helping them, they can get lost. So, from my point of view international system, is in no question the risk that they would be coming back and playing a part in transforming it. And yes, I think this is a problem that we have to come together from the problems, a general problem that it’s very hard to solve with Brexit.\\n\\nCHAIRMAN:\\n\\nYou say that you agree with British voters that it’s a very bad thing to have an early European exit. Can you sum that up.\\n\\nFRESSE:\\n\\nI think we’ve got a very good job to do on this. I’d say that this is something that I’m most interested in resolving. It’s actually worthwhile to discuss this, to do research on the issue, and to suggest that other countries have to do something, if that sort of transition is not coming in and continuing to work hard.\\n\\nYou try and reassure the voters that this matters? Can you explain why this had a more decisive and positive effect than Brexit?\\n\\nFRESSE:\\n\\nI think that two absolutely big things for a lot of people, particularly the people in the UK we’re talking about, the country’s biggest asset, was the economic governance that was provided by our leaders. And they had a big impact on Britain as well. I think that one of the lessons and more importantly, the lesson I think, is that the people of the United Kingdom had to make their own decisions, they had to make their own decisions. And I think that in some cases, as David Cameron was doing, I don’t think, was perfectly understandable that this happened just because people in the UK Government took money from it. I think it was actually a case of people making themselves to not be involved.\\n\\nAMY GOODMAN: Well, Dr. Suzanne Edmond, global health ambassador, is with us. I’ll have to talk with her as we move into this conversation. In London, Suzanne Edmond is the former executive director of Health England and medical education at the Undersecretary of Health and Social Care and is a professor from West Ham University for Economics and Politics. We’re joining her right now. Thank you for joining us on the Voices of the New World Service.<|endoftext|>']\n",
            "\n",
            "Generating sample 41/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "est. He has an Alaska, Arizona, Oregon, Virginia and Colorado convictions.\\n\\nKristina was also being held on $100,000 bail and had been held in Santa Monica Jail for about five years, which according to a report from 12ABC, is when he was staying in the same homes with his grandmother and an ex-girlfriend, Lee Willis Jr., according to police.\\n\\nBoth the cases took place a short distance from each other. Kristina and her sister, Jane Collins, are in the two very different houses. They were quite well together before they left for Cleveland, where Morales\\' accomplice lived. Up until now, Kristina was not arrested.\\n\\nThe abuse and violence that occurred in the days prior with Morales in custody has only been revealed by the photos taken by Kristina on Aug. 27 by Morales\\' attorney. In the photo taken at the scene, the 14-year old Melissa was standing out from the same window as a \"suspect\" surrounded by Morales holding a baby on the phone, and holding her down. In other words, there is a scene and child with pepper spray on Morales.\\n\\nMelissa was still inside the home where one of the infant daughters was murdered while Morales was present.\\n\\n12ABC reported that \"Cleveland police say Morales also struck Melissa while he was driving; police say the girl escaped being attacked by Morales. Melissa turned away from Morales in Morales\\'s cruiser\" on Aug. 29.\\n\\nThey placed Morales in custody after his arrest, and on Aug. 29, Morales fled.\\n\\n\"But police said a person broke through the front doors of multiple Cleveland businesses that same day as Morales and his family fled. The break occurred inside a three-story building at the corner at 60th and Cantina,\" the ABC reported.\\n\\nMorales had been recognized by the police when he was detained several hours later.\\n\\nAt this time, there is no official word at this time. But as well as the man who registered as Morales, it appears Morales may also be fighting a child with his wife.\\n\\nTo date, there has been tremendous outrage among the Const. (who Morales is pregnant) talked about being pregnant, just because \"the baby is already inoperable.\"\\n\\nIn the first case, the rape of a baby took place because Morales himself had custody. Morales accused Morales of kidnapping the baby and \"being lice, but they were not. The police were walking around Mr. (Baby) Morales, coming home, and had them told them this guy has \\'baby.\\' He looks like he\\'s there, but he was arrested on the second day of arrest.\"\\n\\nIn theory, that means at least Morales may not care.\\n\\nHe is the guy who witnesses in this case say it\\'s thought their daughters were murdered and that they had the baby break into Morales\\' hands while together with Morales in custody. Are they ashamed of him?\\n\\nAnd how are they going to spin this story? This appears to be a a one win case because Morales is also a one win case.\\n\\nHe is a violent man who is innocent, leaving a child alone. If there was a need for a father, there was this.<|endoftext|>']\n",
            "\n",
            "Generating sample 42/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "about my family, and I don’t know what I want to see. It’s overwhelming. But considering his other kids and wife, he has to wonder what a separation will be like.\\n\\nThis would suggest that the first reasonable conclusion about why Kraft feels obligated to marry someone is that it isn\\'t just because he thinks about love. It\\'s also because he thinks it\\'s wrong. And if he is born gay, he says, then he will realize that he either welcomes it and accepts it or face the truth too. Because Jonathan Kraft is a gay man, too.<|endoftext|>']\n",
            "Generative perplexity: tensor(23.0227, device='cuda:0')\n",
            "Entropy: tensor(5.0092, device='cuda:0')\n",
            "['<|endoftext|>Brock Leiley/WQMI\\n\\nAfter years of being one of the most hated men in the country, Jonathan Kraft is preparing to stop making plans to wed his girlfriend.\\n\\nThe 43-year-old football player says in an interview with TMZ that he plans to part ways with his girlfriend, which means same sex marriage is legal in the northern region of the United States.\\n\\n\"My mother was a really sweet white guy, and she\\'s part of a really bourgeois family,\" says Kraft. \"And my sister was a jerk, so she was not like this. My wife is also really like this girl, but is not gay at all.\"\\n\\nAccording to the TMZ that spoke with Kraft from LifeZette, Kraft is not at all different from the married person.\\n\\nKraft is married to Susan, 62, and first dates his girlfriend a few years ago in London, and were engaged in a previous year party in New York.\\n\\n\"I want to try to be like married,\" Kraft says. \"Now, I don\\'t assume you\\'re so sure, but I don\\'t have any doubts really. There are some rumors that come out about what the motivation was to break with me and that she was sending my messages to Facebook to prove me wrong.\"\\n\\nBut if this is true, Kraft is probably the one who might get into writing that he is turning himself into a lesbian.\\n\\nSeriously, if it has anything to do with a gay-themed holiday, some of Kraft\\'s answers don\\'t matter.\\n\\nAdvertisement\\n\\nMy husband and I loved and had much fun with our new houseman. I was disappointed that I wouldn\\'t be with him, so we said, ‘Are you going to love him too? I still see him as a great mom, and he’s happy,\\'” Kraft says.\\n\\nI loved that, so he said \"Yeah, and yeah, that\\'s a fun fact, but the good news, is that he\\'s happy to have us again. He loves him enough to keep us company a lot.\"\\n\\nI think that works for him. I don’t know how he feels about my family, and I don’t know what I want to see. It’s overwhelming. But considering his other kids and wife, he has to wonder what a separation will be like.\\n\\nThis would suggest that the first reasonable conclusion about why Kraft feels obligated to marry someone is that it isn\\'t just because he thinks about love. It\\'s also because he thinks it\\'s wrong. And if he is born gay, he says, then he will realize that he either welcomes it and accepts it or face the truth too. Because Jonathan Kraft is a gay man, too.<|endoftext|>']\n",
            "\n",
            "Generating sample 43/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "l in Portland, Ore., Thursday after it collided with other vehicles about a mile from it, narrowly missing the trucks. A total of 11 vehicles crashed and seven people were injured, another official said. The station is up for a tanker load and eight an oil tanker load.\\n\\nMeanwhile, about 1,500 people were stranded on shore, and the coastguard Agency sent out emergency communications on a lifeboat in Moffett, 30 miles north of Tampa. The boat would be evacuated, unloaded and taken to another station with the help of an evacuation crew. The agency's emergency service will then start the rescue, which Gov. Rick Scott said is as basic and necessary.\\n\\nA major source of flow of oil in the gulf has come from the Gulf of off the Gulf of Mexico and into the Caribbean Sea as part of the seal of well off the coast of Jamaica. BP spent about $4 billion drilling the carbon-dredge well for two months. BP operates about 80 wells on the Atlantic Gulf Coast, which extends into the oil field along the Gulf of Mexico.\\n\\nBP said that deepwater conditions are OK, though there is a rupture near a wellhead in the UK, and an explosion in an offshore processing facility, where the plume and human activity that began is currently investigating. It has had no connection to the oil spill.\\n\\nAt least seven oil refineries have been damaged in the spill. Meanwhile, U.S. Coast Guard have stopped the Atlantic Blackwater oil rig, and clean-up crews are still working on the frackers. BP's cleanup unit assessed a swathe of oil and passed the test results to the group.\\n\\nA major source of oil is on the Gulf States Coast, where 175,000 barrels of oil has been released since Friday. Oil from Mexico began flowing more than a million miles from the U.S. coast to California.\\n\\nBP said Friday that workers were preparing to break up the spill defer it for the weekend. It says the oil spill continues far into the week, but the workers are still continuing their work.\\n\\nAt the center of the spill in the Gulf: Energy refineries and metallurgical facilities, like the place where oil from the Deepwater Horizon spilled into the surrounding bay. BP says that access to any oilfields, garages or other refineries will be blocked on Friday.\\n\\nBy Monday, about 11.2 million of crude oil was released. That's eight million barrels BP's data from Friday says 11 million barrels of liquid oil was released. BP says that number will reach a release peak by the weekend as the spill is contained.\\n\\nBP has estimated the depth of the oil spill and the distance that it will be seen on Friday. That area is about two times the maximum depth from the well, according to the American Oil Risk Center, monitoring BP.\\n\\nIt is not clear how or how much oil will be released were the cleanup crew able to recover the oil at the same time.\\n\\nShortly after the spill started, some people in the area were beginning to feel it was spreading. They were warned that they will be away next week to evacuate.<|endoftext|>\"]\n",
            "\n",
            "Generating sample 44/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "uda:0')\n",
            "[\"<|endoftext|>Crazy, an aging sound engineer who does all the calculations and makes your USB drive sure you will be steamrolled into buying a self-driving Apple TV set.\\n\\nCrazy, who is speaking his man by sneezing and can't get off of his wacko to play The National Anthem while snuggling through a mirror, runs Crazy’s lab.\\n\\nListen people always feel like an abrasive bunch about how they’re doing it for the people, not everybody else. His alarm clocks sounded like Donald Trump died last night, and a lyric from Coca-Cola to a song in between puts your coffee out of the playing of Cookie Monster just like people do.\\n\\n(More on the Gadget: HERE)\\n\\nCrazy Crazy? What does he really do? Not much. He’s going to be listening to his memory loss doctors and hanging out with his wife Dr. Mark Dow, engineers and friends. He turns to the superlative Big Dumbbell to share his crazy skills and tips for our meetings on the Brain.\\n\\nThere’s also internet-savvy hacker Jonathan Lacks and robotic humorist, Joe Notara, and the Crazy lab to complete the crazy package.\\n\\nWouldn’t surprise me if Crazy could have some freakin’ Lego sets thrown into the picture.\\n\\nMake sure it’s got some crazy fun, isn’t it? How cool! It’s been almost 2 months since he took our call. We have now a few points about the conversation that aren’t true.\\n\\nFirst, we got to hear some dialogue of random guests that coupled with his anecdotes about the stunts and the live performances of these weird radio shows.\\n\\nI love hearing about yet another experiment, and I thought we had some cool ideas for a Weird TV Outlet! We have four little amazing shows that we can play with their red walls for a place party. We should try to talk about making cat videos and talking about that Pokemon game experimenting with wacky over-the-top Pokemon Digital Shapes.\\n\\nMaybe we could even play Doctor Who and talk about a H.T. McCoy. Or even Batman. Any time we ever see a real concept of an extraterrestrial version of Batman doing crazy stunts, he has to come up with the weirdest stunt.\\n\\nWe don’t know about you right now, and even crazy. We aren’t out of control.\\n\\nI was hoping to see this crazy for the first time and the guy was willing to listen. He also did some a lot of cool stuff.\\n\\nSecond, we got to hear some secret recordings of The Warywolves and A.J. Winslow, who wanted to take over a house that he thought was Kalek and use it as his headquarters. He thought we should hunt him down for a fight with the police. We’re told he freaked himself because he wanted to be fighting the cops.\\n\\nIt’s a good mix of love and hard science.\\n\\nCrazy has his local high school guy as a writer, and a sports fan in their dorm. We got to sleep in the house last night, though because of something short of sleep pressures, he left over several CDs to dance on at the music lounge. I know a lot of work will have to be done.\\n\\nMany people out tonight than we said before.\\n\\nHappy Funhousebers!<|endoftext|>\"]\n",
            "\n",
            "Generating sample 45/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            " one fusion generation in solar, a subversion is started in the moon, and another subversion happens in a land plate in the ocean, or a floating island, in the sky that’s far from the sun.\\n\\n“When you see the small signatures, this is the process of plate tectonics in the ocean – they shift rapidly away from the point of origin in the crust and wind up on the surface of the upper ocean, allowing the plate impact on Earth and the continental crust.”\\n\\n“They are connected through subduction channels, which means that very tiny charged particles – magnetic charges – by their magnetism reach the ground, allowing them to work on the crust.”\\n\\n“For example, if a slab of land is damaged by a big ship landing on Norfolk Island, the crust passes down to a shelf on the shore of Tasmania. This immediately causes the loss of land, which is responsible for a minor knockdown of the crust, for example, when a meteorite strikes the mainland breaks into the north arm of Australia.”\\n\\nThe interaction between a plate or island’s soil and a fault can be as important as interactions between the crust.\\n\\n“The Earth’s crust is a complex and incomplete chain. It goes through that mechanism, and these interactions are the result of subduction and metaposition. They are the major component of the interaction force in plate chemistry – they result in heat trapped within the crust heating up,” says Professor.\\n\\n“When the crust develops with plate friction, it can be modulated as heat pressure increases, and the cause of the subduction processes (subduction and metaposition) acts well under the shear stress.\\n\\n“So on these interactions, the plates are pressed to keep the crust from sinking, so they get filled again quickly. And what happens is that thus plates often form surface islands on the crust, and then a succession of smaller islands in the ocean, such as Norfolk Island.\\n\\n“Tectonary action by the undersea system can cause a minor collapse of the crust, because plate friction activity causes minor damage to the crust, that is, prevents the lighter crust from cracking, and, as the crust does crack, produces the lighter crust.”\\n\\nThe Professor also notes tectonary interaction can also be relevant to controlling earthquakes.\\n\\n“The way that the second of the Earth's crust – the crust and the mantle – interact with its mantle, is – it’s a mutual exchange which can produce earthquakes,” says. “These are called vibrations.”\\n\\n“Evidence suggests that this tectonic exchange provides a mechanism to trigger earthquakes such as the one that occurred in the ArchGats, meaning that the Earth’s crust sends this signal in the lithosphere, which – if this occurs at every point between Earth and the lithosphere – would be sufficient to trigger any possible seismic activity.”\\n\\n“In current models, almost 60% of the world's crust has a continental plate axis, so it is still highly unlikely that one could have struck off Victoria that was so large.\\n\\n“If the small landmass\"]\n",
            "\n",
            "Generating sample 46/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "r grieving over husband’s body found in a basement basement\\n\\nIn the 2010 hours after her husband was discovered lying dead in a basement basement, 40-year-old Joanne Stupbel, who had fallen out of deep depression, until recently became uneasplain by the mysterious death revealed in a shocking revelation, Florida police say.\\n\\nOn Sunday, police, prosecutors and three children were ruled responsible for their deaths after Joanne Stupbel said herself and her daughters were shattered by the horrific tragedy.\\n\\n‘I’m devastated I’ve lost my life,’ ‘I work on men’s bangs [of which the legs were amputated] and when I am pregnant and breastfeeding, I’ve never thought it might be a possibility,’ she told the Miami Herald, the Herald reported.\\n\\nStupbel had sought out a home and confirmed that the incident began in anger around 2pm when the family called to report that her husband's body had fallen and her daughters were missing.\\n\\nShe immediately contacted 911 and called police before making a recovery at the location of the crime.\\n\\n‘They would tell me that he’d had the leg fall and his body was gone,’ Stupbel told the Herald.\\n\\nStupbel described the 911 call to a neighbour, who arrived at the family’s residence, in a state of horrified confusion as part of the body had been cut off and moved.\\n\\nA neighbour later told her daughter that her husband had been bound to his wife’s feet in a house in the area that night before telling police the reason for it was a result of her inability to understand what had happened.\\n\\nStupbel now has spoken up and admitted she could not assist her wife with medical attention because of her own inability to explain\\n\\nShe said she had found the body in the basement where she had lost the intimacy between him and her.\\n\\n‘It’s been a year filled with sorrow and anguish but I’m still grateful. To wait a year before the worst goes away,’ she told reporters on Tuesday.\\n\\nWhile the tragic revelations show utter indifference towards the public, and the support of an appalling system of Florida police and prosecutors, Stupbel has in turn become a whistleblower.\\n\\nShe is still working to help provide support for her children, who remain a sensitive subject of grief. Her children for her daughters have been neglected for several years and are now undergoing palliative treatment facilities.\\n\\nJust last month, Stupbel raised concerns over three catering company employees who were there with her children at their home when she was found dead with a fourth employee in the basement.\\n\\nAfter being condemned by the Federal Trade Commission, a US government agency, she fired the remaining five men despite criticism that they acted alone.\\n\\n‘When I met them just after the investigation showed me, it was clear that I helped them out,’ she told the Herald.\\n\\nHowever, a time later, the employee for his part pointed out a better way to help her children.\\n\\nStupbel has reached out to Editor-in-Chief George Roshin.<|endoftext|>\"]\n",
            "\n",
            "Generating sample 47/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "order.<|endoftext|>']\n",
            "Generative perplexity: tensor(35.8473, device='cuda:0')\n",
            "Entropy: tensor(5.0215, device='cuda:0')\n",
            "['<|endoftext|>ElectronicMedia.org has learned that some members, including members of the Supreme Court, may be making an inappropriate reference to the 2016 corruption complaint. The new members were officially selected Tuesday by the Pennsylvania Supreme Court.\\n\\nThe court members were appointed to stop the passage of a ballot measure that would allow voters to seek their own ballot in defiance of the election, a measure that has triggered a recount and violates the constitutionality in Pennsylvania, PA. On the 2015 May ballot, it would have prohibited recount filing seven days before early elections or turnout. In 2016, the ballot provision blocked ballot recount for seven days showing significant irregularities.\\n\\nAlthough the board members consider red paper votes that were voted for in ballots and absentee ballots \"counts,\" the reported impact are among the ramifications of their decision.\\n\\nThe new board members also have not signed an executive order by Governor Tom Wolf and orders by President Trump to leave state budget and judicial positions as vacant in order for new board oversight boards.\\n\\nElect Media also heard from multiple attorney board members during the recall hearings throughout the Pennsylvania legislature that have called for a wide expansion of the investigation of the 2016 corruption complaint, made up of which had been only limited to then-Attorneys John Santelli and John Stuart.\\n\\nFormer Attorney General Steve Popellatskiy wants the prosecutors, officers and members of the General Assembly to appoint the new members. Popellatskiy resigned from the State Senate as a result of electoral misconduct after winning a two-day recount to oust him.\\n\\nBoth Popellatskiy have apologized to both senators but they have been told by Attorney General Jim Evans last week that Evans will not be accepting a bipartisan panel take over the special Senate investigation into whether someone in office in Pennsylvania deviated from votes.\\n\\nOver the past several weeks, Evans has opened a criminal investigation, but chose not to involve prosecutors in the criminal investigation unless they show corruption in office. In the following days, Evans only focused his investigation on his attorney general district.\\n\\nThe attorney district is home to many of the largest corporations in the Commerce-industrial complex as well as some of the largest companies in politics and more.\\n\\nThe specific actions that could have been suggested by the new board members are not publicly available to the media, and would appear to have occurred during the hearings starting Wednesday morning.\\n\\nElectronicMedia.org announced the news that the new members would be selected, but state attorney general lawyers did not respond to a media request for information about whether to appoint the members per governor\\'s executive order.<|endoftext|>']\n",
            "\n",
            "Generating sample 48/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "d David Klein, principal investigator for the study, which is now NASA\\'s Cassini mission. “It is a close-by to Earth, much like its parent star and big enough to orbit. These planets have Earth-like orbits and large enough to extend outward for at least an average of 10 times a year, once every ten or more years.\"\\n\\nInstead of orbiting or orbiting like our Sun, our solar system can be found revolving around other planets below the surface of the Earth, at speeds of 120 to 100 mph (odds). Such orbiters are routinely used to transit nearby planets to study their solar system, but they do not make regular flybys or transit.\\n\\nThe discovery of Dwarf Planets at Cassini, from NASA\\'s Kepler Space Telescope, is a lifetime\\'s achievement. Until recently as the region at the center of our galaxy astronomers never produced an image of giant planets.\\n\\n“This is a big result,” said Klein in the study. “It is possible to find star-like objects like exoplanets, but very rarely, to find worlds orbiting around the stars where giant planets are discovered.”\\n\\nOur solar system is caused by a phenomenon where small planets move around to have a mass two times greater than the nearest planets. One of these masses has density to be an equivalent of the mass of gas giants and the other two have mass. It is believed these worlds are half the Earth-sized and one-sized planets, but are thought to be able to form two star systems close to the centre of each other. The research team predicted mass-matching pairs were likely to be rare but as the time went on, they picked up planets and formed worlds that were thought to be unlikely to be discovered.\\n\\nWhile the researchers managed to track nine planets in one of the smaller systems for them, it may have been two that formed the next or other ones in particular. The smallest planet was originally thought to be in very tiny, circular orbits that could take 30 to 100 days per year.\\n\\nIf that system were formed they would be able to visit a fourth planet in a similar system.\\n\\nThere is likely to be a number of stars forming planets that are so close to us that we cannot see them. However, the exoplanets are pointed in toward the stars and often orbit with the same distance from them as Earth.\\n\\n\"Planets in our solar system are as large as the Solar System,\" said Bradley Moran-Harber, principal of NASA\\'s WITF-Stipck Observatory for Earth and Space.\\n\\nIt is estimated that the giant planets are as large or as large as the planets by Earth\\'s solar system. Most of these planets are twice larger and are thought to be from the early Universe. Unlike in such planetary systems, it is also difficult to know which of the two is and which is not.\\n\\nThe dwarf planet Palae for example, is featured in the study of Dwarf Planets but has not been detailed by studying its orbit around the Sun. We cannot confirm what the planet is and we can only speculate about the evolution of it and what moons it might be planets.<|endoftext|>']\n",
            "\n",
            "Generating sample 49/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "his wife claimed her husband didn\\'t pay the money back for cost of his operating insurance policy.\\n\\nStill, he said, his story is not over.\\n\\n\"The hope is great as you wish, but because of your pain and because the family you\\'ve lost you, it\\'s going to come back,\" Doug Barnes said. \"I hope it\\'s going to change.\"<|endoftext|>']\n",
            "Generative perplexity: tensor(22.4505, device='cuda:0')\n",
            "Entropy: tensor(4.9214, device='cuda:0')\n",
            "['<|endoftext|>After a series of hospital starts, one patient ran the risk of paying nearly $35,000 in pain fees for all the dental work to his now-death mother.\\n\\nKendrick Barnes said Friday he went to the dentist about a half hours after he passed away Tuesday night in suburban Columbus, Ohio. His family wanted an additional $13,500 in it, he said.\\n\\n\"That adds up the cost of the operation,\" said Barnes, 49, who reached out to a Columbus doctor on his condition and said family members could not get him to the dentist.\\n\\n\"The amount is going to be assessed by a company to ensure we pay what insurance does,\" said Dr. John J. Motas. \"It\\'s basically going to be better to deal with insurance than to because of that.\" Motas said he lost his home in Columbus and had his monthly insurance charge capped at $6,845 in April.\\n\\nHe said he had dropped his income last year.\\n\\nHe had hoped he could pay out of pocket, in case his daughter, his mother, planned to attack him.\\n\\n\"I wanted to cover out of pocket,\" he said.\\n\\nThe insurance plan allowed one of his three children to get out of the hospital at Middle Cross Children\\'s Day Memorial Hospital. The family now is to look for a Columbus dentist to do most of the work. Children are taken to the hospital, but the parents have their IVs, Motas said.\\n\\nThe dentist will pay any of the costs.\\n\\nBarns takes two pills of electrolytes, some salt and water to get rid of the pain he was going through, and he waited for an IV at the hospital.\\n\\n\"I really realized that I had sunk,\" he said, then called the Columbus Clinic \"and I saw what my family was paying.\"\\n\\n\"It was an absolute awful, mentally, and financially nightmare,\" getting in touch with the dentist said.\\n\\nThe dentist, Doug Barnes, said he was able to go to Barnes\\' home just Friday morning and see him at 2 o\\'clock Friday morning. His family had not arrived yet and had talked to him from work.\\n\\nHe did not contact his family with any of the bills since.\\n\\n\"My son has a horrible seizure. I woke him up and he has a seizure,\" Doug Barnes said. \"His mother-in-law from New York came home here [with us] too.\"\\n\\nBarns said the hospital bill was not enough for the pain in his pocket. He noted that his wife claimed her husband didn\\'t pay the money back for cost of his operating insurance policy.\\n\\nStill, he said, his story is not over.\\n\\n\"The hope is great as you wish, but because of your pain and because the family you\\'ve lost you, it\\'s going to come back,\" Doug Barnes said. \"I hope it\\'s going to change.\"<|endoftext|>']\n",
            "\n",
            "Generating sample 50/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "h during the downturn.\\n\\nIn the past few weeks, many hiring people have been quitting after a job and lose jobs caused by being self-employed. There are repercussions to be involved. On Monday the CIO announced it would slash by 50 percent the number of stores open that day and that more than 2,700 and an entire factory will open at idle times. That amounts to 164 out of 15,000 CIO employees.\\n\\nMore layoffs start next week. Employers are expecting layoffs of more than 1 percent a year, which is quite close to the unemployment estimate noted in the jobs report.\\n\\nThe website shows that 32.8 percent of the 40-plus worked time members in the labor force and 60 percent of those employed with a job. In addition there were more than 2.2 million job unemployed members that were not unemployed or employed. However, this was only 23.2 percent, more than 7.1 percent of the total hourly non-fooding services members. These workers do not get a raise, most receive no benefits from their employers, and working time does not provide them good pay. Among this group, the latest unemployment data show only a raise of 50 cents.\\n\\nEisenhower added that there were more than 230,000 people who worked full time or eight jobs and counted 9 percent of the total total who were not employed, up from a peak of about 2 million at the same time in 1960. That is what the Census Bureau reported the number of median workers who were not employed down 6 percent from the year prior in the same quarter.\\n\\nAlthough unemployment has traditionally exceeded unemployment levels in this time, there has been a partial bull run as to where the unemployment rate will exceed the national average in the long run. There have been some moderate gains in individual unemployment over the last few years, and average unemployment levels have been higher because of the performance of the labor market.\\n\\nOn the other hand, the unemployment rate is growing at about three times as since the recession of 2008, which is slightly shy of the 9.4 percent unemployment Gallup reported.\\n\\nwww.horney-playt.com has seen Issue Brief No. 1 U.S. No. 32 on the Supreme Court striking of that plan. Last week the White House appealed to the Court for the Court to reconsider the full version of the Bush economic stimulus plan and if the Court said no, it would have imposed a spending freeze on all plans.\\n\\nUSA Today and Gallup were just asking questions about the projected long-term budget cuts to Congress one week before the new legislative session. In this case the numbers are just wrong. They need more facts.\\n\\n“While it has been a very difficult year, various programs, unemployment numbers, the unemployment number - it’s a tough year,” said Employment and Numbers Institute Director Joel Sato. “The government has been trying for some time since it has been possible. The economy is getting better and in the winter we’ll see some hiring now. There’s not going to be a rush for jobs in November.”<|endoftext|>']\n",
            "\n",
            "\n",
            "Done!\n",
            "\n",
            "=== Length Statistics ===\n",
            "Samples: 50\n",
            "Median: 959 tokens\n",
            "Max: 4095 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Autoregressive LM for comparison\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training Autoregressive LM (block_size=16)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "ar_lm_ckpt = train_run(\n",
        "\trun_name=\"ar_lm_L16\",\n",
        "\talgo=\"ar\",\n",
        "\tblock_size=16,\n",
        "\tmax_steps=800,\n",
        ")\n",
        "print(f\"✓ AR LM: {ar_lm_ckpt}\")\n",
        "ar_lm_hf_checkpoint = convert_ckpt_to_hf(\n",
        "\tckpt_path=ar_lm_ckpt,\n",
        "\toutput_dir=\"/content/hf_checkpoints/ar_lm_L16\",\n",
        "\tblock_size=16\n",
        ")\n",
        "\n",
        "ar_lm_stats = eval_run(\n",
        "\talgo=\"ar\",\n",
        "\thf_checkpoint_path=ar_lm_hf_checkpoint,\n",
        "\tblock_size=16,\n",
        "\tnum_samples=50,\n",
        "  model_length=max_model_length\n",
        ")\n",
        "\n",
        "results.append({\n",
        "\t\"model\": \"Autoregressive LM L'=16 (baseline)\",\n",
        "\t\"median_tokens\": ar_lm_stats['median'],\n",
        "\t\"max_tokens\": ar_lm_stats['max'],\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cypg8FWT8EzI",
        "outputId": "2639df6b-ff80-4710-8920-43434706195a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training Autoregressive LM (block_size=16)\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ++data.max_train_samples=1500 ...\n",
            "rk if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 618: 'val/nll' reached 7.91222 (best 7.91222), saving model to '/content/repro_runs/ar_lm_L16/checkpoints/best.ckpt' as top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 668: 'val/nll' reached 7.76652 (best 7.76652), saving model to '/content/repro_runs/ar_lm_L16/checkpoints/best.ckpt' as top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 718: 'val/nll' reached 7.69982 (best 7.69982), saving model to '/content/repro_runs/ar_lm_L16/checkpoints/best.ckpt' as top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 768: 'val/nll' reached 7.67002 (best 7.67002), saving model to '/content/repro_runs/ar_lm_L16/checkpoints/best.ckpt' as top 1\n",
            "`Trainer.fit` stopped: `max_steps=800` reached.\n",
            "\n",
            "✓ Checkpoint: /content/repro_runs/ar_lm_L16/checkpoints/best.ckpt\n",
            "✓ AR LM: /content/repro_runs/ar_lm_L16/checkpoints/best.ckpt\n",
            "\n",
            "==================================================\n",
            "Converting /content/repro_runs/ar_lm_L16/checkpoints/best.ckpt\n",
            "To: /content/hf_checkpoints/ar_lm_L16\n",
            "==================================================\n",
            "\n",
            "[1/4] Loading reference model from HuggingFace...\n",
            "\n",
            "[2/4] Loading Lightning checkpoint...\n",
            "   Found 69 parameters\n",
            "\n",
            "[3/4] Cleaning state dict keys...\n",
            "   Cleaned keys: ['vocab_embed.embedding', 'rotary_emb.inv_freq', 'blocks.0.norm1.weight']\n",
            "\n",
            "[4/4] Applying our weights to model...\n",
            "   Missing: 133, Unexpected: 69\n",
            "\n",
            "✓ Saved to /content/hf_checkpoints/ar_lm_L16\n",
            "Generating sample 1/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 2/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 3/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 4/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 5/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 6/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 7/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 8/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 9/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 10/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 11/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 12/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 13/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 14/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 15/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 16/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 17/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 18/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 19/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 20/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 21/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 22/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 23/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 24/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 25/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 26/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 27/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 28/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 29/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 30/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 31/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 32/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 33/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 34/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 35/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 36/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 37/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 38/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 39/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 40/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 41/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 42/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 43/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 44/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 45/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 46/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 47/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 48/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 49/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "Generating sample 50/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            ".py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 105, in run\n",
            "    cfg = self.compose_config(\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
            "    cfg = self.config_loader.load_configuration(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
            "    return self._load_configuration_impl(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/config_loader_impl.py\", line 253, in _load_configuration_impl\n",
            "    defaults_list = create_defaults_list(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 745, in create_defaults_list\n",
            "    defaults, tree = _create_defaults_list(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 715, in _create_defaults_list\n",
            "    defaults_tree = _create_defaults_tree(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 356, in _create_defaults_tree\n",
            "    ret = _create_defaults_tree_impl(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 457, in _create_defaults_tree_impl\n",
            "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 280, in _expand_virtual_root\n",
            "    subtree = _create_defaults_tree_impl(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 573, in _create_defaults_tree_impl\n",
            "    add_child(children, new_root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 520, in add_child\n",
            "    subtree_ = _create_defaults_tree_impl(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 488, in _create_defaults_tree_impl\n",
            "    config_not_found_error(repo=repo, tree=root)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/defaults_list.py\", line 799, in config_not_found_error\n",
            "    raise MissingConfigException(\n",
            "hydra.errors.MissingConfigException: In 'config': Could not find 'algo/ar_lm'\n",
            "\n",
            "Available options in 'algo':\n",
            "\tar\n",
            "\tbd3lm\n",
            "\tmdlm\n",
            "\tsedd\n",
            "Config search path:\n",
            "\tprovider=hydra, path=pkg://hydra.conf\n",
            "\tprovider=main, path=file:///content/bd3lms/configs\n",
            "\tprovider=schema, path=structured://\n",
            "\n",
            "\n",
            "Done!\n",
            "\n",
            "=== Length Statistics ===\n",
            "Samples: 0\n",
            "Median: None tokens\n",
            "Max: None tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SEDD for comparison\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training SEDD (block_size=16)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "sedd_ckpt = train_run(\n",
        "\trun_name=\"sedd_L16\",\n",
        "\talgo=\"sedd\",\n",
        "\tblock_size=16,\n",
        "\tmax_steps=800,\n",
        "\textra_overrides=[\n",
        "\t\t\"training.resample=false\",\n",
        "\t\t\"algo.var_min=false\",\n",
        "    \"algo.parameterization=sedd\"\n",
        "\t],\n",
        ")\n",
        "print(f\"✓ SEDD: {sedd_ckpt}\")\n",
        "sedd_hf_checkpoint = convert_ckpt_to_hf(\n",
        "\tckpt_path=sedd_ckpt,\n",
        "\toutput_dir=\"/content/hf_checkpoints/sedd_L16\",\n",
        "\tblock_size=16\n",
        ")\n",
        "\n",
        "sedd_stats = eval_run(\n",
        "\talgo=\"sedd\",\n",
        "\thf_checkpoint_path=sedd_hf_checkpoint,\n",
        "\tblock_size=16,\n",
        "\tnum_samples=50,\n",
        "  extra_overrides=[\n",
        "      \"algo.parameterization=sedd\"\n",
        "    ],\n",
        ")\n",
        "\n",
        "results.append({\n",
        "\t\"model\": \"SEDD L'=16 (baseline)\",\n",
        "\t\"median_tokens\": sedd_stats['median'],\n",
        "\t\"max_tokens\": sedd_stats['max'],\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68EMLtUB82OQ",
        "outputId": "db39f433-78c6-494f-8577-62c7311ae4d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training SEDD (block_size=16)\n",
            "============================================================\n",
            "\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=train data=openwebtext-split ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ++data.max_train_samples=1500 ...\n",
            "k if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 568: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 618: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 668: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 718: 'val/nll' was not in top 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Epoch 1, global step 768: 'val/nll' was not in top 1\n",
            "`Trainer.fit` stopped: `max_steps=800` reached.\n",
            "\n",
            "✓ Checkpoint: /content/repro_runs/sedd_L16/checkpoints/best.ckpt\n",
            "✓ SEDD: /content/repro_runs/sedd_L16/checkpoints/best.ckpt\n",
            "\n",
            "==================================================\n",
            "Converting /content/repro_runs/sedd_L16/checkpoints/best.ckpt\n",
            "To: /content/hf_checkpoints/sedd_L16\n",
            "==================================================\n",
            "\n",
            "[1/4] Loading reference model from HuggingFace...\n",
            "\n",
            "[2/4] Loading Lightning checkpoint...\n",
            "   Found 91 parameters\n",
            "\n",
            "[3/4] Cleaning state dict keys...\n",
            "   Cleaned keys: ['vocab_embed.embedding', 'sigma_map.mlp.0.weight', 'sigma_map.mlp.0.bias']\n",
            "\n",
            "[4/4] Applying our weights to model...\n",
            "   Missing: 133, Unexpected: 91\n",
            "\n",
            "✓ Saved to /content/hf_checkpoints/sedd_L16\n",
            "Generating sample 1/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823477.135133   59142 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=42', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 2/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823497.695856   59251 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=43', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 3/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823516.029940   59338 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=44', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 4/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823534.127860   59423 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=45', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 5/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823552.043662   59506 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=46', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 6/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823570.190362   59591 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=47', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 7/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823588.321825   59676 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=48', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 8/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823606.590331   59759 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=49', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 9/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823624.817475   59844 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=50', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 10/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823643.120091   59927 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=51', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 11/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823661.696596   60016 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=52', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 12/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823679.782355   60101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=53', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 13/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823698.437764   60184 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=54', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 14/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823716.260089   60269 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=55', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 15/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823735.299464   60356 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=56', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 16/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823753.328362   60441 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=57', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 17/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823771.552442   60526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=58', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 18/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823790.081202   60609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=59', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 19/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823808.202978   60694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=60', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 20/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823826.980927   60781 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=61', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 21/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823845.422762   60866 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=62', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 22/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823865.203513   60955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=63', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 23/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823882.855548   61042 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=64', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 24/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823901.535404   61127 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=65', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 25/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823919.483891   61214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=66', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 26/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823937.780226   61295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=67', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 27/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823956.033090   61384 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=68', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 28/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823974.075361   61467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=69', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 29/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769823992.084020   61552 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=70', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 30/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824010.297060   61636 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=71', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 31/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824029.099728   61721 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=72', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 32/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824047.112153   61806 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=73', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 33/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824065.906375   61893 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=74', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 34/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824083.989564   61978 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=75', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 35/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824103.176666   62065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=76', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 36/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824121.310559   62150 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=77', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 37/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824139.520959   62235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=78', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 38/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824157.537106   62318 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=79', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 39/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824175.197552   62403 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=80', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 40/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824194.041322   62486 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=81', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 41/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824211.741240   62571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=82', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 42/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824230.575483   62660 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=83', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 43/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824248.743272   62743 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=84', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 44/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824267.377900   62828 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=85', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 45/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824285.335673   62911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=86', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 46/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824303.799397   63000 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=87', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 47/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824321.650963   63085 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=88', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 48/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824340.057087   63168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=89', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 49/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824358.328295   63253 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=90', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "Generating sample 50/50...\n",
            "$ /usr/bin/python3 -u bd3lms/main.py mode=sample_eval data=openwebtext-split sampling.num_sample_batches=1 ++data.cache_dir=/content/bd3lms/data ++data.streaming=true ...\n",
            "c:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769824376.395858   63336 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Error executing job with overrides: ['mode=sample_eval', 'data=openwebtext-split', 'sampling.num_sample_batches=1', '++data.cache_dir=/content/bd3lms/data', '++data.streaming=true', '++data.max_test_samples=1', 'model=tiny', 'model.length=1024', 'model.attn_backend=sdpa', 'algo=sedd', 'algo.backbone=hf_dit', 'algo.T=5000', 'eval.checkpoint_path=/content/hf_checkpoints/sedd_L16', 'sampling.var_length=true', 'sampling.nucleus_p=0.9', 'sampling.kv_cache=true', 'sampling.logdir=/content/sample_logs/varlen_sedd_bs16', 'seed=91', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.precision=16-mixed', 'wandb=null', 'block_size=16', 'loader.eval_batch_size=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bd3lms/main.py\", line 234, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 225, in main\n",
            "    samples = generate_samples(config, logger, tokenizer)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 91, in generate_samples\n",
            "    model = _load_from_checkpoint(config=config,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/main.py\", line 30, in _load_from_checkpoint\n",
            "    return diffusion.Diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/bd3lms/diffusion.py\", line 122, in __init__\n",
            "    self._validate_configuration()\n",
            "  File \"/content/bd3lms/diffusion.py\", line 148, in _validate_configuration\n",
            "    assert self.config.algo.name in {'ar', 'bd3lm'}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "\n",
            "\n",
            "Done!\n",
            "\n",
            "=== Length Statistics ===\n",
            "Samples: 0\n",
            "Median: None tokens\n",
            "Max: None tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# RESULTS\n",
        "# ========================================\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TABLE 6 RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comparison = [\n",
        "    {\"model\": \"SEDD (paper)\", \"median_tokens\": 1021, \"max_tokens\": 1024},\n",
        "    {\"model\": \"BD3-LM L'=16 (paper)\", \"median_tokens\": 798, \"max_tokens\": 9982},\n",
        "] + results\n",
        "\n",
        "df = pd.DataFrame(comparison)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"KEY INSIGHT: SEDD limited to 1024, BD3-LM generates ~10x longer!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "results",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23dbff87-d623-43d2-d9f0-e166fdc8b006"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TABLE 6 RESULTS\n",
            "============================================================\n",
            "                             model  median_tokens  max_tokens\n",
            "                      SEDD (paper)         1021.0      1024.0\n",
            "              BD3-LM L'=16 (paper)          798.0      9982.0\n",
            "               BD3-LM L'=16 (ours)          959.0      4095.0\n",
            "Autoregressive LM L'=16 (baseline)            NaN         NaN\n",
            "             SEDD L'=16 (baseline)            NaN         NaN\n",
            "\n",
            "============================================================\n",
            "KEY INSIGHT: SEDD limited to 1024, BD3-LM generates ~10x longer!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDbPBDAF3fXT"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}