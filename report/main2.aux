\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\abx@aux@refcontext{nty/global//global/global}
\abx@aux@cite{0}{arriola2025block}
\abx@aux@segm{0}{0}{arriola2025block}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Block Diffusion Models (BD3-LMs)}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Background: Masked Discrete Diffusion and Noise Schedules}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Protocol and Metrics}{2}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Model Configuration and Datasets}{2}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Training Regimen}{2}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Evaluation Metrics}{2}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Reproduction Results}{3}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}AR vs BD3-LM with $L'=1$}{3}{subsection.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Test perplexities for single-token generation on LM1B (800 training steps).}}{3}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:ar_vs_bd3lm_l1}{{1}{3}{Test perplexities for single-token generation on LM1B (800 training steps)}{table.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training NLL curves for single-token generation on LM1B.}}{3}{figure.caption.2}\protected@file@percent }
\newlabel{fig:l1_curves}{{1}{3}{Training NLL curves for single-token generation on LM1B}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Effect of clipped noise schedules}{3}{subsection.5.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Effect of clipped noise schedules on LM1B (400 pretraining steps + 100 fine-tuning steps).}}{4}{table.caption.3}\protected@file@percent }
\newlabel{tab:clipping_effect}{{2}{4}{Effect of clipped noise schedules on LM1B (400 pretraining steps + 100 fine-tuning steps)}{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}LM1B and OWT comparisons}{4}{subsection.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Test perplexities on LM1B (400 pretraining steps + 100 fine-tuning steps).}}{4}{table.caption.4}\protected@file@percent }
\newlabel{tab:lm1b_main}{{3}{4}{Test perplexities on LM1B (400 pretraining steps + 100 fine-tuning steps)}{table.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Test perplexities on OWT (3000 pretraining steps + 3000 fine-tuning steps).}}{4}{table.caption.5}\protected@file@percent }
\newlabel{tab:owt_main}{{4}{4}{Test perplexities on OWT (3000 pretraining steps + 3000 fine-tuning steps)}{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Transfer evaluation (trained on OWT)}{4}{subsection.5.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Zero-shot validation perplexities of models trained on OWT (800 pretraining steps + 800 fine-tuning steps).}}{5}{table.caption.6}\protected@file@percent }
\newlabel{tab:transfer}{{5}{5}{Zero-shot validation perplexities of models trained on OWT (800 pretraining steps + 800 fine-tuning steps)}{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Variable-length generation}{5}{subsection.5.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Generation length statistics for 10 sampled documents from OWT-trained models (800 pretraining steps + 500 fine-tuning steps). BD3-LM reproduction with model length $=16$K.}}{5}{table.caption.7}\protected@file@percent }
\newlabel{tab:gen_length_stats}{{6}{5}{Generation length statistics for 10 sampled documents from OWT-trained models (800 pretraining steps + 500 fine-tuning steps). BD3-LM reproduction with model length $=16$K}{table.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Sample quality and schedule ablations}{5}{subsection.5.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Generative perplexity (Gen.PPL; $\downarrow $) and number of function evaluations (NFEs; $\downarrow $) for 300 samples. Models trained on OWT (400 + 100 training steps).}}{5}{table.caption.8}\protected@file@percent }
\newlabel{tab:sample_quality}{{7}{5}{Generative perplexity (Gen.PPL; $\downarrow $) and number of function evaluations (NFEs; $\downarrow $) for 300 samples. Models trained on OWT (400 + 100 training steps)}{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Effect of noise schedule on PPL and Var.\ NELBO for different $L'$ on LM1B (5000 + 3000 training steps).}}{6}{table.caption.9}\protected@file@percent }
\newlabel{tab:noise_schedule_ablation}{{8}{6}{Effect of noise schedule on PPL and Var.\ NELBO for different $L'$ on LM1B (5000 + 3000 training steps)}{table.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Extension 1: Alternative Noise Schedules}{6}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Already Implemented Noise Schedules}{6}{subsection.6.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Already implemented noise schedules: masked probability $p(t)$ and induced loss scaling.}}{6}{table.caption.10}\protected@file@percent }
\newlabel{tab:implemented_schedules}{{9}{6}{Already implemented noise schedules: masked probability $p(t)$ and induced loss scaling}{table.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Gaussian \& Bimodal Gaussian Noise Schedules}{6}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Results}{7}{subsection.6.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Already-implemented schedules vs newly implemented Gaussian and bimodal Gaussian (B.G.) schedules on LM1B (400 pretraining steps + 100 fine-tuning steps).}}{7}{table.caption.11}\protected@file@percent }
\newlabel{tab:new_schedules}{{10}{7}{Already-implemented schedules vs newly implemented Gaussian and bimodal Gaussian (B.G.) schedules on LM1B (400 pretraining steps + 100 fine-tuning steps)}{table.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Applying bimodal Gaussian during pretraining on LM1B: for each pretraining schedule we report the best fine-tuning schedule found (400 pretraining steps + 100 fine-tuning steps).}}{7}{table.caption.12}\protected@file@percent }
\newlabel{tab:bg_pretraining}{{11}{7}{Applying bimodal Gaussian during pretraining on LM1B: for each pretraining schedule we report the best fine-tuning schedule found (400 pretraining steps + 100 fine-tuning steps)}{table.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Extension 2: Loss Reweighting for the Masked Diffusion Objective}{7}{section.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Illustration of reweighting schemes (from the final presentation).}}{8}{figure.caption.13}\protected@file@percent }
\newlabel{fig:reweighting}{{2}{8}{Illustration of reweighting schemes (from the final presentation)}{figure.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Weighting functions investigated for masked diffusion models (as reported in the final presentation).}}{8}{table.caption.14}\protected@file@percent }
\newlabel{tab:reweighting_defs}{{12}{8}{Weighting functions investigated for masked diffusion models (as reported in the final presentation)}{table.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces Test perplexities under different loss reweightings (from the final presentation).}}{8}{table.caption.15}\protected@file@percent }
\newlabel{tab:reweighted_results}{{13}{8}{Test perplexities under different loss reweightings (from the final presentation)}{table.caption.15}{}}
\abx@aux@nociteall
\@writefile{toc}{\contentsline {section}{\numberline {8}Discussion}{9}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Conclusion and Future Work}{9}{section.9}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{221A3227F80F2C2F777DE714612D2AA1}
\abx@aux@defaultrefcontext{0}{arriola2025block}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{kosmopoulou-etal-2025-masked}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{shi2025demystifyingdiffusionobjectivesreweighted}{nty/global//global/global}
\gdef \@abspage@last{9}
